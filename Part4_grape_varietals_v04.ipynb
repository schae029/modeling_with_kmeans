{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with k-means, Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part 4 I continue to apply the methods of Parts 1, 2, and 3.  The difference is that here we are looking for 3 clusters rather than just 2.\n",
    "\n",
    "As in Part 2, since there are so few records in the *wine* dataset (178 records, or samples), I will include all records in the training set data and compare model performance based on cross-validation scores.\n",
    "\n",
    "The wine samples represent three varietals.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                   * * * * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "require(rattle)\n",
    "require(car)\n",
    "require(repr)\n",
    "require(ggplot2)\n",
    "require(stringr)\n",
    "require(parallel)\n",
    "require(faraway)\n",
    "require(randomForest)\n",
    "require(plyr)\n",
    "require(e1071)\n",
    "require(xgboost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(digits= 5, show.signif.stars= FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>178</li><li>14</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 178\n",
       "\\item 14\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 178\n",
       "2. 14\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 178  14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'Type'</li><li>'Alcohol'</li><li>'Malic'</li><li>'Ash'</li><li>'Alcalinity'</li><li>'Magnesium'</li><li>'Phenols'</li><li>'Flavanoids'</li><li>'Nonflavanoids'</li><li>'Proanthocyanins'</li><li>'Color'</li><li>'Hue'</li><li>'Dilution'</li><li>'Proline'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Type'\n",
       "\\item 'Alcohol'\n",
       "\\item 'Malic'\n",
       "\\item 'Ash'\n",
       "\\item 'Alcalinity'\n",
       "\\item 'Magnesium'\n",
       "\\item 'Phenols'\n",
       "\\item 'Flavanoids'\n",
       "\\item 'Nonflavanoids'\n",
       "\\item 'Proanthocyanins'\n",
       "\\item 'Color'\n",
       "\\item 'Hue'\n",
       "\\item 'Dilution'\n",
       "\\item 'Proline'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Type'\n",
       "2. 'Alcohol'\n",
       "3. 'Malic'\n",
       "4. 'Ash'\n",
       "5. 'Alcalinity'\n",
       "6. 'Magnesium'\n",
       "7. 'Phenols'\n",
       "8. 'Flavanoids'\n",
       "9. 'Nonflavanoids'\n",
       "10. 'Proanthocyanins'\n",
       "11. 'Color'\n",
       "12. 'Hue'\n",
       "13. 'Dilution'\n",
       "14. 'Proline'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"Type\"            \"Alcohol\"         \"Malic\"           \"Ash\"            \n",
       " [5] \"Alcalinity\"      \"Magnesium\"       \"Phenols\"         \"Flavanoids\"     \n",
       " [9] \"Nonflavanoids\"   \"Proanthocyanins\" \"Color\"           \"Hue\"            \n",
       "[13] \"Dilution\"        \"Proline\"        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data.  The wine dataset is found in \n",
    "# package rattle.\n",
    "\n",
    "data(wine, package=\"rattle\")\n",
    "dim(wine)\n",
    "colnames(wine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 14</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Type</th><th scope=col>Alcohol</th><th scope=col>Malic</th><th scope=col>Ash</th><th scope=col>Alcalinity</th><th scope=col>Magnesium</th><th scope=col>Phenols</th><th scope=col>Flavanoids</th><th scope=col>Nonflavanoids</th><th scope=col>Proanthocyanins</th><th scope=col>Color</th><th scope=col>Hue</th><th scope=col>Dilution</th><th scope=col>Proline</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>14.23</td><td>1.71</td><td>2.43</td><td>15.6</td><td>127</td><td>2.80</td><td>3.06</td><td>0.28</td><td>2.29</td><td>5.64</td><td>1.04</td><td>3.92</td><td>1065</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>1</td><td>13.20</td><td>1.78</td><td>2.14</td><td>11.2</td><td>100</td><td>2.65</td><td>2.76</td><td>0.26</td><td>1.28</td><td>4.38</td><td>1.05</td><td>3.40</td><td>1050</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>1</td><td>13.16</td><td>2.36</td><td>2.67</td><td>18.6</td><td>101</td><td>2.80</td><td>3.24</td><td>0.30</td><td>2.81</td><td>5.68</td><td>1.03</td><td>3.17</td><td>1185</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>1</td><td>14.37</td><td>1.95</td><td>2.50</td><td>16.8</td><td>113</td><td>3.85</td><td>3.49</td><td>0.24</td><td>2.18</td><td>7.80</td><td>0.86</td><td>3.45</td><td>1480</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>1</td><td>13.24</td><td>2.59</td><td>2.87</td><td>21.0</td><td>118</td><td>2.80</td><td>2.69</td><td>0.39</td><td>1.82</td><td>4.32</td><td>1.04</td><td>2.93</td><td> 735</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>1</td><td>14.20</td><td>1.76</td><td>2.45</td><td>15.2</td><td>112</td><td>3.27</td><td>3.39</td><td>0.34</td><td>1.97</td><td>6.75</td><td>1.05</td><td>2.85</td><td>1450</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 14\n",
       "\\begin{tabular}{r|llllllllllllll}\n",
       "  & Type & Alcohol & Malic & Ash & Alcalinity & Magnesium & Phenols & Flavanoids & Nonflavanoids & Proanthocyanins & Color & Hue & Dilution & Proline\\\\\n",
       "  & <fct> & <dbl> & <dbl> & <dbl> & <dbl> & <int> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <int>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & 14.23 & 1.71 & 2.43 & 15.6 & 127 & 2.80 & 3.06 & 0.28 & 2.29 & 5.64 & 1.04 & 3.92 & 1065\\\\\n",
       "\t2 & 1 & 13.20 & 1.78 & 2.14 & 11.2 & 100 & 2.65 & 2.76 & 0.26 & 1.28 & 4.38 & 1.05 & 3.40 & 1050\\\\\n",
       "\t3 & 1 & 13.16 & 2.36 & 2.67 & 18.6 & 101 & 2.80 & 3.24 & 0.30 & 2.81 & 5.68 & 1.03 & 3.17 & 1185\\\\\n",
       "\t4 & 1 & 14.37 & 1.95 & 2.50 & 16.8 & 113 & 3.85 & 3.49 & 0.24 & 2.18 & 7.80 & 0.86 & 3.45 & 1480\\\\\n",
       "\t5 & 1 & 13.24 & 2.59 & 2.87 & 21.0 & 118 & 2.80 & 2.69 & 0.39 & 1.82 & 4.32 & 1.04 & 2.93 &  735\\\\\n",
       "\t6 & 1 & 14.20 & 1.76 & 2.45 & 15.2 & 112 & 3.27 & 3.39 & 0.34 & 1.97 & 6.75 & 1.05 & 2.85 & 1450\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 14\n",
       "\n",
       "| <!--/--> | Type &lt;fct&gt; | Alcohol &lt;dbl&gt; | Malic &lt;dbl&gt; | Ash &lt;dbl&gt; | Alcalinity &lt;dbl&gt; | Magnesium &lt;int&gt; | Phenols &lt;dbl&gt; | Flavanoids &lt;dbl&gt; | Nonflavanoids &lt;dbl&gt; | Proanthocyanins &lt;dbl&gt; | Color &lt;dbl&gt; | Hue &lt;dbl&gt; | Dilution &lt;dbl&gt; | Proline &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1 | 14.23 | 1.71 | 2.43 | 15.6 | 127 | 2.80 | 3.06 | 0.28 | 2.29 | 5.64 | 1.04 | 3.92 | 1065 |\n",
       "| 2 | 1 | 13.20 | 1.78 | 2.14 | 11.2 | 100 | 2.65 | 2.76 | 0.26 | 1.28 | 4.38 | 1.05 | 3.40 | 1050 |\n",
       "| 3 | 1 | 13.16 | 2.36 | 2.67 | 18.6 | 101 | 2.80 | 3.24 | 0.30 | 2.81 | 5.68 | 1.03 | 3.17 | 1185 |\n",
       "| 4 | 1 | 14.37 | 1.95 | 2.50 | 16.8 | 113 | 3.85 | 3.49 | 0.24 | 2.18 | 7.80 | 0.86 | 3.45 | 1480 |\n",
       "| 5 | 1 | 13.24 | 2.59 | 2.87 | 21.0 | 118 | 2.80 | 2.69 | 0.39 | 1.82 | 4.32 | 1.04 | 2.93 |  735 |\n",
       "| 6 | 1 | 14.20 | 1.76 | 2.45 | 15.2 | 112 | 3.27 | 3.39 | 0.34 | 1.97 | 6.75 | 1.05 | 2.85 | 1450 |\n",
       "\n"
      ],
      "text/plain": [
       "  Type Alcohol Malic Ash  Alcalinity Magnesium Phenols Flavanoids Nonflavanoids\n",
       "1 1    14.23   1.71  2.43 15.6       127       2.80    3.06       0.28         \n",
       "2 1    13.20   1.78  2.14 11.2       100       2.65    2.76       0.26         \n",
       "3 1    13.16   2.36  2.67 18.6       101       2.80    3.24       0.30         \n",
       "4 1    14.37   1.95  2.50 16.8       113       3.85    3.49       0.24         \n",
       "5 1    13.24   2.59  2.87 21.0       118       2.80    2.69       0.39         \n",
       "6 1    14.20   1.76  2.45 15.2       112       3.27    3.39       0.34         \n",
       "  Proanthocyanins Color Hue  Dilution Proline\n",
       "1 2.29            5.64  1.04 3.92     1065   \n",
       "2 1.28            4.38  1.05 3.40     1050   \n",
       "3 2.81            5.68  1.03 3.17     1185   \n",
       "4 2.18            7.80  0.86 3.45     1480   \n",
       "5 1.82            4.32  1.04 2.93      735   \n",
       "6 1.97            6.75  1.05 2.85     1450   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note that all of the predictors are numeric (continuous).\n",
    "# Note that Type is a factor.\n",
    "\n",
    "head(wine[, 1:14])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 14</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Type</th><th scope=col>Alcohol</th><th scope=col>Malic</th><th scope=col>Ash</th><th scope=col>Alcalinity</th><th scope=col>Magnesium</th><th scope=col>Phenols</th><th scope=col>Flavanoids</th><th scope=col>Nonflavanoids</th><th scope=col>Proanthocyanins</th><th scope=col>Color</th><th scope=col>Hue</th><th scope=col>Dilution</th><th scope=col>Proline</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>173</th><td>3</td><td>14.16</td><td>2.51</td><td>2.48</td><td>20.0</td><td> 91</td><td>1.68</td><td>0.70</td><td>0.44</td><td>1.24</td><td> 9.7</td><td>0.62</td><td>1.71</td><td>660</td></tr>\n",
       "\t<tr><th scope=row>174</th><td>3</td><td>13.71</td><td>5.65</td><td>2.45</td><td>20.5</td><td> 95</td><td>1.68</td><td>0.61</td><td>0.52</td><td>1.06</td><td> 7.7</td><td>0.64</td><td>1.74</td><td>740</td></tr>\n",
       "\t<tr><th scope=row>175</th><td>3</td><td>13.40</td><td>3.91</td><td>2.48</td><td>23.0</td><td>102</td><td>1.80</td><td>0.75</td><td>0.43</td><td>1.41</td><td> 7.3</td><td>0.70</td><td>1.56</td><td>750</td></tr>\n",
       "\t<tr><th scope=row>176</th><td>3</td><td>13.27</td><td>4.28</td><td>2.26</td><td>20.0</td><td>120</td><td>1.59</td><td>0.69</td><td>0.43</td><td>1.35</td><td>10.2</td><td>0.59</td><td>1.56</td><td>835</td></tr>\n",
       "\t<tr><th scope=row>177</th><td>3</td><td>13.17</td><td>2.59</td><td>2.37</td><td>20.0</td><td>120</td><td>1.65</td><td>0.68</td><td>0.53</td><td>1.46</td><td> 9.3</td><td>0.60</td><td>1.62</td><td>840</td></tr>\n",
       "\t<tr><th scope=row>178</th><td>3</td><td>14.13</td><td>4.10</td><td>2.74</td><td>24.5</td><td> 96</td><td>2.05</td><td>0.76</td><td>0.56</td><td>1.35</td><td> 9.2</td><td>0.61</td><td>1.60</td><td>560</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 14\n",
       "\\begin{tabular}{r|llllllllllllll}\n",
       "  & Type & Alcohol & Malic & Ash & Alcalinity & Magnesium & Phenols & Flavanoids & Nonflavanoids & Proanthocyanins & Color & Hue & Dilution & Proline\\\\\n",
       "  & <fct> & <dbl> & <dbl> & <dbl> & <dbl> & <int> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <int>\\\\\n",
       "\\hline\n",
       "\t173 & 3 & 14.16 & 2.51 & 2.48 & 20.0 &  91 & 1.68 & 0.70 & 0.44 & 1.24 &  9.7 & 0.62 & 1.71 & 660\\\\\n",
       "\t174 & 3 & 13.71 & 5.65 & 2.45 & 20.5 &  95 & 1.68 & 0.61 & 0.52 & 1.06 &  7.7 & 0.64 & 1.74 & 740\\\\\n",
       "\t175 & 3 & 13.40 & 3.91 & 2.48 & 23.0 & 102 & 1.80 & 0.75 & 0.43 & 1.41 &  7.3 & 0.70 & 1.56 & 750\\\\\n",
       "\t176 & 3 & 13.27 & 4.28 & 2.26 & 20.0 & 120 & 1.59 & 0.69 & 0.43 & 1.35 & 10.2 & 0.59 & 1.56 & 835\\\\\n",
       "\t177 & 3 & 13.17 & 2.59 & 2.37 & 20.0 & 120 & 1.65 & 0.68 & 0.53 & 1.46 &  9.3 & 0.60 & 1.62 & 840\\\\\n",
       "\t178 & 3 & 14.13 & 4.10 & 2.74 & 24.5 &  96 & 2.05 & 0.76 & 0.56 & 1.35 &  9.2 & 0.61 & 1.60 & 560\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 14\n",
       "\n",
       "| <!--/--> | Type &lt;fct&gt; | Alcohol &lt;dbl&gt; | Malic &lt;dbl&gt; | Ash &lt;dbl&gt; | Alcalinity &lt;dbl&gt; | Magnesium &lt;int&gt; | Phenols &lt;dbl&gt; | Flavanoids &lt;dbl&gt; | Nonflavanoids &lt;dbl&gt; | Proanthocyanins &lt;dbl&gt; | Color &lt;dbl&gt; | Hue &lt;dbl&gt; | Dilution &lt;dbl&gt; | Proline &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 173 | 3 | 14.16 | 2.51 | 2.48 | 20.0 |  91 | 1.68 | 0.70 | 0.44 | 1.24 |  9.7 | 0.62 | 1.71 | 660 |\n",
       "| 174 | 3 | 13.71 | 5.65 | 2.45 | 20.5 |  95 | 1.68 | 0.61 | 0.52 | 1.06 |  7.7 | 0.64 | 1.74 | 740 |\n",
       "| 175 | 3 | 13.40 | 3.91 | 2.48 | 23.0 | 102 | 1.80 | 0.75 | 0.43 | 1.41 |  7.3 | 0.70 | 1.56 | 750 |\n",
       "| 176 | 3 | 13.27 | 4.28 | 2.26 | 20.0 | 120 | 1.59 | 0.69 | 0.43 | 1.35 | 10.2 | 0.59 | 1.56 | 835 |\n",
       "| 177 | 3 | 13.17 | 2.59 | 2.37 | 20.0 | 120 | 1.65 | 0.68 | 0.53 | 1.46 |  9.3 | 0.60 | 1.62 | 840 |\n",
       "| 178 | 3 | 14.13 | 4.10 | 2.74 | 24.5 |  96 | 2.05 | 0.76 | 0.56 | 1.35 |  9.2 | 0.61 | 1.60 | 560 |\n",
       "\n"
      ],
      "text/plain": [
       "    Type Alcohol Malic Ash  Alcalinity Magnesium Phenols Flavanoids\n",
       "173 3    14.16   2.51  2.48 20.0        91       1.68    0.70      \n",
       "174 3    13.71   5.65  2.45 20.5        95       1.68    0.61      \n",
       "175 3    13.40   3.91  2.48 23.0       102       1.80    0.75      \n",
       "176 3    13.27   4.28  2.26 20.0       120       1.59    0.69      \n",
       "177 3    13.17   2.59  2.37 20.0       120       1.65    0.68      \n",
       "178 3    14.13   4.10  2.74 24.5        96       2.05    0.76      \n",
       "    Nonflavanoids Proanthocyanins Color Hue  Dilution Proline\n",
       "173 0.44          1.24             9.7  0.62 1.71     660    \n",
       "174 0.52          1.06             7.7  0.64 1.74     740    \n",
       "175 0.43          1.41             7.3  0.70 1.56     750    \n",
       "176 0.43          1.35            10.2  0.59 1.56     835    \n",
       "177 0.53          1.46             9.3  0.60 1.62     840    \n",
       "178 0.56          1.35             9.2  0.61 1.60     560    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tail(wine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'113'</li><li>'159'</li><li>'21'</li><li>'131'</li><li>'137'</li><li>'133'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '113'\n",
       "\\item '159'\n",
       "\\item '21'\n",
       "\\item '131'\n",
       "\\item '137'\n",
       "\\item '133'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '113'\n",
       "2. '159'\n",
       "3. '21'\n",
       "4. '131'\n",
       "5. '137'\n",
       "6. '133'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"113\" \"159\" \"21\"  \"131\" \"137\" \"133\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'104'</li><li>'144'</li><li>'32'</li><li>'140'</li><li>'28'</li><li>'168'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '104'\n",
       "\\item '144'\n",
       "\\item '32'\n",
       "\\item '140'\n",
       "\\item '28'\n",
       "\\item '168'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '104'\n",
       "2. '144'\n",
       "3. '32'\n",
       "4. '140'\n",
       "5. '28'\n",
       "6. '168'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"104\" \"144\" \"32\"  \"140\" \"28\"  \"168\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Shuffle the data.\n",
    "\n",
    "set.seed(1234)\n",
    "smp <- sample(rownames(wine), nrow(wine), replace=FALSE)\n",
    "wine <- wine[smp,]\n",
    "smp02 <- sample(rownames(wine), nrow(wine), replace=FALSE)\n",
    "wine <- wine[smp02,]\n",
    "head(rownames(wine))\n",
    "tail(rownames(wine))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- wine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  2  3 \n",
       "59 71 48 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The wine samples are from 3 grape varietals.\n",
    "\n",
    "table(wine$Type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to output a confusion matrix and the \n",
    "# accuracy score.\n",
    "\n",
    "get_confusion <- function(preds, df_actual) {\n",
    "    \n",
    "    # df_actual is a one-column dataframe;\n",
    "    # preds is a named vector of predictions;\n",
    "    # preds is of type factor; it is assumed there are\n",
    "    # at least 2 factor levels\n",
    "    \n",
    "    levs <- levels(preds)\n",
    "    n_levs <- length(levs)\n",
    "    if(n_levs== 1) { levs <- c('0', '1') }\n",
    "    n_levs <- max(n_levs, 2)\n",
    "    actual <- as.vector(df_actual[, 1])\n",
    "    names(actual) <- rownames(df_actual)\n",
    "    \n",
    "    datout <- rep(0, n_levs * (n_levs + 1))\n",
    "    dim(datout) <- c(n_levs, n_levs + 1)\n",
    "    datout <- as.data.frame(datout)\n",
    "    colnames(datout) <- c(levs, \"class.error\")\n",
    "    rownames(datout) <- levs\n",
    "    \n",
    "    result <- vector(\"list\", length= 2)\n",
    "    names(result) <- c(\"matrix\",\"acc\")\n",
    "    \n",
    "    # for each factor level, identify the rcd names\n",
    "    # which should be classed as such\n",
    "    for(rowlev in levs) {\n",
    "        actlev_names <- names(actual[actual == rowlev])\n",
    "        # columns are for the predicted values:\n",
    "        for(collev in levs) {\n",
    "            predlev_names <- names(preds[preds == collev])\n",
    "            if(length(predlev_names > 0)) {\n",
    "                datout[rowlev, collev] <- sum(predlev_names %in% actlev_names)\n",
    "            }\n",
    "        }\n",
    "        nonrow_cols <- levs[!(levs %in% rowlev)]\n",
    "        datout[rowlev, \"class.error\"] <- round(sum(as.vector(datout[rowlev, nonrow_cols]))/\n",
    "                                               sum(as.vector(datout[rowlev, levs])), 4)\n",
    "    }\n",
    "    \n",
    "    result$matrix <- datout\n",
    "    mat <- as.matrix(datout[, 1:nrow(datout)])\n",
    "    result[[2]] <- round(sum(diag(mat))/floor(sum(mat)), 4)\n",
    "    \n",
    "    return(result)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following function is from Robert Kabacoff's \"R in Action\", pp.379-380.\n",
    "\n",
    "wssplot <- function(data, title=\"wss plot\", nc=15, seed=1233) {\n",
    "    \n",
    "    # wss[1] is the total sum of squares when there is only\n",
    "    # one cluster.  In R's kmeans help this is called 'totss'.\n",
    "    # Here is another way to compute totss: \n",
    "    # ss <- function(x) sum(scale(x, scale = FALSE)^2)\n",
    "    wss <- (nrow(data) - 1)*sum(apply(data, 2, var))\n",
    "    for(i in 2:nc) {\n",
    "        set.seed(seed)\n",
    "        km_model <- suppressWarnings(kmeans(data, centers=i, iter.max=50,\n",
    "                                            nstart=15))\n",
    "        wss[i] <- sum(km_model$withinss)\n",
    "    }\n",
    "    plot(1:nc, wss, type='b', xlab=\"Number of clusters\",\n",
    "        ylab=\"Within groups sums of squares\",\n",
    "        main= title)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for identifying which cluster each record\n",
    "# belongs to.  \n",
    "\n",
    "getCluster <- function(x, centers) {\n",
    "    \n",
    "    # x is a row of a dataframe; its columns need\n",
    "    # to be in the same order as centers (a matrix'\n",
    "    # constructed from kmeans)\n",
    "    \n",
    "    cl_dist <- apply(centers, 1, function(y) sqrt(sum((x-y)^2)))\n",
    "    return(which.min(cl_dist)[1])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to constrain range of data between 0 and 1.\n",
    "\n",
    "range01 <- function(x) {(x - min(x))/(max(x) - min(x))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to constrain range of data between min_x and max_x.\n",
    "# This function is used to transform validation data.\n",
    "\n",
    "range02 <- function(x, min_x, max_x) {(x - min_x)/(max_x - min_x)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate combination of parameters for gridSearch;\n",
    "# each combination must add to a number ~1.  Returns a dataframe, \n",
    "# each row of which is a valid combination.\n",
    "\n",
    "# I re-factored this ftn using R's expand.grid ftn.  expand.grid\n",
    "# actually takes more time to run.  This is probably due to  \n",
    "# type-checking.  It appears that we also run out of memory more\n",
    "# quickly when using expand.grid.  So at the moment I am \n",
    "# reverting to the deprecated section.\n",
    "\n",
    "generate_combs <- function(arglist, tol=0.0001) {\n",
    "    # arglist is a named list; each name is a column\n",
    "    # name of the dataframe which goes to k-means\n",
    "    \n",
    "    #################################################\n",
    "    # this next section is an alternative to expand.grid\n",
    "    #################################################\n",
    "    # if(FALSE) {\n",
    "    n_args <- length(arglist)\n",
    "  \n",
    "    param_vlens <- rep(NA, n_args)\n",
    "    for(i in 1:n_args) {\n",
    "        param_vlens[i] <- length(arglist[[i]])\n",
    "    }\n",
    "    n_rows <- prod(param_vlens)\n",
    "  \n",
    "    datout <- rep(NA, n_args*n_rows)\n",
    "    dim(datout) <- c(n_rows, n_args)\n",
    "    datout <- as.data.frame(datout)\n",
    "    colnames(datout) <- names(arglist)\n",
    "  \n",
    "    cprod <- 1\n",
    "    for(j in 1:n_args) {\n",
    "        vect <- arglist[[j]]\n",
    "        val <- rep(vect, rep(cprod, length(vect)))\n",
    "        datout[, j] <- rep(val, n_rows/length(val))\n",
    "        cprod <- cprod*length(vect)\n",
    "    }  \n",
    "    # } ## end of 'if(FALSE)'\n",
    "    #################################################\n",
    "    \n",
    "    # datout <- expand.grid(arglist, KEEP.OUT.ATTRS= FALSE)\n",
    "    # colnames(datout) <- names(arglist)\n",
    "    \n",
    "    row_sums <- round(rowSums(datout), 4)\n",
    "    names(row_sums) <- rownames(datout)\n",
    "    tol <- tol\n",
    "    row_sums <- row_sums[which((as.numeric(row_sums) <= (1 + tol)) & (as.numeric(row_sums) >= (1 - tol)))]\n",
    "    datout <- datout[names(row_sums),]\n",
    "    return(datout)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Get best models for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8AAAALQCAMAAABoqemGAAADAFBMVEUAAAABAQECAgIDAwME\nBAQFBQUGBgYHBwcICAgJCQkKCgoLCwsMDAwNDQ0ODg4PDw8QEBARERESEhITExMUFBQVFRUW\nFhYXFxcYGBgZGRkaGhobGxscHBwdHR0eHh4fHx8gICAhISEiIiIjIyMkJCQlJSUmJiYnJyco\nKCgpKSkqKiorKyssLCwtLS0uLi4vLy8wMDAxMTEyMjIzMzM0NDQ1NTU2NjY3Nzc4ODg5OTk6\nOjo7Ozs8PDw9PT0+Pj4/Pz9AQEBBQUFCQkJDQ0NERERFRUVGRkZHR0dISEhJSUlKSkpLS0tM\nTExNTU1OTk5PT09QUFBRUVFSUlJTU1NUVFRVVVVWVlZXV1dYWFhZWVlaWlpbW1tcXFxdXV1e\nXl5fX19gYGBhYWFiYmJjY2NkZGRlZWVmZmZnZ2doaGhpaWlqampra2tsbGxtbW1ubm5vb29w\ncHBxcXFycnJzc3N0dHR1dXV2dnZ3d3d4eHh5eXl6enp7e3t8fHx9fX1+fn5/f3+AgICBgYGC\ngoKDg4OEhISFhYWGhoaHh4eIiIiJiYmKioqLi4uMjIyNjY2Ojo6Pj4+QkJCRkZGSkpKTk5OU\nlJSVlZWWlpaXl5eYmJiZmZmampqbm5ucnJydnZ2enp6fn5+goKChoaGioqKjo6OkpKSlpaWm\npqanp6eoqKipqamqqqqrq6usrKytra2urq6vr6+wsLCxsbGysrKzs7O0tLS1tbW2tra3t7e4\nuLi5ubm6urq7u7u8vLy9vb2+vr6/v7/AwMDBwcHCwsLDw8PExMTFxcXGxsbHx8fIyMjJycnK\nysrLy8vMzMzNzc3Ozs7Pz8/Q0NDR0dHS0tLT09PU1NTV1dXW1tbX19fY2NjZ2dna2trb29vc\n3Nzd3d3e3t7f39/g4ODh4eHi4uLj4+Pk5OTl5eXm5ubn5+fo6Ojp6enq6urr6+vs7Ozt7e3u\n7u7v7+/w8PDx8fHy8vLz8/P09PT19fX29vb39/f4+Pj5+fn6+vr7+/v8/Pz9/f3+/v7////i\nsF19AAAACXBIWXMAABJ0AAASdAHeZh94AAAgAElEQVR4nO3deYBN5f8H8M9sZoYxlhnMGOsY\nmYRkhCxjSbaERBqErzR2Ld9fzSRLom9KixZFpZBvC1LfNoUKqVRClrIkS0IZZBlmf37n3HNn\nnzn3nPs899zzXO/XH/eee++zfGru2733rMQAQFrk7QIAwH0IMIDEEGAAiSHAABJDgAEkhgAD\nSAwBBpAYAgwgMQQYQGIIMIDEEGAAiSHAABJDgAEkhgADSAwBBpAYAgwgMQQYQGIIMIDEEGAA\niSHAABJDgAEkhgADSAwBBpAYAgwgMQQYQGIIMIDEEGAAiSHAABJDgAEkhgADSAwBBpAYAgwg\nMQQYQGIIMIDEEGAAiSHAABJDgAEkhgADSAwBBpAYAiy9hURhZvtkz4oNqvSm0EE/I6I0s3UA\nLwRYemVmLbdv376byu/znJI2es3soLrKCrCLKoAfAiy9MrOWo8TpnfL7dCeqPnGz2UF1lRVg\nF1UAPwRYeu4E+GqiKbqD5uXk5JgrAwH2CgRYemUFeP9mJTqzt1wor0880TTBZZQRYFdVAD8E\n2Ls6E/VV7mYr7/STjH2n3H3D8lb3jA2J7b4sW21Q7IFmDFGXi/fGhFwzO0N9WBDgrKf7NQy/\n4e6dyuIgcthS2KnIi/mvPqJTg3PQR4jicp9qGlL/1l+1tjvualWp0e3fFPtvODA4skb/9/MD\nnPV6l/rBdds/d6FoFUWeBKEQYO96XPkxmsdYX+V9/hFj84mq5uT119731Ep5uxd74KQEuGNH\nx5Mt9rHCAO9sobUMmplXOsBFXywZ4DJqKBLgRkmOxsE/q02fqaB1fTCv8D/hq+qOpwZrAc5o\n5yy4+YXCKoo+CUIhwN61XXlX72WsBjm+0ypZGexYQ3zVwHZ+RKNY8QdOSoD9yK9BoPJSd1YQ\n4EuxyuN61wcrt6+X+vVZ/MVfN9cjGrH5aPk1FAmwMlm0OlVP5eHnyn37f12v3D5VMPSpysrD\nqDBHPpUApyp38Z1rKbczCqso9iSIhAB7V16UGqnf1Uj2YEyJ2WLWm+hO5oiQ8rlY7IHTGPWz\n9zA720O5/64ga9OI/Bczdrw1UeSZkgEu/mKJ38Bl1FA0wLeeYmlKZsOVPDbVuimjhZ3O730f\nUaUPWXaKM8BXE01XnlXq7lUY4GJPgkgIsJeNJBrD3iK6marm/a2834+xBKKYl4+ySxs2bMgu\n/sBJDfBPyv3JUKLZBVlTMjlUfXWX8mm9umSAi79YciVW6RqKBLiC+q33TUc6dyv/DJxVHp1X\nPpHfzu9c2fmxep2jSd4777xzSmmRSNS6IMDFnwSREGAve5uoKbuHopYS7ftI+WRlbLrj2+hV\n41elsxIPnJQA13Us3Oj4eNaylqmEapXj2auIHisR4BIvlgxw6RqKBDhWbbHOsYJrFRWa6ex7\nTFneoS486VyJlb350cHXqt/VWxf5Il/0SRAJAfayNH/yO9OOBu4lWqZ8NX1QSdtUba0Qhb9a\n4oGTEuC2joURpH7n1bL2u/Z9WtGN6K4SAS7xYskAl66h6FpotcV6R4CfLhLgyc6+XyjLp9SF\nlVqAtytfs/3ihvQuFuBiT4JICLC3tSV6P5ieyqtCk7oTfaU+lb0x9VrH2qOdJR84KAGu71hQ\nfgRPKPoJ/J7j2Sbq+uXSn8BFXiy1Hbh0DWUGeAVR1c1OB51dv1decVT2uiPAGcpP6DtOMvZQ\n0QAXfxJEQoC9bSbRTeqW1+6UUIXCstiF3bt3K08fVzfLLij2IL+HuhZa/dZ6Kozo+YKsKdEc\nrr66x59oZcnfwMVfLBXgkjWUE+Cfld/AF9WHf588mf+V/ozyyix14TZHgNU872eObVKFAS7+\nJIiEAHubuuMEVchgU9X7/oztU+7WKs//pfxk/LTYg/we6kqs646xc8o30tDC9U3Kx5v/UsZO\nXK98TP7tiM7iwkmKv1gqwCVrKCfAWQ2J7lcevaGM9kt+38ZKy89Y3nPaWmj1x/ISxj7yKwjw\nYlbiSRAJAfa2XPVHbjvGPlATsFB5Io4oIHHozeFENc8Xf+Dk2A7s31jdpyKFFWQtvYHyuFH7\nUOVW/blcVfmePen3/C4lXiwZ4FI1lB1g9p5y1/JfrZWP8bsL+i5U+9SpRlqATyqv0bXNlahS\ns4IqSjwJAiHAXjeEHJ9rx9UEHFIe/xrhXE8UsrHEAyclwO3bOp4crH6Rzd8Ta/s1WsugaeoW\n49vVxcI9sYq/WGpf6JI1lBNgNi1AG+bOwiMdMjprT92ircS6z/EgNokocFdBFcWfBIEQYK9T\nvpA6fpfWIYp3PPHP/MTY0MhW9/5Z6oFG3Rf6/KTo4KbPOsJYsC905pN9G1Rue5djn0d2amR0\naPyewk7FXiwV4FI1lBNg9s2wZqGNbyt+jO97tzeM7P3WGi3Auc+3qNTq/nP/Ux7dW1BF8SdB\nIARYPmqAvV0D2AQCLB8EGAogwPJBgKEAAiwfBBgKIMDyeXnQoJnergFsAgEGkBgCDCAxBBhA\nYggwgMQQYACJIcAAEkOAASSGAANIDAEGkBgCDCAxBBhAYggwgMQQYACJIcAAEkOAASSGAANI\nDAEGkBgCDCAxBBhAYggwgMQQYACJIcAAEkOAASSGAANIDAEGkBgCDCAxBBhAYggwgMQQYACJ\nIcAAEkOAASSGAANIDAEGkBgCDCAxCwK8YysAGLDDfLo8H+AfCQAM+dF0vDwf4G8o0+NzAPiA\nTPrGdB8EGMAmEGAAiSHAABJDgAEkhgADSAwBBpAYAgwgMQQYQGIIMIDEEGAAiSHAABKTMcCn\nt//j8QoApCBfgN9qTEQtP/N4DQASkC7AcyvM+Pnc1ikBb3q8CAD7ky3A+4NWOO6fDk/zeBUA\ntidbgGe10u5zol73eBUAtidbgIeNcS70SvF4FQC2J1uAR410LnSb7vEqAGxPtgA/1yDbcX++\n8nserwLA9mQL8KmqD6t3uf9qcNnjVQDYnmwBZh+H9nhlzYJ2Vb/3eBEA9iddgNkvd8YFNx17\nxOM1AEhAvgADQAEEGEBiCDCAxBBgAIkhwAASQ4ABJCZngH+4xeMlAMhAzgBv9k/3eA0AEpAz\nwGm03eM1AEhAzgCzyLc9XgOABCQNcMeZHq8BQAKSBnjMHR6vAUACkgZ43nUerwFAApIG+MOK\nuR4vAsD+JA3wfjrs8SIA7E/SAOcEf+7xIgDsT9IAs6bPebwIAPuTNcADJ3i8CAD7kzXAU7t5\nvAgA+5M1wEtre7wIAPuTNcDf0zmPVwFge7IG+Bz94PEqAGxP1gCz6GUerwLA9qQNcNeHPV4F\ngO1JG+Dxt3m8CgDbkzbA85t5vAoA25M2wGsqZHu8DAC7szTAr31ksKGBAB+iA+6WAeAzLA0w\n0YC/DTU0EODcikb/NQDwXdYGuH79mu8baWjkvNAtn3K3DACfYW2Au5wfS523uG5oJMBD7na3\nDACfYXGAGVsbRwPWuTqdhpEAz+zkbhkAPsPyALOs5yOp3vRvdBNqJMBv1XC3DACfYX2AGTv3\nbDxRSKJOQyMB3kZp7tYB4Cu8EWDFxnuv1hvFSIDT/c1XDuBjvBRgxVGdhoauTlhvsbt1APgK\n7wVYj6EA93jQ3ToAfIWlAT55xmBDQwGe0s/dOgB8hfX7Qp87dtzlSdkNBXjBVVx1APgAiwO8\na0QUEQXEJG3WbWYowF8EGmgE4NOsDfAkP4pu26dPuzpEY/TaGQrwMfrF7UIAfIOlAV5APbdp\nS7uH0NM6DQ0FmIWvdrcQAB9haYDbNyk4hjevUwedhsYCfP3j7hYC4CMsDXD4yMLlqVV0GhoL\n8PBR7hYC4COs/QSOzylY7sr/CTy7nbuFAPgIi38D996pLe0bSk/qNDQW4JVV3S0EwEdYuxZ6\nHFHdjv36JzYkGpWn085YgHfRCbcrAfAJFm8H3p4UqW4Hjk7aoNvMWIAzA/VHAfB51u+Jdfbo\nCTF7YjHWaCFXJQDSk/a0sqqb7/N0IQD25pUArx/kooHBAP+7N28lAHLzSoBfczWCwQC/0pC3\nEgC5SR3gTf6XeEsBkJrUAf6LfuYtBUBqlgd4TWpqam9SblJ1GhkMMIt4l6cUAOlZHuB5cXFx\nNUi5idNpZDTA7WfxlAIgPam/QrPRQ3lLAZCa3AF+IoG3FACpyR3gDyrp7VEN4PPkDvBe0ju7\nNIDPk3pXSpZdYZ2HKwGwNS8EOH3nd66aGA0wi3+BrxYAuVke4MMDg4jYjGHHSr3yx8ECK40G\neMAknloAZGd1gI/XpfZdic2jmOMlXvmNiko3Nlxqd45aAKRndYAn0jK2XBlgScCEki/9WfgJ\nPIcuGBvujToctQBIz+oA1+/KHAFm/RrrtFpoNMDf+Z3nKAZAdlYHuNJYZ4DHV9JpZTjAZ2kr\nRzEAsrM6wG3bOAPcSm8nKsMBZrWWcxQDIDurAzyHZueqAZ5DD+m0Mh7gztM5igGQndUBzkmk\nuBtoQgI1v6zTyniAxw7mKAZAdpZvB86cX4+IIqbprnwyHuBnWvAUAyA5b+xKeWHPaRctjAf4\nk5Ac140AfJU3Apy7f0+2fgvjAT5IBzmrAZCYpQGetli5yX4ijCg4+R+9hsYDnBv6ibvVAMjP\n0gBTF+VmMlUbNLYdNc3QaWg8wKzFM+5WAyA/ywO8269NmrK4mGboNDQR4MFj3a0GQH6WB/gV\n+tax3OF6nYYmAjy9s7vVAMjP8gDPcGZzXGWdhiYCvLyWu9UAyM/yAL9Jux3LA5rrNDQR4K10\nxt1yAKRnbYBrz175Q4071MUfgkbrNDQR4It+Ls/vAeCzLA1wXT/HwfpfMpYaGqF3OjoTAWZ1\n3nC3HADpWbsjx6Wdqx4f3XETY/F1N+i1MxPg7nrXaAHwbV46K+WeXN2XzQR40gDeYgCkZc/T\nypoJ8AvxHiwEwN7kD/C6oCwPVgJga94K8NmWLXVeNRPgo7SXvxwAOXkrwGmkN4qZAOeFfcBf\nDoCcvBXgrPXrdV41E2CW8AR3NQCSkv83MBuqt0sIgE8TE+C8IwYvhWKQqQDPai90bgCJcAd4\nw+hD7FgzCp4u8kq9pgL8bnWBMwNIhTfAa/xpN0uim1rT2+KKMhfgn+kvgVMDyIQ3wJ0qrs5L\nD+3CMmt1EleUuQBfDtgkcGoAmfAGuHofxtbTYsaG1HTZ74Wqxei0NBVg1vAVE40BfAlvgKsM\nVY/R38/YGL1rHWkOTAmmys0K6LQ0F+De/zbRGMCX8Aa4Te3MrPhGjGXFNTXQ8zPqa2gGcwG+\n72YTjQF8CW+Al1KTBjSbfZVIs4x0vcoTAV7YyERjAF/CvRnpscjAgZfYNOpvKHLDbjU0g7kA\nbwjQu84SgA8TsCOHepWFA2Kvj2AuwCdol9DZAaQhIMDpO4WflcpcgFm1laILAJADd4APDwwi\nYjOGHRNWEjMd4HazRU4OIA/eAB+vS+27EptHMcfFFWU2wKOGC5wbQCK8AZ5Iy9hy5YklARPE\nFWU2wI/rXeUBwIfxBrh+V+YIMOvXWFhNpgO8urLIIykA5MEb4EpjnQEe73pPLONMBvgXEvoL\nHEAavAFu28YZ4FYJwmoyHeCsoC8ETg4gD94Az6HZuWqA59BD4ooyG2B21QKBkwPIgzfAOYkU\ndwNNSKDmIveGMhvgflMETg4gD+7twJnz6xFRxLTzwkpi5gP8YA+RswNIgzPAFxd+y9iFPacF\nVqQyG+DF9QQXACAH7rXQw8TVUshsgL/xM9cewEfwBnhCjTRxxRQwG+DTtM0DVQDYHm+As8c2\nf/fA+YsqcUWZDjCr8ZbA2QGkwRvgqKgAchJXlPkAd5opcHYAafAGeFQhcUWZD/DdQwTODiAN\nH7i0iuopvWsdAvgsYQH++G7uWgqZDvBHobkCpweQBXeA/1w2X/VMiyrCanIjwAfokMDpAWTB\nG+Ad1fLXYU0UV5T5AOeErBE4PYAseAM8MHDBp41v2bI2sbu4mtwIMGs2X+T8AJLgDXDMLYzN\nbcLY6Yhl4opyI8C3jRc4PYAseAMcMpmxD4JyGEvuLKwmdwL8cFeB0wPIgjfA8YPU63vuYmyq\nV1disWXRAqcHkAVvgIcHf5KbETKVsXYiDwgyH+Af6KzA+QEkwRvgw2G0nI3xu+1GEvkj1HyA\nz/t9L3B+AElwbwfeM3kjS+8ZSL3OCKvJnQCz2ksFzg8gCUF7Yv0j9pB+NwLcbarQCgCk4CP7\nQjM2YaAnCgGwN+6VWIXEFeVOgJ8zcoFxAB/DG+D8HSmpcpy4otwJ8OcVsgUWACAH3gBnOKSt\n7xD6ibii3AnwYdovsAAAOYj6DZzeJCKLv5p8bgQ4L+xDcfMDSELYSqwH6Ch3MQXcCDC7bp64\n+QEkISzA9wQLPKTenQDfMUbc/ACSEBTgvI1VWgioJp87AZ7ZUWABAHLgDXCYJphoibii3Arw\n2xECCwCQA2+A+zqN+EBcTe4FeDudElkCgAx8Zk8sdsl/swcqAbA13wkwq/+a+EIA7I03wHWK\nEbUeya0A93xA0OwA0uAN8LgY8qudUMePGnRU3CqoKrcCfM8tgmYHkAZvgL/27/GLcre3Z8xh\nYTW5GeCXGgusAEAKvAG+peElx/2l2EGCKlK5FeAvAzMElgAgA94A1xrpXBhdR0Q5Tm4F+E/a\nI7AEABnwBrh+/ulcu4s8LaRbAWZV3xNYAoAMeAN8h9/7jvv/+fcTVJHKvQC3eUxgCQAy4D4r\nZYT/7YvXvH67f+jP4opyM8AjRggsAUAG3Dty7OjmOCFHs/XCSmLuBvixtiJrAJCAgD2xdq98\netl3Yi/P616AV4ULLQLA/sTsSpl3JFNEMQXcC/BuOi60CgDb4w7whtGH2LFmFDw9T1hN7gY4\nM/ArgTUASIA3wGv8aTdLopta09viinIzwCzuZYE1AEiAN8CdKq7OSw/twjJrdRJXlLsB7nuv\nwBoAJMAb4Op9GFtPixkbUlNcUe4G+P96CawBQAK8Aa4ylLEZ6imZx1QSV5S7AX61gcAaACTA\nG+A2tTOz4hsxlhUn8tImbgb4a/90gUUA2B9vgJdSkwY0m32VSLPEFeVugE/RDoFFANgf92ak\nxyIDB15i06i/W5Erh5sBZhHvCCwCwP4E7MihXlTswEEx5Ti5G+AOjwgtA8DuLD2p3WsfGWzo\nboDvSnKrG4CsLA0w0YC/DTV0N8BPtnKrG4CsrA1w/fo13zfS0N0A/6+SyB06AWzP2gB3OT+W\nOm9x3dDdAO+jI271A5CUxQFmbG0cDVjn6uBDdwOcHfy5W/0AJGV5gFnW85FUb/o3uscfuhtg\n1vR59/oByIknwAfSGNt7zkzHLo67c8/GE4Uk6jR0O8C3TnSvH4CceAIc+rCybOaqos4AKzbe\ne7Xe57jbAX7oRvf6AciJJ8B16zy1kEYuzGegY5ciD47qNHQ7wEti3OsHICeeAL8RSEUZ6NjF\ndRsHtwO8hcx8pQeQHddKrBObNlDqhnyuO548Y3AGtwP8D/3oXkcAKfGuhR6+yWzvc8eOuzyF\npdsBZlFvutkRQEYiNiNd3HfeaNddI6KUL9sBMUmbdZu5H+Au09zsCCAj7gCfnxWtRDJq1kUj\nPSf5UXTbPn3a1SEao9fO/QCPE3mRRAC74w3wpWYUNXDioBi61sC1PRdQz23a0u4h9LROQ/cD\n/GwzNzsCyIg3wA9SqprczIfpIdcd2zfJzl/M69RBp6H7AV4TnONmTwAJ8Qa4VYJzoU1CWU2L\nCx9ZuDy1ik5D9wP8O/3mZk8ACfEGuFKyc2F8mOuO7eMLPx67euYTOLfix272BJAQb4Cbd3Qu\ndG7huuMC6r1TW9o3lJ7Uaeh+gNm1er+tAXwMb4An0nzHMfQv0mQDPccR1e3Yr39iQ6JReofe\ncwT49mTXbQB8BW+Az8VSs0lzJreghob2YdyeFKluB45O0t9viyPAM/SOcgLwMdzbgU+MD1Ii\nGTTW8JU9zx494cE9sdh/RV7iBcDmBOyJlXVgw/4sQeU4cQT4J0oTWQmArVl6Ro58613tLsUR\n4It+37rbFUA6Xgnwa65G4Agwq/u6210BZON7Ab4pxe2uALLxvQBP7u92VwDZWB7gNampqb1J\nuUnVacQT4BebuN0VQDaWB3heXFxcDVJu4nQa8QR4fZDgVeIA9iUmwHlHdE/zXJJHv0L/Qb+6\n3RdAMtwB3jD6EDvWjIKnm7gqkUcDnBdu6PJLAL6AN8Br/Gk3S6KbWtPbxgfwaIBZ68fd7wsg\nF94Ad6q4Oi89tAvLrNXJ+ACeDfDwUe73BZALb4Cr92FsPS1mbIjIfZC5Ajz7BnGFANgbb4Cr\nDGVsBu1nbEwlo93Td37nqglXgFdUdb8vgFx4A9ymdmZWfCPGsuKaGut8eGAQEZsx7JheI64A\n76ST7ncGkApvgJdSkwY0m32VSLMM9T1el9p3JTaPYkoef3isbUKBejwBzgjY6H5nAKlwb0Z6\nLDJw4CU2jfobi9xEWsaWKwMsCZhQ4pWM1xYVGMYTYBa7iKMzgEwE7Mihnir2wEGDfet3ZY4A\ns36NdVpxfYVmfe7n6AwgE6t3paw01hng8XorvfgCfH8fjs4AMuEOcPYvm50M9W3bxhngVnrn\nkeYL8KJYjs4AMuEN8I4GJq4PrJhDs3PVAM/RvZIDX4A3+l/m6A0gEd4Ad6bec+drDPXNSaS4\nG2hCAjXXCxlfgP+inRy9ASTCG+DKZn9vZs6vp3xaR0zTvSIpX4BZ9RU8vQHkwRvgRlPNz3lh\nz2kXLTgDfMOjPL0B5MEb4NHXmj18/tyx4548L7TqX8N4egPIgzfAf8V3/uiXvQ5Guu4aEaVe\nmSEmSX+dNWeA57bm6Q0gD94An2xpZi30JD+KbtunT7s6RGP02nEG+P0wE2cXAJAYb4AHUL1x\nqRrXHRdQz23a0u4hpHcVQc4A/0p/8HQHkAZvgCO7mejYvkl2/mJeJ89cH9ghK2gdT3cAaXAG\nOJ0eNtExfGTh8tQqOg05A8ziX+TqDiAL3k/guBtcrlIu1D4+p2C5qwc/gVl/IxcrBpAfb4C/\nq3b7tlNpDq47LqDezn2k9g2lJ3Ua8gY45Sau7gCy4A1w1WAza6HHEdXt2K9/YkOiUXorinkD\n/Hpdru4AsuAN8JhCRrpuT4pUtwNHJ23QbcYb4G/9+PoDSML6i5udPXrC03tisbP0E1d/AEl4\n5eqELvEGmNX8r5hCAOyNN8DDC4krij/AiTPEFAJgb7wBLliFVVnvaoOlnW3ZUudV7gAn387X\nH0AOvAHOcEhb3yH0E1NjpOmuteYO8NMt+PoDyEHUb+D0JhGmjivMWr9e51XuAH8SkuO6EYD0\nhK3EeoCOchdTgDvAv9HvYioBsDVhAb4n2MQ+la5wBzg35FMxlQDYmqAA522sIvJXJ3eAWfNn\nhRQCYG+8AQ7TBBMtEVeUgAAPGiekEAB74w1wX6cRH4irSUSAp3URUgiAvVm5J9YLVYvRackf\n4DejOAcAkIGYAOcdyTTQ78CUYKrcrIBOS/4A/0hnOEcAkAB3gDeMPsSONaPg6UbOI/cZ9TU0\nA3+AL/ht4RwBQAK8AV7jT7tZEt3Umt420vUqqwLMYkSuVAOwKd4Ad6q4Oi89tAvLrNXJSNdh\ntxqaQUCAb9S7eBqAj+ANcPU+jK2nxYwNqSmuKBEBnmjsnwoAqfEGuMpQxmbQfsbG6F2w2ywB\nAX7+ahGFANgbb4Db1M7Mim/EWFZcU3FFiQjw2iCzF20CkA9vgJdSkwY0m32VSLPEFSUiwEdo\nn4hKAGyNezPSY5GBAy+xadRf5GnkBAQ4L+x/IioBsDUBO3Kol0s5cFBMOU4CAsxaPSGgEAB7\n89GT2imGjhZQCIC9+W6AZ+lduwXAN/hugN+pLqAQAHvz3QDvoL8FVAJga74b4Ev+XwuoBMDW\nfDfArMGr/GMA2JuVxwMbJyTAvf6PfwwAe7P2eGCjhAT4XmOHLgJIzOLjgQ0SEuCXzV3sBUBC\nFh8PbJCQAH8VkME/CICt+ezxwIydUL4bAPg2nz0eWFF1lYBBAOzMZ48HVrSdI2AQADvz2eOB\nFSPvFDAIgJ357PHAiv+0ETAIgJ357vHAjL0XLnLbNIANCQjw3o8WvCd4fa+YAO+hPwWMAmBj\n3AHe2o1UHX8QVhITFeDMwC8FjAJgY7wB/q0a3fzC6pcG+FX5TVxRggLMrnpJxCgA9sUb4MF+\n7zjuV/kNFlSRSlCAb7lHxCgA9sUb4Lr51+HtVldIPRpBAX6gp4hRAOyLM8CZNNK5NDpaSD0a\nQQF+rb6IUQDsizPAuTViLzsWMuJEXotIUIA3+6WLGAbAtni/Qi+m3vuVuwN9qttwJdZp2i5i\nGADb4g3wmFjyb9CuoT/V6aIYKKgqQQFmkSIPUgawH94ARxYj6oAGUQHuOFPIMAB25cMntVOM\nuUPIMAB25dsBnnedkGEA7Io3wMMLiStKWIA/qpgrZBwAm+INMOWrLPIUcqICvJ8OCxkHwKZ4\nA5zhkLa+Q+gn4ooSFuCc4M+EjANgU6J+A6c3icjiryafqACza54TMw6APQlbifUAHeUupoCw\nAA+cIGYcAHsSFuB7ggWuLxIW4KndxIwDYE+CApy3sUoLAdXkExbgpbXFjANgT7wBDtMEEy0R\nV5S4AH9P58QMBGBLvAHu6zTiA3E1CQzwORJ6qh8Am/HtPbEYi14maCAAOxIR4Iv7zosppoC4\nAHd9WNBAAHbEHeDzs6KJKGrWRWElMZEBHn+boIEA7Ig3wJeaUdTAiYNi6FqR1/IUF+D51wga\nCMCOeAP8IKWqyc18mB4SVpPIAH9WIVvQSAA2xBvgVgnOhTYJZTV1k7gAH6IDgkYCsCHeAFdK\ndi6MDxNSj0ZcgHMrfiRoJAAb4g1w847Ohc623BOLsZZPiRoJwH54AzyR5jsuAfgiTRZVEhMa\n4CF3ixoJwH54A3wulppNmjO5BTUUuc+iwADP7CRqJAD74d4OfGJ8EBEFjT0urCQmNMBv1RA1\nEoD9CNgTK+vAhv0CD+ZXCbScDCoAACAASURBVAzwNkoTNRSA7XAG+OLCbwUWU0BggNP9zf8H\nAsiCezPSMHG1FBIYYFZvsbChAOyGN8ATanjiG6rIAPd4UNhQAHbDG+Dssc3fPXD+okpcUUID\nPKWfsKEA7IY3wFFRAflnhhZXlNAAL7hK2FAAdsMb4FGFxBUlNMBfBGYKGwvAZnz9jByMHaNf\nhI0FYDNeCfBfP7n4wSwywCx8tbixAOyF+wLf+SamvHLKZc/DI19m7MeWRP63/KHXTmiAr/+P\nuLEA7IX7At+hBZc3o1BXG2wORNCzbH+oX49xnSn6jE5DoQG+c6S4sQDshTfApxo2fP6Hw1sX\nxPbe8ekAWq7fcZDfq3nsNv91yuI7NEmnodAAz2knbiwAe+FeCx11wnF/Mno6y+vm4kImtdoq\nN3V6O5a7652sSmiAV1YVNxaAvfAGuN5I58LopozNdXHkT+Whyk3NuxzLd4frNBQa4F10Qtxg\nALbCHeC+zoUBtRh7IEK/Y9fa5xjr20I9A0Bus0SdhkIDnBm4QdxgALbCG+CRgdo1VT4OGsqO\nNu6i33FjhXbfse1hD+WwyxPpGZ2GQgPMGi0UOBiAnXCvxIqlDv/3xAOJVOevXRX81rro+XYg\n1e0US5Gtw0l3xy2xAb75PoGDAdgJ944cxycFE5H/6JPsx/auTwB55P7a6gankF6f6zYTG+B/\n9xY4GICdCNgTK+PXz3eYOBTpwh+/n3R1LXCxAX6locDBAOzE+l0pzx077iq/ggO8yf+SwNEA\nbMTiAO8aEaV8gw6ISdqs20xsgP+mnwWOBmAj1gZ4kh9Ft+3Tp10dojF67cQGmEW8K3I0APuw\nNMALqOc2bWn3EHpap6HgALefJXI0APuwNMDtmxRcKjCvUwedhoIDPHqoyNEA7MPSAIePLFye\nWkWnoeAAPyHyyokANmLtJ3B8TsFyVws/gT+olCdyOADb4A7wyju6O7nuuIB679SW9g2lJ3Ua\nCg7wXjoqcjgA2+AN8GtEYZEaAz3HEdXt2K9/YkOiUXofioIDnF3B1T6eAHLiDfA14fpbdEvY\nnhSpbgeOTtI/QEhwgNnVLwgdDsAuOAOcV8H0ZYHPHj1h8Z5YjA3QO/0HgLw4A5zh55EjfUQH\nONXAD3QACfF+he7c4B/zk64f5KKB6AC/UUfocAB2wRvgI82bv/tbmoPxAV5ztSFKdIC/8zsv\ndDwAm+ANcNVKZP7aSJYH+CxtFToegE0IO7H7GN2jE4qzPMCslosT3gLIyfLjgdekpqb2JuUm\nVaeR8AB3ni52PAB7sDzA8+Li4mqQchOn00h4gMcOFjsegD3wBJjoGCu8sIqdfwOzZ5qLHQ/A\nHngCPGBAGhtUyPgA1gf405Ac140ApOOVy4taH+CDdFDsgAC2cIUEODf0E7EDAtgCd4BXDe/l\nJKwmDwSYtdC7EASArHgD/CpRhTCN0e7pO79z1UR8gAePFTwggB3wBrhp2EZzZ7s4PDCIiM0Y\ndqzkCxcfSSnQU3iAp3cWPCCAHfAGuOIQc32P16X2XYnNo5jjJV450bt7gatJ9L7Ln90keEAA\nO+AN8HUmDyecSMvYcmWAJQETdFqJ/woN4JN4A/xQQ3OHE9bvyhwBZv0a67RCgAEM4QnwRcWp\nLi1WHb6gLhm7vlmlsc4Aj6+k0woBBjCEb1fKYgz1bdvGGeBWeudqRoABDOEJ8JjiDPWdQ7Nz\n1QDPoYd0WiHAAIbw/gZOy3AupJ8x1DcnkeJuoAkJ1PyyTisEGMAQ3gDTEufCoxEGJ5xfT/m6\nHTFNdzuR+AB/mdSsUf/luEAD+BiuAL+/fDklL3d4vbXBACsu7DntooXwAE8NTHrx1fFhA7LE\nDgvgZVwBblB0HdYIg73PHTtu+XmhV2uXZthba4bQYQG8jSvAaz/4gKZ8oFmr95u2wK4RUeqV\nGWKS9K/nIDrAic4Tu79WPVu/IYBceH8Dd//cTM9JfhTdtk+fdnWIdFdaiw5w/sGEx2iv0HEB\nvMzS44EXUM9t2tLuIfS0TkPBAc4N+EpbOEs7RI4L4G2WnhOrfZOCb7B5nSy8PjCLdV7cbFPA\nWaHjAniZpefECh9ZuDy1ik5D0QGe2uicepfT42ahwwJ4m6VfodvHF55arquVn8DnmrZcn561\n9eaIfUKHBfA2ngA/9aPJUz0uoN47taV9Q+lJnYbCtwOfGhbgH0RdsQoLfAzfb+DKvZ/YYmbD\nzDiiuh379U9sSDRKb68oD+xKeX7Ll6dEjwngbTwBvusafyKq1OOxbwzv4LQ9KVLdDhydtEG3\nGfaFBjCE7zfwP2sf7V1dSWTFGx/dmKHTo6izR09YvicWgI/iX4mVt3fJuGsDiEJElcQ8G+AD\nU7E3FvgMIWuh/357sL+ZayO55MkAH6oxEgclga/gDnDGFymt/IgaT/zA1BhnW7bUedWjX6F3\nVJ3oucEBLMUX4F1P9wolqjZo0SGzY6TpfmJ79jfwN5Ue8eDoABbiCfCdUUSBnR7d4s6F/7LW\nr9d51cMrsT6voLcjNoA8+LYDB9/nmW2rnl4L/d+A1zw6PoBFuD6Bo4kq9py3zew6odz9e1ys\nCPb4ZqSXAlZ6dgIAS/D9Bt7z3C2ViSIGL/rNUMdpi5Wb7CfClI/uZN3zwXt+O/BjFT7z8AwA\nFuBeC529+ZGOQUT173rbQMcuys1kqjZobDtqqrfjhwU7cjxQUf+kIAAyELId+MLHQwxtB1YD\nvNuvTZqyuJj0Tk9lQYDz7q663dNzAHgaf4Bzti0YFktE4QY6KgF+hb51LHe4XqehFbtS5gyp\n/bvHJwHwLL4An/poatdKSnir9H1qq4GNSWqAZzizOa6yTkNL9oXO6t2o5CVOASTDE+CRV6ln\n0ql6y9M/uTw6wdlRCfCbtNuxPKC5TkNrDmZI79TM1QmqAeyNbztwtX7PbDMYXkeH2rNX/lDj\nDnXxh6DROg0tOhrpn1ZtcNQTSI0nwM9uNxFeVV0/x9nvvmQsNTTiqE5Dqw4n/LtJN0Onswaw\nKUvPicUu7Vz1+OiOmxiLr6t7RL9lxwMfrd8fBxeCxKwNcIE9+p/d1h3Qv7/WnSa/RgDYiJcC\n7IKFZ+TYUXWSVVMBCHfFB5h9U+lRy+YCEAwBZh8G4eBCkBUCrB5cuNjC2QAEQoAVC3BwIUgK\nAVbNrmDqKqkAdoEAOzxQyfz/BgDvQ4Ad8u6O2GPtjAAiIMCanNtxcCFICAF2ysTBhSAhBDhf\nekccXAjSQYAL/HNdWxxcCJJBgAv91eRGo5dYBLAHBLiIo/UG4OBCkAoCXNS+WiNw5UKQCQJc\nzPaqk70zMYBbEODivgyZ7aWZAdyAAJfwYeAz3poawDQEuKTlAa97bW4AkxDgUhYErPLe5ACm\nIMClPYqDC0EWCHAZ/q/yj96cHsAwBLgMeWMicXAhSAEBLkvOwDpnvVoAgDEIcJky5l3ybgEA\nhiDAABJDgAEkhgDryfh+yUd/eLsIgPIhwDpWRvvXr+w3BCfqANtCgMu3MnDWOca+bdYmy9uV\nAJQDAS5Xdu1HHPd/Rb7s5UoAyoMAl2tToHNb8H09vFsIQLkQ4HL9t7Zz4eV4r9YBUD4EuFwf\nhuVqC49f791CAMqFAJfr7wDtoKS8dvd6uRKA8iDA5bu74W/Kbd70UFx0BewKAS7fpd4Vk+bc\n36Lyx94uBKA8CLCOvJVj2veb4dwVK2PJee9WA1AaAmzUX/Ui5l70dhEAxSHAhmUuiomci6MM\nwVYQYBMyF0XXnHvZ21UAFEKATbk4v2bd+bgCGtgGAmzShblV6y/CJdDAJhBg087PrRK/NMfb\nVQCoEGA3pKVUbLoClzEEG0CA3fJ3SmhzRBi8DwF20x9Tgtt+6O0i4IqHALvtSHJg+y+8XQRc\n4RBgDoeSAzps8HYRcEVDgLn8cqd/d1xHCbwHAea0a7Bf923eLgKuWAgwt58H+/f92dtFwBUK\nARbg2+7+g/d7uwi4IiHAQnzdNejO37xdBFyBEGBB1lxfYYu3a4ArDwIsSt5G5+H+h6a0jen6\nCK4vDFZAgEVbW7nd42/OaFQf36jBAgiwYH9XfUDdR/pSr1a53i4FrgAIsGDzGmkHCx8P/Mq7\nhcAVwfoAnzt23OVnk8QBvn2scyHhSa/WAVcGiwO8a0QUEQXEJG3WbSZxgPvd51zo9KhX64Ar\ng7UBnuRH0W379GlXh2iMXjuJA3zvTdp9TuR/vVsIXBEsDfAC6uncbXj3EHpap6HEAd7i/7Xj\n/rnwM477pZU63rt8H479B8+wNMDtmxScDS6vUwedhhIHmE2osugvdujhwNe1h5f+N61XJFXp\nlrLykFfLAt9kaYDDRxYuT62i01DmAOc+WY2CqcGqos/9+eHMvhFUpcOUpbhOGghl7SdwfOHJ\nHLv66icwY1l71v5exndmJcXdK1F035kf/mV9TeCjLP4N3HuntrRvKOltZZE7wDpydi+d0iHU\nkeK04q98MqhJo/7veqcqkJe1a6HHEdXt2K9/YkOiUXrrdXw2wA7ZaoqDlRTP/Trd+VTe5KCR\nC18dW/EOnG8aTLF4O/D2pEh1O3B0kv6ppHw7wA7p38wfHu8f2F97tLSiY8P4rognvFkTyMf6\nPbHOHj3hy3timXLuy8+1hese0u6fi8EGJzADu1LaQZbfRm1hLx3zbiUgGexKaQcXyHlqyz8I\nRyGCGdiV0hZqOXf7+CREu4L47OuHPPTK+t9xFURwAbtS2sI9TR2n88jqMER7vPPxu29sGEhB\njW5Knrti65nyuuW8fVf7Wx89aU2NYEfYldIW0uKu/zI945tuUUeKPJl9cN3SucndY4lCYrur\nQb5Uotf5rmHD5ky5uhou8HLlwq6U9nDydn//QOpd5p6Wlw+uW5QyOCGUqFrC4JRF6w7mr6ke\n2kTNe8594cetKxTsBbtS2sW5LV+X+1XZIefQF69NvaNNJFH4GscTh/20VYG5zad5vDqwKexK\nKZ1zOz7Qkv5WTeczD3f1XjXgXdiVUl6LrnIuzGvt1TrAi7ArpbzWhDrXat19q3Z/TdOeY2Yt\n+WL/Zf1+eRuf+vciXArGN2BXSnldqq5tivsj/E3tiU0vPJjUoW4gUdT1A+95ZuWW42V+y/mz\nQ1DCLXH+95o+buIC/ij2g9PKSmxJ0JMXWd6mJonFs3hm64r5KYMTov2oQnTC4JT5K7YWvUxE\nZvP26rrrtREPmprr8oyGfn4NZ7j4cAereSXA6we5aIAAG7OsRkDDMP87z5X96sU9n706Y2S3\nxiFEVZv3Hf+C9uziiNOO+w+DzGx8Sr+hzos//vhCnRvSXbcFC3klwK+5GgEBNujSt2987Prw\nhxM/rJ5/36B+2uf0YOdOrHm13jQx0dR6jv29Ttabaqq+rDeGte3/KM5A4jkI8JWm8yznQoL2\nC/pgj+69Bg8enTwpJeU/c+cvWrRixcfrvti69deDR86cKdxxLmqRtrAoyszxjqfbVB39xH3x\nEZvMlXhpyeQ7Zph/X16REOArzcBxzoXaSx13/zyRkjIpefTgwb26d05IiIuNqVaNClXQTk9/\ninZpnXbRKcd9xgn9vU40fVuqn9vZE6qfMlPhjgaRA8cl+g/PMtOJsb2P3j708cPm+qgyzHex\nEcsDvCY1NbU3KTepOo0QYM95udZ5x/26gKPlN7p0Ju3gwZ1bv1+37k/H41IB/j8l3CHVGsQn\ndOk1eNS4lEfmLlq64vONW/cdOZNZOMpu0vbbyW78uIkCz0bdof7Q3hY9xUQnxp4MbD3u7mYh\nr5vqxA7eWZ8i+35rrhM7Mq1Pu1HvmL563YUfdmS6bmWO5QGeFxcXV4OUmzidRgiw51xq3EPN\n4PfRE010yot2foVeGK19hb68b+uGz1csWTT3kZRxowb36pIQ36BaiPah7V+tdpO9jkaLYp3d\n7+nrnPvMGdcbr/7TSHuXfxpo5jCrdyusUO9eMndNuS3hiUu/XTE0cImZTux/Ydc9MHd4pR7m\nVuj93sdP+UYz5h9TndiRsU2D4+78pdzX8RX6inOwRaUbh7f2G2XqG+rD9U6odyfqPqzX6syJ\ng9u+W7f67cXaW/vpVs7nZ3bR7us5Eh5WrVrt2Nj4hIQ23bt3Hzx48Jjk5PtTlA9x5zk5uzu3\nb+VWX2GiwKbOtWv/6maiU2bsvxz/Hr0QYuar98GQR9Rev8fqHtNeqlfNGzddPP1h05YXzfT6\nvmq7BWte6RH6cXkNEOArT87/po154idzfdLbxzz3/ffPxbQ386mzqqrzH4k7Rmj3f27d+uO6\ndetWrlixeNGiZ+fOnZWS8u/k5DFKiG/q3r3tcK1RwlPO7ldpn/rfBQRVq1YtJjY29jot832V\n9nclJ49LSUmZMXeu9t3+L9qhdfosSPtmm31G4Wqr9ceh2udhXotZLloWNeUG7X5tgJnV6/27\nOlYJnq4/00Snyw1GO/5zHq5a3loEBBgMyXikkb9/o0dMrfH5J/wlx/3+0A9M9Lp5snafGfY/\nx332V+s+WbFixeuLFi2aO3fubCW2k5OTk4cMHnyrEuYOCdrGsH2k/VhnP5G2VXxiwXq4gGqq\nBso/ALHXJCjaKt1u1r6dP97OOeek27T7Z5TRU/4zt5jnF+X7UmvUeq52nxv2oVbgT1u3bt12\n0OEv9d+NM2W8e8/mf7d/trGJ/xerKmtDZdd/rpwWCDAYddHUlz/VyxWevsByPqt/s5ltTy/V\n1HYce6NSOTuolOWcv/Msaysra/cXdiup2rplnWqVkv8VS9UILnBE8qGU6dqKvDn5x7RO0fYm\nzxvaXXNjQnFXqfGPvUNrHL/Q2av2W467tVSOKuq/HNXfcDTaQc7V9l8GaF8RXlDn6Te4iKTk\nQvdp33Sm5f8gGPGvcv7DsSsleNDiSP+6IUHjTa3tyWh2w0ElS29VnGemV9ckx13ejUkmOr0X\n7jwcpN1DJnr1cF4C+kyA8x+N846P3T8dH8EHtjpscPzL8an6L4e2w9uv5Nzx7dMQ532K5t/J\nRd3uDPNw7bt9Si/nnGOGl1OMFwKcvvM7V00QYF9xacvStX+b7PNnl4D4xBrB/zHV6YeQ+5RP\n1bQRVQ6Y6JQeleK4XxFY/mre0hZGaL99p8eYOOlgVlVtszu7V+9MFiUtjnautb+uvMvFWx7g\nwwODiNiMYaV3ANy1tcBUBPiK9sPCR949YbLP+jrBLa8JuuoHU50+DUpaf/TbB4PmmumU1bbp\n5lx2ZkbgajO9UmMOqXebQt4x0Skt/BnH/btB5R3+aXWAj9el9l2JzaOYkrvS/+ZX9OcD9pkH\nkzLXz1+w0ewxkj90q0D+175nrtOZof6V6lCMqfyyjJ5V739r8eige031WhYwZeu5n6dXKPdf\nGKsDPJGWseXKAEsCJpR86cKZAp+R8D1WAMqUfbDkyT4N+HPNsq1m36I5r94UE9u/3A265fis\npfJx1vjtcl+3OsD1uzJHgFk/vbXp3yDAAJp/tp/WedXqAFca6wzw+Eo6rRBgAEOsDnDbNs4A\nt0rQaYUAAxhidYDn0OxcNcBzSG/LGwIMYIjVAc5JpLgbaEICNdfbTxUBBjDE8u3AmfPVQ1Ii\npp3Xa4QAAxjijV0pL+zRW62mQoABDLE+wOeOHXd5KgMEGMAQiwO8a0SUeoBXTNJm3WYIMIAh\n1gZ4kh9Ft+3Tp10dIt2zGSDAAIZYfHXCntu0pd1D6GmdhggwgCHWXh+4SeGJhjvpHVWFAAMY\nYmmAw0cWLk+totMQAQYwxNpP4PjCo7266n0C/1jeSUoAoLgfTeeQ4zdwb+1M32zfUHpSr+WO\nrcINa/GmVWbQG5bNFTbFsqkSEy2bakqYZVO9QTMsm6vFMPHv6x3mc+j+WuhxRHU79uuf2JBo\nlJnznImQ2st1G0Gs/AUQscqyqUaNsmyqVRGWTeXOd1B39dK7HIl1OLYDb0+KVD70A6KTNogr\nxyAEmBcCzEv+ACvOHj1h+qIyIiDAvBBgXj4RYG9BgHkhwLwQYA4IMC8EmJcPBfhsy5YCRjED\nAeaFAPPyoQCnkdWf4wgwLwSYlw8FOGv9egGjmIEA80KAeflQgK2HAPNCgHn5RICNHNDvCQgw\nLwSYl/wBNnhAvyfM6GfZVD8GmrjqFafoDy2bKjnZsqk+jLZsquxA8zsTu6vfDMum0uP5A/o9\n4YKZy6lzOmjdVIfNXg3IfWfOWDZVzmHLprLyj/WXPa7Z5/kD+gHAYzx/QD8AeIznD+gHAI/x\n/AH9AOAxFhzQDwCeIucB/QDgIOcB/QDgIOcB/QDgIOe+0ADggAADSAwBBpAYAgwgMQQYQGII\nMIDEEGAAiSHALl1Y8oe3S5DVgRd8cq6iU3n73SFjgDOmdgqPTfrNqulG0ceWzLPpxvDo2635\nrzp9f9OKTe/3/DH9U6o6F17qUKXDS9bMZcG7o+A/i1n37iiPhAH+pxM1HdPDL3S7NdOtJGv+\nRO9UqD20f0DEEQumOhNLXZI7U9w/Hp5nbbDznT6Omoy4iiZZMZcF746C/yxm3bujXBIG+CGa\nqNx+4n+tJbMdqx5myZ/oSGBbJU+v0kgL5ppKC5Tb+TTTo7MMa0KkvdO3U69slt3Db5cFc3n8\n3VE4FbPu3VE+CQMcXzlDvetOVpwYK69bw6mW/Inup+/U6Z592YK5bqa/lds/aYBHZ7m1b9/K\n2js9iX5Wbn+iERbM5fF3R+FUFr47yidhgJv2ddz1ob0WTDbP/+u5lvyJate1YBKnWfSWcruM\n/uPpiZpp7/TIOo676CgL5rLi3dEsP8CWvTvKJ2GANX+H1LLgfK/bKzzELPkTXaBOO26pWXfQ\nAc9PpfxO7BKUNDMpsPt5T0+kvdPPknbGlrbkyQmbFVmz5OF3R/5Ulr07dMga4H1x9IbnZ7nU\ntGWmNX+iP6hRWPPRvfwrWnJi48WBRBT0psfn0d7pR0k7jXcfOubxuTQefnc4p7Lu3aFDzgBf\nnBEa8qIF80wM2c2s+RP9TpSax9g6v+s8Pxd7nPr9nL7jZs+fDVh7p5+g/o5Hfei4x+dSefzd\n4ZzKuneHDikD/Gk96mvFD+D19Cyz6E90kiIcJwnsYcGqudMhV2cpd5mNK57z8EzaOz03INHx\nqF2AJ8/+UBBgz787tKksfHfokDHAM+iajZZM9BTle83TU+WGtHbcj6OfPD0V+5bGO+7HkKe/\nrztDFR3ruKsbY8FcVrw7tKksfHfokDDAS+gOi643tm6cqi31Huf5yz/1Cr+s3nX2v+jxqf50\nfqXVtiZ5UrP8zUj7lNvdlGTBXFa8O7SprHx3lE++AOc1ibls6YTWfEn6nCYqXzDfpb4WzHVt\nwFrldo3/9Z6eyBmqDTRc+bsNoa89P5cl746i68vwFdqsQ1Sjl+aUNRNa9CcaRc2Tb6JoK3aN\n31nZr+f47n5VfvX0RPnv9FHUbWoi3WXBXJa8OxBgHl8U/PTw5EaJIqz6Ez3VsXLTSdZcNPD4\n3U0rNh170uPz5L/T855oH95+nhVzWfLuQIABQAgEGEBiCDCAxBBgAIkhwAASQ4ABJIYAA0gM\nAQaQGAIMIDEEGEBiCDCAxBBgAIkhwAASQ4ABJIYAA0gMAQaQGAIMIDEEGEBiCDCAxBBgAIkh\nwAASQ4ABJIYAA0gMAQaQGAIMIDEEGEBiCDCAxBBgAIkhwAASQ4ABJIYAA0gMAQaQGAIMIDEE\nWAZzqHm2thQfqd8ysrupgd+oV/G3Uk8OpwxTg4AXIcAymEP0pLYkNsAnAus8nFbq2XIDvLbB\n+2ZGBwsgwDKYQ34VDzuWxAZ4Ez1VxrPlBvgDWm5mdLAAAiyDOTSW+jqWygjwpaIPdAJ8sfRT\nG2hhGQ3NBbiMYcE6CLAM5tC6PvSeuqQGuG+YupRBwxkbU/W7xlTj1pN/3xVXuevPTA3wkdtj\n6tz6i9oi57F2YQ0mHVeWRkVlTworyOq5yS3CEh68pCZVsTf/6dNjr67a7XWmBbjIHGxZu6oR\niZ8x1l1tnlbGsPkNwHoIsAzm0PpDFWPOs9IBDq7ebmo3anl1i4d6U8NsJcDxdWNHJvqFfc1Y\nZiK1Tu5C9Y6oSRtbI+kb52AnG1GHu1tRswtsUyqNXHLO+fSRBgG9kuPonlIBfoyik3pX9N/I\nPp9CyUsySg9b0ACshwDLQAkwm6tmq1SA6fZcxupS50zGepPyuRtJfZXvv2/R9YzNp9lKs6V0\nm5K0gOaF66om0HzlNoUeLf4V+k5azVhWe7/9JQMc2UQZcTWNdn6FLj1sYQOwHAIsAzXA2c0C\nfiojwNuUxXH0kXI7lzYrYQo4qL54M/3M6sXlqos3VEhno+jdgrGyKjTLU7tH1S4W4FP+N6p3\nn3RcVyLAWYENsxjL233IGeBSwxZpAJZDgGWgBph949c6t3SATymLqepnr/LRqAY4ztHhBVp1\nkW5YrupKO5WkHSgY6wBNctwPpItFA7yZ5uQvlvgEvpWunvlFuvpQDXAZwxY2AMshwDJwBJjd\nTc+XDrD6HTbVsSZKC3BHR4fVtGAP5ftWSdr5grE2OJM6kfYVDfB/6bX8xRIBvjQrlqji0D+1\nAJcxbGEDsBwCLAMtwGdqhv9ZGOC0sgPc2NFhAX2cRhML+o+iwo09+2my436Qkr4iAV5Pc/MX\nCwPsmEOxb3Fnap7nCHDZwzobgOUQYBloAWZv0iBHgIPVqHxRdoADDqkt+9FvLKK1o++8GcUD\nnBXUQr3LjIkq9hv4D7pFvVsTuFALcMEcB6Z9pb5wEx3RfgOXGrZIA7AcAiwDZ4DZjVRBCfAI\n2qR8b+1YdoCpfyZj79LNjD1MjzF1dfHQ4gFmY+lFpr46q/ha6Jv91jCW3c1vryPAhXMcpMQs\nJfatgzOVAL9exrBFGoDlEGAZ5Ad4XzApAX6fqtz7YJPQymUGuCY1vqubX809jJ1vRgkT+gfE\nHCsR4OMNqMuEttTiYvEA/1ozoO/EpnSf9hW6yBz9KC75jiiazthaaj07vfSwhQ3AcgiwDPID\nzB5RA8zeaBZM1T+ONHOnJAAAANVJREFUKzPAkz7rFdlg2B9q48sprSrGjXfsMlU0wOyfic0r\ntUq9zErsSnl8ZOOwVq/mOXelLJzj/MyrK0V2+K/ywuU7I6qfKT1sYQOwHAIspdwjWT4xB/BC\ngAEkhgADSAwBBpAYAgwgMQQYQGIIMIDEEGAAiSHAABJDgAEkhgADSAwBBpAYAgwgMQQYQGII\nMIDEEGAAiSHAABJDgAEkhgADSAwBBpAYAgwgMQQYQGIIMIDEEGAAiSHAABJDgAEkhgADSAwB\nBpAYAgwgMQQYQGIIMIDE/h/mvO9V7Z43PQAAAABJRU5ErkJggg==",
      "text/plain": [
       "Plot with title “wss plot of wine data”"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 480
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect the wss plot for our data.\n",
    "\n",
    "options(repr.plot.width= 8, repr.plot.height= 6)\n",
    "\n",
    "wssplot(train[, -1], title=\"wss plot of wine data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8AAAALQCAMAAABoqemGAAADAFBMVEUAAAABAQECAgIDAwME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\nIcAAEkOAASSGAANIDAEGkBgCDCCx/wcjz/Rl0CV7dgAAAABJRU5ErkJggg==",
      "text/plain": [
       "Plot with title “wss plot of wine data, scaled”"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 480
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scale the data; then plot.\n",
    "\n",
    "train_scaled <- scale(train[, -1], center=TRUE, scale=TRUE)\n",
    "train_scaled <- range01(train_scaled)\n",
    "\n",
    "options(repr.plot.width= 8, repr.plot.height= 6)\n",
    "\n",
    "wssplot(train_scaled, title=\"wss plot of wine data, scaled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMMENT:\n",
    "\n",
    "# We see that after scaling the data, it is easier to \n",
    "# \"identify\" 3 clusters.  Without the scaling, the wss\n",
    "# plot makes it appear that the data is best partitioned\n",
    "# into 2 classes rather than 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      " randomForest(formula = Type ~ ., data = train, ntree = 100, mtry = 3,      nodesize = 1, importance = TRUE) \n",
      "               Type of random forest: classification\n",
      "                     Number of trees: 100\n",
      "No. of variables tried at each split: 3\n",
      "\n",
      "        OOB estimate of  error rate: 1.69%\n",
      "Confusion matrix:\n",
      "   1  2  3 class.error\n",
      "1 59  0  0    0.000000\n",
      "2  1 68  2    0.042254\n",
      "3  0  0 48    0.000000\n"
     ]
    }
   ],
   "source": [
    "# Initial model.\n",
    "\n",
    "set.seed(123)\n",
    "rfclf <- randomForest(Type ~ ., data= train,\n",
    "                      ntree= 100, mtry= 3, nodesize= 1, \n",
    "                      importance=TRUE)\n",
    "print(rfclf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    1      2     3 MeanDecreaseAccuracy MeanDecreaseGini\n",
      "Alcohol         0.172  0.074 0.008                0.087           16.068\n",
      "Malic           0.013  0.008 0.016                0.012            2.767\n",
      "Ash             0.003  0.003 0.014                0.006            1.803\n",
      "Alcalinity      0.012  0.003 0.030                0.012            2.804\n",
      "Magnesium       0.063  0.011 0.002                0.025            3.517\n",
      "Phenols         0.093  0.000 0.049                0.044            7.943\n",
      "Flavanoids      0.128  0.027 0.238                0.114           17.190\n",
      "Nonflavanoids   0.012 -0.002 0.004                0.005            1.364\n",
      "Proanthocyanins 0.012  0.001 0.014                0.008            1.770\n",
      "Color           0.107  0.091 0.135                0.109           17.491\n",
      "Hue             0.052  0.015 0.130                0.057            9.597\n",
      "Dilution        0.114  0.015 0.214                0.100           16.171\n",
      "Proline         0.263  0.055 0.027                0.115           18.078\n"
     ]
    }
   ],
   "source": [
    "print(round(rfclf$importance, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMMENTS:\n",
    "\n",
    "# If the models that we want to boost using k-means are too \n",
    "# powerful, the k-means algorithm will probably have nothing\n",
    "# to add.  So we need to reduce the number of predictors.  \n",
    "# In a previous notebook I had selected only Magnesium, Phenols,\n",
    "# and Flavanoids.  Using only these 3 predictors, the typical\n",
    "# cross-val accuracy score was around 87%.  The k-means \n",
    "# algorithm was still not able to improve upon the best of\n",
    "# the models (an xgboost model) using only these 3 predictors.\n",
    "# In the xgboost model, Phenols was insignificant relative\n",
    "# to the other predictors, with a gain under 3%.  For Magnesium \n",
    "# the gain was just under 20%.  For Flavanoids, the gain was \n",
    "# almost 78%.  It may be that in order for k-means to boost\n",
    "# a model's performance, we also need more balance in the \n",
    "# importance of the predictors.  We saw greater balance between \n",
    "# the 3 predictors I used in Parts 1 and 2 for the cow data.\n",
    "\n",
    "# It is worth trying Hue, Phenols, and Alcalinity.  (See\n",
    "# the above importance output.)  This choice should give us\n",
    "# more balance and lower the predictive power of the models\n",
    "# to a point where the k-means algorithm can have something\n",
    "# to contribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#&* Bookmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- wine[, c(\"Type\",\"Hue\",\"Phenols\",\"Alcalinity\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      " randomForest(formula = Type ~ ., data = train, ntree = 100, mtry = 3,      nodesize = 1, importance = TRUE) \n",
      "               Type of random forest: classification\n",
      "                     Number of trees: 100\n",
      "No. of variables tried at each split: 3\n",
      "\n",
      "        OOB estimate of  error rate: 20.22%\n",
      "Confusion matrix:\n",
      "   1  2  3 class.error\n",
      "1 51  8  0     0.13559\n",
      "2 11 52  8     0.26761\n",
      "3  0  9 39     0.18750\n"
     ]
    }
   ],
   "source": [
    "set.seed(123)\n",
    "rfclf <- randomForest(Type ~ ., data= train,\n",
    "                      ntree= 100, mtry= 3, nodesize= 1, \n",
    "                      importance=TRUE)\n",
    "print(rfclf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               1     2     3 MeanDecreaseAccuracy MeanDecreaseGini\n",
      "Hue        0.188 0.104 0.496                0.235           50.687\n",
      "Phenols    0.342 0.041 0.229                0.192           43.940\n",
      "Alcalinity 0.148 0.021 0.105                0.087           21.824\n"
     ]
    }
   ],
   "source": [
    "print(round(rfclf$importance, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is called from get_cvScore_rf.\n",
    "\n",
    "get_Acc_rf <- function(traindat, valdat, ntrees, mtry, nodesize) {\n",
    "        \n",
    "    rfmod <- randomForest(Type ~ ., data= traindat, ntree= ntrees,\n",
    "                          mtry= mtry, nodesize= nodesize)\n",
    "        \n",
    "    preds <- predict(rfmod, newdata= valdat, type=\"response\")\n",
    "    ans <- get_confusion(preds, valdat[, \"Type\", drop=FALSE])\n",
    "\n",
    "    return(as.numeric(ans[[2]]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain a cross-validation score, averaging the\n",
    "# accuracy scores of the folds.  This function is called from\n",
    "# avg_seedScores_rf.\n",
    "\n",
    "get_cvScore_rf <- function(seed, dat, ntrees, mtry,\n",
    "                           nodesize, folds= 5) {\n",
    "    \n",
    "    # divide dat by the number of folds \n",
    "    segment_size <- round(nrow(dat)/folds)\n",
    "    diff <- nrow(dat) - folds * segment_size\n",
    "    last_seg_size <- segment_size + diff\n",
    "    segmentsv <- c(rep(segment_size, (folds - 1)), last_seg_size)\n",
    "    stopifnot(sum(segmentsv) == nrow(dat))\n",
    "    \n",
    "    # shuffle dat\n",
    "    set.seed(seed)\n",
    "    smp <- sample(rownames(dat), nrow(dat), replace= FALSE)\n",
    "    dat <- dat[smp,]\n",
    "    \n",
    "    # split the data into the folds\n",
    "    row_list <- vector(\"list\", length= folds)\n",
    "    names(row_list) <- as.character(1:folds)\n",
    "    startpt <- 1\n",
    "    for(i in 1:folds) {\n",
    "        endpt <- startpt + segmentsv[i] - 1\n",
    "        stopifnot(endpt <= dim(dat)[1])\n",
    "        row_list[[i]] <- rownames(dat)[startpt:endpt]\n",
    "        startpt <- endpt + 1\n",
    "    }\n",
    "    \n",
    "    train_list <- test_list <- vector(\"list\", length= folds)\n",
    "    for(j in 1:folds) {\n",
    "        testdat <- dat[row_list[[j]],]\n",
    "        traindat <- dat[which(!(rownames(dat) %in% rownames(testdat))),]\n",
    "        stopifnot((length(rownames(traindat)) + length(rownames(testdat))) == dim(dat)[1])\n",
    "        test_list[[j]] <- testdat\n",
    "        train_list[[j]] <- traindat\n",
    "    }\n",
    "\n",
    "    scores <- mcmapply(get_Acc_rf, train_list, test_list,\n",
    "                       MoreArgs= list(ntrees= ntrees, mtry=mtry,\n",
    "                                      nodesize=nodesize),\n",
    "                       SIMPLIFY= TRUE, mc.cores=5)\n",
    "    \n",
    "    return(round(mean(scores), 5))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the seed value can have a big effect on the results,\n",
    "# I take the average over a number of seeds.  This ftn is\n",
    "# called from gridSearch02.\n",
    "\n",
    "avg_seedScores_rf <- function(seed_vector, traindat, n_trees,  \n",
    "                              mtry, nodesize, folds= 5) {\n",
    "    \n",
    "    seed_len <- length(seed_vector)\n",
    "    outv <- rep(NA, seed_len)\n",
    "    for(i in 1:seed_len) {\n",
    "        seed <- seed_vector[i]\n",
    "        outv[i] <- get_cvScore_rf(seed, traindat, n_trees,\n",
    "                                  mtry, nodesize, folds=folds)\n",
    "    }\n",
    "    return(round(mean(outv), 5))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This grid search is specific to finding the best random forest\n",
    "# classifier for train.\n",
    "\n",
    "gridSearch02 <- function(seed_vector, traindat, ntree_vector, \n",
    "                         mtry_vector, nodesizes, folds=5) {\n",
    "    \n",
    "    tree_len <- length(ntree_vector)\n",
    "    mtry_len <- length(mtry_vector)\n",
    "    node_len <- length(nodesizes)\n",
    "    # We need to capture the gridSearch parameters as well as \n",
    "    # the cross-val  scores.\n",
    "    datout <- rep(NA, 2 * tree_len * mtry_len * node_len)\n",
    "    dim(datout) <- c((tree_len * mtry_len * node_len), 2)\n",
    "    datout <- as.data.frame(datout)\n",
    "    colnames(datout) <- c(\"params\", \"acc\")\n",
    "    datout$params <- \"\"\n",
    "    \n",
    "    index <- 0\n",
    "    for(i in 1:tree_len) {\n",
    "        n_trees <- ntree_vector[i]\n",
    "        for(j in 1:mtry_len) {\n",
    "            mtry <- mtry_vector[j]\n",
    "            for(k in 1:node_len) {\n",
    "                index <- index + 1\n",
    "                nodesize <- nodesizes[k]\n",
    "                param_string <- paste(as.character(n_trees), \n",
    "                                      as.character(mtry),\n",
    "                                      as.character(nodesize), sep= \"--\")\n",
    "                datout$params[index] <- param_string\n",
    "                datout$acc[index] <- avg_seedScores_rf(seed_vector, traindat, n_trees, \n",
    "                                                         folds=folds, mtry=mtry,\n",
    "                                                         nodesize=nodesize)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return(datout)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-05-30 06:56:33'"
      ],
      "text/latex": [
       "'Start time: 2021-05-30 06:56:33'"
      ],
      "text/markdown": [
       "'Start time: 2021-05-30 06:56:33'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-05-30 06:56:33\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 2.21 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'150--1--2'"
      ],
      "text/latex": [
       "'150--1--2'"
      ],
      "text/markdown": [
       "'150--1--2'"
      ],
      "text/plain": [
       "[1] \"150--1--2\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.80765"
      ],
      "text/latex": [
       "0.80765"
      ],
      "text/markdown": [
       "0.80765"
      ],
      "text/plain": [
       "[1] 0.80765"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run grid search to get better parameters for the \n",
    "# random forest model.  Test with 200 seeds.  For each\n",
    "# seed, an average is taken over 5 folds.\n",
    "\n",
    "set.seed(7541)\n",
    "seed_smp <- sample(1:9999, 200, replace=FALSE)\n",
    "tree_vector <- c(60, 80, 100, 120, 150)\n",
    "mtry_vector <- c(1, 2)\n",
    "node_vector <- c(1, 2)\n",
    "\n",
    "start <- Sys.time()\n",
    "paste(\"Start time: \", start, sep=\"\")\n",
    "ans <- gridSearch02(seed_smp, train, tree_vector, mtry_vector, node_vector)\n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 2.21 mins\n",
    "\n",
    "(best_params <- ans[which(ans$acc == max(ans$acc)),]$params)\n",
    "#  '150--1--2'\n",
    "\n",
    "(best_rf_acc <- ans[which(ans$acc == max(ans$acc)),]$acc)\n",
    "#  0.80765\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-05-30 07:00:40'"
      ],
      "text/latex": [
       "'Start time: 2021-05-30 07:00:40'"
      ],
      "text/markdown": [
       "'Start time: 2021-05-30 07:00:40'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-05-30 07:00:40\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 30.33 secs"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'150--1--2'"
      ],
      "text/latex": [
       "'150--1--2'"
      ],
      "text/markdown": [
       "'150--1--2'"
      ],
      "text/plain": [
       "[1] \"150--1--2\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.80868"
      ],
      "text/latex": [
       "0.80868"
      ],
      "text/markdown": [
       "0.80868"
      ],
      "text/plain": [
       "[1] 0.80868"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Refine the search.\n",
    "\n",
    "set.seed(7543)\n",
    "seed_smp <- sample(1:9999, 200, replace=FALSE)\n",
    "tree_vector <- c(150, 180)\n",
    "mtry_vector <- c(1)\n",
    "node_vector <- c(1, 2)\n",
    "\n",
    "start <- Sys.time()\n",
    "paste(\"Start time: \", start, sep=\"\")\n",
    "ans <- gridSearch02(seed_smp, train, tree_vector, mtry_vector, node_vector)\n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 30.33 secs\n",
    "\n",
    "(best_params <- ans[which(ans$acc == max(ans$acc)),]$params)\n",
    "#  '150--1--2'\n",
    "\n",
    "(best_rf_acc <- ans[which(ans$acc == max(ans$acc)),]$acc)\n",
    "#  0.8087\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an average accuracy score for rfclf_best on training set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time difference of 21.38 secs"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get stable scores for the best random forest model.  I will\n",
    "# refer to this model as rfclf_best.  Note that 2000 seeds\n",
    "# are being used. \n",
    "\n",
    "set.seed(1433)\n",
    "seed_smp <- sample(1:9999, 2000, replace=FALSE)\n",
    "\n",
    "datout <- rep(NA, 2 * length(seed_smp))\n",
    "dim(datout) <- c(length(seed_smp), 2)\n",
    "datout <- as.data.frame(datout)\n",
    "colnames(datout) <- c(\"seed\",\"Acc\")\n",
    "datout$seed <- seed_smp\n",
    "\n",
    "start <- Sys.time()\n",
    "for(i in 1:length(seed_smp)) {\n",
    "    \n",
    "    set.seed(seed_smp[i])\n",
    "    rfmod <- randomForest(Type ~ ., data= train, ntree=150,\n",
    "                              mtry= 1, nodesize= 2)\n",
    "        \n",
    "    # preds <- predict(rfmod, newdata= dat, type=\"response\")\n",
    "    # ans <- get_confusion(preds, dat[, \"Type\", drop=FALSE])\n",
    "    # mat <- as.matrix(ans[[1]])\n",
    "    mat <- rfmod$confusion\n",
    "    # percent_correct <- sum(diag(mat))/floor(sum(mat))\n",
    "    # datout[i, c(\"Acc\")] <- round(percent_correct, 4)\n",
    "    datout[i, c(\"Acc\")] <- round(1-median(rfmod$err.rate[,1]), 4)\n",
    "}\n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 21.38 secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAMAAAC323mdAAAC+lBMVEUAAAABAQECAgIDAwME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\ngg==",
      "text/plain": [
       "Plot with title “Distribution of accuracy scores for rfclf_best on train data”"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width= 10, repr.plot.height= 6)\n",
    "hist(datout$Acc, breaks=16, xlab=\"accuracy\",\n",
    "     main=\"Distribution of accuracy scores for rfclf_best on train data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.804"
      ],
      "text/latex": [
       "0.804"
      ],
      "text/markdown": [
       "0.804"
      ],
      "text/plain": [
       "[1] 0.804"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rfclf_best's average accuracy score on the trainset data.\n",
    "\n",
    "round(mean(datout$Acc), 4)\n",
    "# 0.8040\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "394"
      ],
      "text/latex": [
       "394"
      ],
      "text/markdown": [
       "394"
      ],
      "text/plain": [
       "[1] 394"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>5605</li><li>8920</li><li>8072</li><li>2781</li><li>644</li><li>7123</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 5605\n",
       "\\item 8920\n",
       "\\item 8072\n",
       "\\item 2781\n",
       "\\item 644\n",
       "\\item 7123\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 5605\n",
       "2. 8920\n",
       "3. 8072\n",
       "4. 2781\n",
       "5. 644\n",
       "6. 7123\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 5605 8920 8072 2781  644 7123"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Identify seeds with an accuracy score between 0.8039 \n",
    "# and 0.8041.  When constructing rfclf_best, I want to\n",
    "# use a seed which has an accuracy in the center of the\n",
    "# above distribution of accuracy scores.\n",
    "\n",
    "rf_candidate_seeds <- datout[which((datout$Acc > 0.8033) & (datout$Acc < 0.8046)),]$seed\n",
    "length(rf_candidate_seeds)\n",
    "#  394\n",
    "head(rf_candidate_seeds)\n",
    "#  2781\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      " randomForest(formula = Type ~ ., data = train, ntree = 150, mtry = 1,      nodesize = 2) \n",
      "               Type of random forest: classification\n",
      "                     Number of trees: 150\n",
      "No. of variables tried at each split: 1\n",
      "\n",
      "        OOB estimate of  error rate: 17.98%\n",
      "Confusion matrix:\n",
      "   1  2  3 class.error\n",
      "1 48 11  0     0.18644\n",
      "2  8 58  5     0.18310\n",
      "3  0  8 40     0.16667\n"
     ]
    }
   ],
   "source": [
    "# Best random forest model, for the purposes of \n",
    "# showing average performance on the training set.\n",
    "\n",
    "set.seed(2781)\n",
    "rfclf_best <- randomForest(Type ~ ., data= train, ntree=150,\n",
    "                              mtry= 1, nodesize= 2)\n",
    "\n",
    "print(rfclf_best)\n",
    "# OOB estimate of  error rate: 17.98%; 32 records misclassified\n",
    "# Again, this is the AVERAGE PERFORMANCE of our best rf model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get comparative cross-val score for best random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For model performance comparisons, we want a cross-val score over many folds for our best random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is called from get_cvScore_rfBest.  It\n",
    "# returns an accuracy score on the validation set.\n",
    "\n",
    "get_Acc_rfBest <- function(traindat, valdat) {\n",
    "\n",
    "    # This is our current best rf model.  The seed is\n",
    "    # part of the model.\n",
    "    set.seed(2781)\n",
    "    rfmod <- randomForest(Type ~ ., data= traindat, ntree=150,\n",
    "                              mtry= 1, nodesize=2)\n",
    "        \n",
    "    preds <- predict(rfmod, newdata= valdat, type=\"response\")\n",
    "    ans <- get_confusion(preds, valdat[, \"Type\", drop=FALSE])\n",
    "    return(ans[[2]])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain a cross-validation score, averaging the\n",
    "# accuracy scores of the folds.  This function is called from\n",
    "# compute_cvScore_rf.\n",
    "\n",
    "get_cvScore_rfBest <- function(seed, dat, folds= 5) {\n",
    "    \n",
    "    # divide dat by the number of folds \n",
    "    segment_size <- round(nrow(dat)/folds)\n",
    "    diff <- nrow(dat) - folds * segment_size\n",
    "    last_seg_size <- segment_size + diff\n",
    "    segmentsv <- c(rep(segment_size, (folds - 1)), last_seg_size)\n",
    "    stopifnot(sum(segmentsv) == nrow(dat))\n",
    "    \n",
    "    # shuffle dat\n",
    "    set.seed(seed)\n",
    "    smp <- sample(rownames(dat), nrow(dat), replace= FALSE)\n",
    "    dat <- dat[smp,]\n",
    "    \n",
    "    # split the data into the folds\n",
    "    row_list <- vector(\"list\", length= folds)\n",
    "    names(row_list) <- as.character(1:folds)\n",
    "    startpt <- 1\n",
    "    for(i in 1:folds) {\n",
    "        endpt <- startpt + segmentsv[i] - 1\n",
    "        stopifnot(endpt <= nrow(dat))\n",
    "        row_list[[i]] <- rownames(dat)[startpt:endpt]\n",
    "        startpt <- endpt + 1\n",
    "    }\n",
    "    \n",
    "    train_list <- test_list <- vector(\"list\", length= folds)\n",
    "    for(j in 1:folds) {\n",
    "        testdat <- dat[row_list[[j]],]\n",
    "        traindat <- dat[which(!(rownames(dat) %in% rownames(testdat))),]\n",
    "        stopifnot((length(rownames(traindat)) + length(rownames(testdat))) == dim(dat)[1])\n",
    "        test_list[[j]] <- testdat\n",
    "        train_list[[j]] <- traindat\n",
    "    }\n",
    "\n",
    "    scores <- mcmapply(get_Acc_rfBest, train_list, test_list,\n",
    "                       SIMPLIFY= TRUE, mc.cores=5)\n",
    "    \n",
    "    # The following mean is over 5 accuracy scores, one for each\n",
    "    # of the folds.\n",
    "    return(round(mean(scores), 5))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get a cross-val accuracy score over many \n",
    "# folds for the best random forest model.\n",
    "\n",
    "compute_cvScore_rf <- function(seedv, dat) {\n",
    "    \n",
    "    seedv_len <- length(seedv)\n",
    "    result <- rep(NA, length=seedv_len)\n",
    "    names(result) <- as.character(seedv)\n",
    "    \n",
    "    for(i in 1:seedv_len) {\n",
    "        cur.seed <- seedv[i]\n",
    "        # For each seed in seedv, compute a cross-val\n",
    "        # accuracy score.\n",
    "        result[i] <- get_cvScore_rfBest(cur.seed, dat)\n",
    "    }\n",
    "    return(result)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-05-30 07:09:24'"
      ],
      "text/latex": [
       "'Start time: 2021-05-30 07:09:24'"
      ],
      "text/markdown": [
       "'Start time: 2021-05-30 07:09:24'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-05-30 07:09:24\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 1.23 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use 2000 seeds.  This equates to getting a \n",
    "# comparative cross-val score over 10,000 folds.\n",
    "# Since train has 178 records in it, each fold\n",
    "# will consist of 35 or 36 records.  There are\n",
    "# 1.56e37 ways of selecting 35 from 178.\n",
    "\n",
    "set.seed(1931)\n",
    "seedv <- sample(1:9999, 2000, replace=FALSE)\n",
    "\n",
    "start <- Sys.time()\n",
    "paste(\"Start time: \", start, sep=\"\")\n",
    "ans <- compute_cvScore_rf(seedv, train)\n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 1.23 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "  0.747   0.797   0.808   0.807   0.820   0.859 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.8074"
      ],
      "text/latex": [
       "0.8074"
      ],
      "text/markdown": [
       "0.8074"
      ],
      "text/plain": [
       "[1] 0.8074"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is our comparative cross-val accuracy score for\n",
    "# the current best random forest model.\n",
    "\n",
    "round(mean(ans), 4)\n",
    "# 0.8653\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.8085"
      ],
      "text/latex": [
       "0.8085"
      ],
      "text/markdown": [
       "0.8085"
      ],
      "text/plain": [
       "[1] 0.8085"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.017064"
      ],
      "text/latex": [
       "0.017064"
      ],
      "text/markdown": [
       "0.017064"
      ],
      "text/plain": [
       "[1] 0.017064"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(median(ans), 4)\n",
    "round(sd(ans), 6)\n",
    "# median: 0.8085\n",
    "# sd: 0.017064\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8AAAALQCAMAAABoqemGAAAC/VBMVEUAAAABAQECAgIDAwME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\nMOAwAgYcRsCAwwgYcNj/Ax3vHffWKjhxAAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title “Distribution of cross-val accuracy scores for rfclf_best”"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 480
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width= 8, repr.plot.height= 6)\n",
    "hist(ans, breaks=16, main=\"Distribution of cross-val accuracy scores for rfclf_best\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best gradient boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package gbm no longer handles multinomial data.\n",
    "\n",
    "require(xgboost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 5 × 1</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>ans</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Package</th><td>xgboost                  </td></tr>\n",
       "\t<tr><th scope=row>Type</th><td>Package                  </td></tr>\n",
       "\t<tr><th scope=row>Title</th><td>Extreme Gradient Boosting</td></tr>\n",
       "\t<tr><th scope=row>Version</th><td>1.4.1.1                  </td></tr>\n",
       "\t<tr><th scope=row>Date</th><td>2021-04-22               </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 5 × 1\n",
       "\\begin{tabular}{r|l}\n",
       "  & ans\\\\\n",
       "  & <chr>\\\\\n",
       "\\hline\n",
       "\tPackage & xgboost                  \\\\\n",
       "\tType & Package                  \\\\\n",
       "\tTitle & Extreme Gradient Boosting\\\\\n",
       "\tVersion & 1.4.1.1                  \\\\\n",
       "\tDate & 2021-04-22               \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 5 × 1\n",
       "\n",
       "| <!--/--> | ans &lt;chr&gt; |\n",
       "|---|---|\n",
       "| Package | xgboost                   |\n",
       "| Type | Package                   |\n",
       "| Title | Extreme Gradient Boosting |\n",
       "| Version | 1.4.1.1                   |\n",
       "| Date | 2021-04-22                |\n",
       "\n"
      ],
      "text/plain": [
       "        ans                      \n",
       "Package xgboost                  \n",
       "Type    Package                  \n",
       "Title   Extreme Gradient Boosting\n",
       "Version 1.4.1.1                  \n",
       "Date    2021-04-22               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Package updates for xgboost occur regularly.\n",
    "\n",
    "# packageDate(\"xgboost\")\n",
    "ans <- unlist(packageDescription(\"xgboost\")[1:5])\n",
    "(df <- data.frame(ans))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  2  3 \n",
       "59 71 48 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(train$Type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  1  2 \n",
       "59 71 48 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We need to transform Type for xgboost to work.  The \n",
    "# classes must be numeric, starting at 0.\n",
    "\n",
    "gbtrain <- train\n",
    "\n",
    "gbtrain$label <- NA\n",
    "for(i in 1:nrow(gbtrain)) {\n",
    "    \n",
    "    if(gbtrain$Type[i]== \"1\") { gbtrain$label[i] <- 0 }\n",
    "    if(gbtrain$Type[i]== \"2\") { gbtrain$label[i] <- 1 }\n",
    "    if(gbtrain$Type[i]== \"3\") { gbtrain$label[i] <- 2 }\n",
    "}\n",
    "table(as.factor(gbtrain$label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'Type'</li><li>'Hue'</li><li>'Phenols'</li><li>'Alcalinity'</li><li>'label'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Type'\n",
       "\\item 'Hue'\n",
       "\\item 'Phenols'\n",
       "\\item 'Alcalinity'\n",
       "\\item 'label'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Type'\n",
       "2. 'Hue'\n",
       "3. 'Phenols'\n",
       "4. 'Alcalinity'\n",
       "5. 'label'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"Type\"       \"Hue\"        \"Phenols\"    \"Alcalinity\" \"label\"     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# There are 3 predictors.\n",
    "\n",
    "colnames(gbtrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>label</th><th scope=col>Hue</th><th scope=col>Phenols</th><th scope=col>Alcalinity</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>113</th><td>1</td><td>1.23</td><td>1.75</td><td>20</td></tr>\n",
       "\t<tr><th scope=row>159</th><td>2</td><td>0.57</td><td>2.80</td><td>25</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>0</td><td>1.09</td><td>3.00</td><td>16</td></tr>\n",
       "\t<tr><th scope=row>131</th><td>2</td><td>0.76</td><td>1.51</td><td>18</td></tr>\n",
       "\t<tr><th scope=row>137</th><td>2</td><td>0.75</td><td>1.38</td><td>21</td></tr>\n",
       "\t<tr><th scope=row>133</th><td>2</td><td>0.66</td><td>1.15</td><td>24</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & label & Hue & Phenols & Alcalinity\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t113 & 1 & 1.23 & 1.75 & 20\\\\\n",
       "\t159 & 2 & 0.57 & 2.80 & 25\\\\\n",
       "\t21 & 0 & 1.09 & 3.00 & 16\\\\\n",
       "\t131 & 2 & 0.76 & 1.51 & 18\\\\\n",
       "\t137 & 2 & 0.75 & 1.38 & 21\\\\\n",
       "\t133 & 2 & 0.66 & 1.15 & 24\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 4\n",
       "\n",
       "| <!--/--> | label &lt;dbl&gt; | Hue &lt;dbl&gt; | Phenols &lt;dbl&gt; | Alcalinity &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 113 | 1 | 1.23 | 1.75 | 20 |\n",
       "| 159 | 2 | 0.57 | 2.80 | 25 |\n",
       "| 21 | 0 | 1.09 | 3.00 | 16 |\n",
       "| 131 | 2 | 0.76 | 1.51 | 18 |\n",
       "| 137 | 2 | 0.75 | 1.38 | 21 |\n",
       "| 133 | 2 | 0.66 | 1.15 | 24 |\n",
       "\n"
      ],
      "text/plain": [
       "    label Hue  Phenols Alcalinity\n",
       "113 1     1.23 1.75    20        \n",
       "159 2     0.57 2.80    25        \n",
       "21  0     1.09 3.00    16        \n",
       "131 2     0.76 1.51    18        \n",
       "137 2     0.75 1.38    21        \n",
       "133 2     0.66 1.15    24        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove Type column from gbtrain and make label\n",
    "# the first column.\n",
    "\n",
    "gbtrain <- gbtrain[, -1]\n",
    "cols <- colnames(gbtrain)[1:3]\n",
    "gbtrain <- gbtrain[, c(\"label\", cols)]\n",
    "head(gbtrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain <- xgb.DMatrix(data = as.matrix(gbtrain[, -1]), label = gbtrain$label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-merror:0.191011 \n",
      "[2]\ttrain-merror:0.196629 \n",
      "[3]\ttrain-merror:0.179775 \n",
      "[4]\ttrain-merror:0.174157 \n",
      "[5]\ttrain-merror:0.174157 \n",
      "[6]\ttrain-merror:0.174157 \n",
      "[7]\ttrain-merror:0.157303 \n",
      "[8]\ttrain-merror:0.157303 \n"
     ]
    }
   ],
   "source": [
    "set.seed(123)\n",
    "gbmod <- xgboost(data= dtrain, booster=\"gbtree\", \n",
    "                 objective=\"multi:softmax\", num_class=3,\n",
    "                 eta= 0.25, max_depth=5, gamma=3, \n",
    "                 subsample=0.5, nrounds=8, nthread=10,\n",
    "                 eval_metric=\"merror\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  1  2 \n",
       "64 69 45 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds <- predict(gbmod, as.matrix(gbtrain[, -1]))\n",
    "print(length(preds))\n",
    "table(as.factor(preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 3 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>0</th><th scope=col>1</th><th scope=col>2</th><th scope=col>class.error</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>0</th><td>53</td><td> 6</td><td> 0</td><td>0.1017</td></tr>\n",
       "\t<tr><th scope=row>1</th><td>11</td><td>56</td><td> 4</td><td>0.2113</td></tr>\n",
       "\t<tr><th scope=row>2</th><td> 0</td><td> 7</td><td>41</td><td>0.1458</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 3 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & 0 & 1 & 2 & class.error\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t0 & 53 &  6 &  0 & 0.1017\\\\\n",
       "\t1 & 11 & 56 &  4 & 0.2113\\\\\n",
       "\t2 &  0 &  7 & 41 & 0.1458\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 3 × 4\n",
       "\n",
       "| <!--/--> | 0 &lt;dbl&gt; | 1 &lt;dbl&gt; | 2 &lt;dbl&gt; | class.error &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 0 | 53 |  6 |  0 | 0.1017 |\n",
       "| 1 | 11 | 56 |  4 | 0.2113 |\n",
       "| 2 |  0 |  7 | 41 | 0.1458 |\n",
       "\n"
      ],
      "text/plain": [
       "  0  1  2  class.error\n",
       "0 53  6  0 0.1017     \n",
       "1 11 56  4 0.2113     \n",
       "2  0  7 41 0.1458     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "''"
      ],
      "text/latex": [
       "''"
      ],
      "text/markdown": [
       "''"
      ],
      "text/plain": [
       "[1] \"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.8427"
      ],
      "text/latex": [
       "0.8427"
      ],
      "text/markdown": [
       "0.8427"
      ],
      "text/plain": [
       "[1] 0.8427"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get accuracy score for the xgboost model.\n",
    "\n",
    "preds02 <- as.factor(preds)\n",
    "names(preds02) <- rownames(gbtrain)\n",
    "\n",
    "ans <- get_confusion(preds02, gbtrain[, \"label\", drop=FALSE])\n",
    "ans$matrix\n",
    "\"\"\n",
    "ans$acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature    Gain   Cover Frequency\n",
      "1:    Phenols 0.43449 0.36806     0.400\n",
      "2:        Hue 0.40868 0.40694     0.375\n",
      "3: Alcalinity 0.15684 0.22500     0.225\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAHgCAMAAAC7G6qeAAAC31BMVEUAAAABAQECAgIDAwME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\nAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 240,
       "width": 360
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get feature importances for the gbmod model.\n",
    "\n",
    "options(repr.plot.width= 6, repr.plot.height= 4)\n",
    "\n",
    "importance_matrix <- xgb.importance(model = gbmod)\n",
    "print(importance_matrix)\n",
    "xgb.plot.importance(importance_matrix = importance_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the gradient boost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is called from get_cvScore_xgb.\n",
    "\n",
    "get_Acc_xgb <- function(traindat, valdat, eta, maxDepth, gamma) {\n",
    "    \n",
    "    dtrain <- xgb.DMatrix(data = as.matrix(traindat[, -1]), label = traindat$label)\n",
    "    \n",
    "    set.seed(123)\n",
    "    xgb_mod <- xgboost(data= dtrain, booster=\"gbtree\", \n",
    "                 objective=\"multi:softmax\", num_class=3,\n",
    "                 eta=eta, max_depth=maxDepth, gamma=gamma, \n",
    "                 subsample=0.5, nrounds=8, nthread=10,\n",
    "                 eval_metric=\"merror\", verbose=0)\n",
    "    \n",
    "    preds <- predict(xgb_mod, as.matrix(valdat[, -1]))\n",
    "    preds <- as.factor(preds)\n",
    "    names(preds) <- rownames(valdat)   \n",
    "    ans <- get_confusion(preds, valdat[, \"label\", drop=FALSE])\n",
    "\n",
    "    return(as.numeric(ans[[2]]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain a cross-validation score, averaging the\n",
    "# accuracy scores of the folds.  This function is called from\n",
    "# avg_seedScores_xgb.\n",
    "\n",
    "get_cvScore_xgb <- function(seed, dat, eta, maxDepth,\n",
    "                            gamma, folds= 5) {\n",
    "    \n",
    "    # divide dat by the number of folds \n",
    "    segment_size <- round(nrow(dat)/folds)\n",
    "    diff <- nrow(dat) - folds * segment_size\n",
    "    last_seg_size <- segment_size + diff\n",
    "    segmentsv <- c(rep(segment_size, (folds - 1)), last_seg_size)\n",
    "    stopifnot(sum(segmentsv) == nrow(dat))\n",
    "    \n",
    "    # shuffle dat\n",
    "    set.seed(seed)\n",
    "    smp <- sample(rownames(dat), nrow(dat), replace= FALSE)\n",
    "    dat <- dat[smp,]\n",
    "    \n",
    "    # split the data into the folds\n",
    "    row_list <- vector(\"list\", length= folds)\n",
    "    names(row_list) <- as.character(1:folds)\n",
    "    startpt <- 1\n",
    "    for(i in 1:folds) {\n",
    "        endpt <- startpt + segmentsv[i] - 1\n",
    "        stopifnot(endpt <= nrow(dat))\n",
    "        row_list[[i]] <- rownames(dat)[startpt:endpt]\n",
    "        startpt <- endpt + 1\n",
    "    }\n",
    "    \n",
    "    train_list <- test_list <- vector(\"list\", length= folds)\n",
    "    for(j in 1:folds) {\n",
    "        testdat <- dat[row_list[[j]],]\n",
    "        traindat <- dat[which(!(rownames(dat) %in% rownames(testdat))),]\n",
    "        stopifnot((length(rownames(traindat)) + length(rownames(testdat))) == dim(dat)[1])\n",
    "        test_list[[j]] <- testdat\n",
    "        train_list[[j]] <- traindat\n",
    "    }\n",
    "\n",
    "    # Do NOT use mcmapply with xgboost.  The function is \n",
    "    # already using 10 cores, or threads.\n",
    "    scores <- mapply(get_Acc_xgb, train_list, test_list,\n",
    "                     MoreArgs= list(eta= eta, maxDepth=maxDepth,\n",
    "                                    gamma=gamma), SIMPLIFY= TRUE)\n",
    "    \n",
    "    return(round(mean(scores), 5))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the seed value can affect the results, I take\n",
    "# the average over a number of seeds.  This ftn is\n",
    "# called from gridSearch02_xgb.\n",
    "\n",
    "avg_seedScores_xgb <- function(seed_vector, traindat, eta, maxDepth, \n",
    "                               gamma, folds= 5) {\n",
    "    \n",
    "    seed_len <- length(seed_vector)\n",
    "    outv <- rep(NA, seed_len)\n",
    "    for(i in 1:seed_len) {\n",
    "        seed <- seed_vector[i]\n",
    "        outv[i] <- get_cvScore_xgb(seed, traindat, eta, maxDepth,\n",
    "                                   gamma, folds=folds)\n",
    "    }\n",
    "    return(round(mean(outv), 5))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This grid search is specific to finding the best xgboost\n",
    "# classifier for traindat.\n",
    "\n",
    "gridSearch02_xgb <- function(seed_vector, traindat, eta_vector, \n",
    "                             maxDepth_vector, gamma_vector, folds=5) {\n",
    "    \n",
    "    eta_len <- length(eta_vector)\n",
    "    maxDepth_len <- length(maxDepth_vector)\n",
    "    gamma_len <- length(gamma_vector)\n",
    "    # We need to capture the gridSearch parameters as well as \n",
    "    # the cross-val  scores.\n",
    "    datout <- rep(NA, 2 * eta_len * maxDepth_len * gamma_len)\n",
    "    dim(datout) <- c((eta_len * maxDepth_len * gamma_len), 2)\n",
    "    datout <- as.data.frame(datout)\n",
    "    colnames(datout) <- c(\"params\", \"acc\")\n",
    "    datout$params <- \"\"\n",
    "    \n",
    "    index <- 0\n",
    "    for(i in 1:eta_len) {\n",
    "        eta <- eta_vector[i]\n",
    "        for(j in 1:maxDepth_len) {\n",
    "            maxDepth <- maxDepth_vector[j]\n",
    "            for(k in 1:gamma_len) {\n",
    "                index <- index + 1\n",
    "                gamma <- gamma_vector[k]\n",
    "                param_string <- paste(as.character(eta), \n",
    "                                      as.character(maxDepth),\n",
    "                                      as.character(gamma), sep= \"--\")\n",
    "                datout$params[index] <- param_string\n",
    "                datout$acc[index] <- avg_seedScores_xgb(seed_vector, traindat, eta=eta, \n",
    "                                                        folds=folds, maxDepth=maxDepth,\n",
    "                                                        gamma=gamma)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return(datout)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-05-30 07:16:47'"
      ],
      "text/latex": [
       "'Start time: 2021-05-30 07:16:47'"
      ],
      "text/markdown": [
       "'Start time: 2021-05-30 07:16:47'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-05-30 07:16:47\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 3.67 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'0.23--5--1'"
      ],
      "text/latex": [
       "'0.23--5--1'"
      ],
      "text/markdown": [
       "'0.23--5--1'"
      ],
      "text/plain": [
       "[1] \"0.23--5--1\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.79396"
      ],
      "text/latex": [
       "0.79396"
      ],
      "text/markdown": [
       "0.79396"
      ],
      "text/plain": [
       "[1] 0.79396"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run grid search to get better parameters for the \n",
    "# xgboost model.  Test with 350 seeds.  For each\n",
    "# seed, an average is taken over 5 folds.\n",
    "\n",
    "set.seed(7541)\n",
    "seed_smp <- sample(1:9999, 350, replace=FALSE)\n",
    "eta_vector <- c(0.20, 0.23, 0.25)\n",
    "maxDepth_vector <- 3:5\n",
    "gamma_vector <- 1:2\n",
    "\n",
    "start <- Sys.time()\n",
    "paste(\"Start time: \", start, sep=\"\")\n",
    "ans <- gridSearch02_xgb(seed_smp, gbtrain, eta_vector, maxDepth_vector, gamma_vector)\n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 3.67 mins\n",
    "\n",
    "(best_params <- ans[which(ans$acc == max(ans$acc)),]$params)\n",
    "#  '0.23--5--1'\n",
    "\n",
    "(best_xgb_acc <- ans[which(ans$acc == max(ans$acc)),]$acc)\n",
    "#  0.7940\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-05-30 07:21:34'"
      ],
      "text/latex": [
       "'Start time: 2021-05-30 07:21:34'"
      ],
      "text/markdown": [
       "'Start time: 2021-05-30 07:21:34'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-05-30 07:21:34\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 2.55 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'0.24--6--1'"
      ],
      "text/latex": [
       "'0.24--6--1'"
      ],
      "text/markdown": [
       "'0.24--6--1'"
      ],
      "text/plain": [
       "[1] \"0.24--6--1\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.7936"
      ],
      "text/latex": [
       "0.7936"
      ],
      "text/markdown": [
       "0.7936"
      ],
      "text/plain": [
       "[1] 0.7936"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Refine the search.\n",
    "\n",
    "set.seed(1933)\n",
    "seed_smp <- sample(1:9999, 350, replace=FALSE)\n",
    "eta_vector <- c(0.22, 0.23, 0.24)\n",
    "maxDepth_vector <- 5:6\n",
    "gamma_vector <- 1:2\n",
    "\n",
    "start <- Sys.time()\n",
    "paste(\"Start time: \", start, sep=\"\")\n",
    "ans <- gridSearch02_xgb(seed_smp, gbtrain, eta_vector, maxDepth_vector, gamma_vector)\n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 2.55 mins\n",
    "\n",
    "(best_params <- ans[which(ans$acc == max(ans$acc)),]$params)\n",
    "#  '0.24--6--1'\n",
    "\n",
    "(best_xgb_acc <- ans[which(ans$acc == max(ans$acc)),]$acc)\n",
    "#  0.7936\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an average accuracy score for xgb_best on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time difference of 16.06 secs"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get stable scores for the best xgboost model.  I will\n",
    "# refer to this model as xgb_best.  Note that 2000 seeds\n",
    "# are being used. \n",
    "\n",
    "set.seed(1433)\n",
    "seed_smp <- sample(1:9999, 2000, replace=FALSE)\n",
    "\n",
    "datout <- rep(NA, 2 * length(seed_smp))\n",
    "dim(datout) <- c(length(seed_smp), 2)\n",
    "datout <- as.data.frame(datout)\n",
    "colnames(datout) <- c(\"seed\",\"Acc\")\n",
    "datout$seed <- seed_smp\n",
    "\n",
    "start <- Sys.time()\n",
    "for(i in 1:length(seed_smp)) {\n",
    "    \n",
    "    set.seed(seed_smp[i])\n",
    "    xgbmod <- xgboost(data= dtrain, booster=\"gbtree\", \n",
    "                 objective=\"multi:softmax\", num_class=3,\n",
    "                 eta=0.24, max_depth=6, gamma=1, \n",
    "                 subsample=0.5, nrounds=8, nthread=10,\n",
    "                 eval_metric=\"merror\", verbose=0)\n",
    "    \n",
    "    preds <- predict(xgbmod, as.matrix(gbtrain[, -1]))\n",
    "    preds <- as.factor(preds)\n",
    "    names(preds) <- rownames(gbtrain)   \n",
    "    ans <- get_confusion(preds, gbtrain[, \"label\", drop=FALSE])\n",
    "    \n",
    "    mat <- as.matrix(ans[[1]])\n",
    "    percent_correct <- sum(diag(mat))/floor(sum(mat))\n",
    "    datout[i, c(\"Acc\")] <- round(percent_correct, 4)\n",
    "    \n",
    "}\n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 16 secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAMAAAC323mdAAAC/VBMVEUAAAABAQECAgIDAwME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\n/weV6d/GA0U9fQAAAABJRU5ErkJggg==",
      "text/plain": [
       "Plot with title “Distribution of accuracy scores for xgb_best on trainset”"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width= 10, repr.plot.height= 6)\n",
    "hist(datout$Acc, breaks=16, xlab=\"accuracy\",\n",
    "     main=\"Distribution of accuracy scores for xgb_best on trainset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.902"
      ],
      "text/latex": [
       "0.902"
      ],
      "text/markdown": [
       "0.902"
      ],
      "text/plain": [
       "[1] 0.902"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# xgb_best's average accuracy score on the trainset data.\n",
    "\n",
    "round(mean(datout$Acc), 4)\n",
    "# For rfclf_best we had an accuracy score of 0.8040\n",
    "\n",
    "# 0.902\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "340"
      ],
      "text/latex": [
       "340"
      ],
      "text/markdown": [
       "340"
      ],
      "text/plain": [
       "[1] 340"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>3837</li><li>947</li><li>381</li><li>4998</li><li>2141</li><li>4887</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 3837\n",
       "\\item 947\n",
       "\\item 381\n",
       "\\item 4998\n",
       "\\item 2141\n",
       "\\item 4887\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 3837\n",
       "2. 947\n",
       "3. 381\n",
       "4. 4998\n",
       "5. 2141\n",
       "6. 4887\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 3837  947  381 4998 2141 4887"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Identify seeds with an accuracy score near 0.9020.\n",
    "\n",
    "xgb_candidate_seeds <- datout[which((datout$Acc > 0.8990) & (datout$Acc < 0.9050)),]$seed\n",
    "length(xgb_candidate_seeds)\n",
    "#  340\n",
    "head(xgb_candidate_seeds)\n",
    "#  4998\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best xgb_boost model for the purposes of showing\n",
    "# average performance on the training set.  The seed \n",
    "# value is part of the model.\n",
    "\n",
    "set.seed(4998)\n",
    "xgb_best <- xgboost(data= dtrain, booster=\"gbtree\", \n",
    "                 objective=\"multi:softmax\", num_class=3,\n",
    "                 eta=0.24, max_depth=6, gamma=1, \n",
    "                 subsample=0.5, nrounds=8, nthread=10,\n",
    "                 eval_metric=\"merror\", verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.9045\n"
     ]
    }
   ],
   "source": [
    "# Get accuracy score for xgb_best.\n",
    "\n",
    "preds <- predict(xgb_best, as.matrix(gbtrain[, -1]))\n",
    "preds <- as.factor(preds)\n",
    "names(preds) <- rownames(gbtrain)   \n",
    "ans <- get_confusion(preds, gbtrain[, \"label\", drop=FALSE])\n",
    "   \n",
    "acc <- round(as.numeric(ans[[2]]), 4)\n",
    "print(acc)\n",
    "# 0.9045\n",
    "\n",
    "# This is the AVERAGE PERFORMANCE of our best xgboost model on\n",
    "# the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 3 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>0</th><th scope=col>1</th><th scope=col>2</th><th scope=col>class.error</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>0</th><td>55</td><td> 4</td><td> 0</td><td>0.0678</td></tr>\n",
       "\t<tr><th scope=row>1</th><td> 6</td><td>61</td><td> 4</td><td>0.1408</td></tr>\n",
       "\t<tr><th scope=row>2</th><td> 0</td><td> 3</td><td>45</td><td>0.0625</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 3 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & 0 & 1 & 2 & class.error\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t0 & 55 &  4 &  0 & 0.0678\\\\\n",
       "\t1 &  6 & 61 &  4 & 0.1408\\\\\n",
       "\t2 &  0 &  3 & 45 & 0.0625\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 3 × 4\n",
       "\n",
       "| <!--/--> | 0 &lt;dbl&gt; | 1 &lt;dbl&gt; | 2 &lt;dbl&gt; | class.error &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 0 | 55 |  4 |  0 | 0.0678 |\n",
       "| 1 |  6 | 61 |  4 | 0.1408 |\n",
       "| 2 |  0 |  3 | 45 | 0.0625 |\n",
       "\n"
      ],
      "text/plain": [
       "  0  1  2  class.error\n",
       "0 55  4  0 0.0678     \n",
       "1  6 61  4 0.1408     \n",
       "2  0  3 45 0.0625     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# xgb_best misclassifies, on average, 17 of the 178\n",
    "# records.  rfclf_best misclassified, on average, 32 \n",
    "# of the 178 records.  These are scores on the training set.\n",
    "\n",
    "ans[[1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get comparative cross-val score for best xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is called from get_cvScore_xgbBest.\n",
    "# It returns an accuracy score on the validation set.\n",
    "\n",
    "get_Acc_xgbBest <- function(traindat, valdat) {\n",
    "    \n",
    "    dtrain <- xgb.DMatrix(data = as.matrix(traindat[, -1]), \n",
    "                          label = traindat$label)\n",
    " \n",
    "    # This is our current best xgboost model.\n",
    "    set.seed(4998)\n",
    "    xgbmod <- xgboost(data= dtrain, booster=\"gbtree\", \n",
    "                      objective=\"multi:softmax\", num_class=3,\n",
    "                      eta=0.24, max_depth=6, gamma=1, \n",
    "                      subsample=0.5, nrounds=8, nthread=10,\n",
    "                      eval_metric=\"merror\", verbose=0)\n",
    "        \n",
    "    preds <- predict(xgbmod, as.matrix(valdat[, -1]))\n",
    "    preds <- as.factor(preds)\n",
    "    names(preds) <- rownames(valdat)\n",
    "    ans <- get_confusion(preds, valdat[, \"label\", drop=FALSE])\n",
    "    return(ans[[2]])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain a cross-validation score, averaging the\n",
    "# accuracy scores of the folds.  This function is called from\n",
    "# compute_cvScore_xgb.\n",
    "\n",
    "get_cvScore_xgbBest <- function(seed, dat, folds= 5) {\n",
    "    \n",
    "    # divide dat by the number of folds \n",
    "    segment_size <- round(nrow(dat)/folds)\n",
    "    diff <- nrow(dat) - folds * segment_size\n",
    "    last_seg_size <- segment_size + diff\n",
    "    segmentsv <- c(rep(segment_size, (folds - 1)), last_seg_size)\n",
    "    stopifnot(sum(segmentsv) == nrow(dat))\n",
    "    \n",
    "    # shuffle dat\n",
    "    set.seed(seed)\n",
    "    smp <- sample(rownames(dat), nrow(dat), replace= FALSE)\n",
    "    dat <- dat[smp,]\n",
    "    \n",
    "    # split the data into the folds\n",
    "    row_list <- vector(\"list\", length= folds)\n",
    "    names(row_list) <- as.character(1:folds)\n",
    "    startpt <- 1\n",
    "    for(i in 1:folds) {\n",
    "        endpt <- startpt + segmentsv[i] - 1\n",
    "        stopifnot(endpt <= nrow(dat))\n",
    "        row_list[[i]] <- rownames(dat)[startpt:endpt]\n",
    "        startpt <- endpt + 1\n",
    "    }\n",
    "    \n",
    "    train_list <- test_list <- vector(\"list\", length= folds)\n",
    "    for(j in 1:folds) {\n",
    "        testdat <- dat[row_list[[j]],]\n",
    "        traindat <- dat[which(!(rownames(dat) %in% rownames(testdat))),]\n",
    "        stopifnot((length(rownames(traindat)) + length(rownames(testdat))) == dim(dat)[1])\n",
    "        test_list[[j]] <- testdat\n",
    "        train_list[[j]] <- traindat\n",
    "    }\n",
    "\n",
    "    # Do NOT use mcmapply with xgboost.  The function is \n",
    "    # already using 10 cores, or threads.\n",
    "    scores <- mapply(get_Acc_xgbBest, train_list, test_list,\n",
    "                     SIMPLIFY= TRUE)\n",
    "    \n",
    "    # The following average is over the 5 folds created using\n",
    "    # the current seed.\n",
    "    return(round(mean(scores), 5))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get a cross-val accuracy score over many \n",
    "# folds for the best xgboost model.\n",
    "\n",
    "compute_cvScore_xgb <- function(seedv, dat) {\n",
    "    \n",
    "    seedv_len <- length(seedv)\n",
    "    result <- rep(NA, length=seedv_len)\n",
    "    names(result) <- as.character(seedv)\n",
    "    \n",
    "    for(i in 1:seedv_len) {\n",
    "        cur.seed <- seedv[i]\n",
    "        # For each seed in seedv, compute a cross-val\n",
    "        # accuracy score.\n",
    "        result[i] <- get_cvScore_xgbBest(cur.seed, dat)\n",
    "    }\n",
    "    return(result)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>label</th><th scope=col>Hue</th><th scope=col>Phenols</th><th scope=col>Alcalinity</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>113</th><td>1</td><td>1.23</td><td>1.75</td><td>20</td></tr>\n",
       "\t<tr><th scope=row>159</th><td>2</td><td>0.57</td><td>2.80</td><td>25</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>0</td><td>1.09</td><td>3.00</td><td>16</td></tr>\n",
       "\t<tr><th scope=row>131</th><td>2</td><td>0.76</td><td>1.51</td><td>18</td></tr>\n",
       "\t<tr><th scope=row>137</th><td>2</td><td>0.75</td><td>1.38</td><td>21</td></tr>\n",
       "\t<tr><th scope=row>133</th><td>2</td><td>0.66</td><td>1.15</td><td>24</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & label & Hue & Phenols & Alcalinity\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t113 & 1 & 1.23 & 1.75 & 20\\\\\n",
       "\t159 & 2 & 0.57 & 2.80 & 25\\\\\n",
       "\t21 & 0 & 1.09 & 3.00 & 16\\\\\n",
       "\t131 & 2 & 0.76 & 1.51 & 18\\\\\n",
       "\t137 & 2 & 0.75 & 1.38 & 21\\\\\n",
       "\t133 & 2 & 0.66 & 1.15 & 24\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 4\n",
       "\n",
       "| <!--/--> | label &lt;dbl&gt; | Hue &lt;dbl&gt; | Phenols &lt;dbl&gt; | Alcalinity &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 113 | 1 | 1.23 | 1.75 | 20 |\n",
       "| 159 | 2 | 0.57 | 2.80 | 25 |\n",
       "| 21 | 0 | 1.09 | 3.00 | 16 |\n",
       "| 131 | 2 | 0.76 | 1.51 | 18 |\n",
       "| 137 | 2 | 0.75 | 1.38 | 21 |\n",
       "| 133 | 2 | 0.66 | 1.15 | 24 |\n",
       "\n"
      ],
      "text/plain": [
       "    label Hue  Phenols Alcalinity\n",
       "113 1     1.23 1.75    20        \n",
       "159 2     0.57 2.80    25        \n",
       "21  0     1.09 3.00    16        \n",
       "131 2     0.76 1.51    18        \n",
       "137 2     0.75 1.38    21        \n",
       "133 2     0.66 1.15    24        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(gbtrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-05-30 07:35:28'"
      ],
      "text/latex": [
       "'Start time: 2021-05-30 07:35:28'"
      ],
      "text/markdown": [
       "'Start time: 2021-05-30 07:35:28'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-05-30 07:35:28\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 1.23 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the same initial seed as we did to get the \n",
    "# corresponding score for the random forest model.\n",
    "\n",
    "set.seed(1931)\n",
    "seedv <- sample(1:9999, 2000, replace=FALSE)\n",
    "\n",
    "start <- Sys.time()\n",
    "paste(\"Start time: \", start, sep=\"\")\n",
    "ans <- compute_cvScore_xgb(seedv, gbtrain)\n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 1.24 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "  0.719   0.780   0.792   0.792   0.804   0.849 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.792"
      ],
      "text/latex": [
       "0.792"
      ],
      "text/markdown": [
       "0.792"
      ],
      "text/plain": [
       "[1] 0.792"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is our comparative cross-val accuracy score for the\n",
    "# current best gradient boosting model.\n",
    "\n",
    "round(mean(ans), 4)\n",
    "# 0.7920\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.7925"
      ],
      "text/latex": [
       "0.7925"
      ],
      "text/markdown": [
       "0.7925"
      ],
      "text/plain": [
       "[1] 0.7925"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.019219"
      ],
      "text/latex": [
       "0.019219"
      ],
      "text/markdown": [
       "0.019219"
      ],
      "text/plain": [
       "[1] 0.019219"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(median(ans), 4)\n",
    "round(sd(ans), 6)\n",
    "# 0.7925\n",
    "# 0.019219\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAMAAAC323mdAAAC+lBMVEUAAAABAQECAgIDAwME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\nAAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title “Distribution of cross-val accuracy scores for xgb_best”"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width= 10, repr.plot.height= 6)\n",
    "hist(ans, breaks=16, xlab=\"accuracy\",\n",
    "     main=\"Distribution of cross-val accuracy scores for xgb_best\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Hue           Phenols       Alcalinity  \n",
       " Min.   :0.480   Min.   :0.98   Min.   :10.6  \n",
       " 1st Qu.:0.782   1st Qu.:1.74   1st Qu.:17.2  \n",
       " Median :0.965   Median :2.35   Median :19.5  \n",
       " Mean   :0.957   Mean   :2.30   Mean   :19.5  \n",
       " 3rd Qu.:1.120   3rd Qu.:2.80   3rd Qu.:21.5  \n",
       " Max.   :1.710   Max.   :3.88   Max.   :30.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(train[, -1])\n",
    "\n",
    "# All variables are numeric and positive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Hue            Phenols          Alcalinity      \n",
       " Min.   :-2.089   Min.   :-2.1013   Min.   :-2.66350  \n",
       " 1st Qu.:-0.765   1st Qu.:-0.8830   1st Qu.:-0.68720  \n",
       " Median : 0.033   Median : 0.0957   Median : 0.00151  \n",
       " Mean   : 0.000   Mean   : 0.0000   Mean   : 0.00000  \n",
       " 3rd Qu.: 0.711   3rd Qu.: 0.8067   3rd Qu.: 0.60039  \n",
       " Max.   : 3.292   Max.   : 2.5324   Max.   : 3.14564  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For SVM modeling, we need to scale the data.  In \n",
    "# Parts 1 and 2 we got a better model if we scaled\n",
    "# the data without applying any prior transformations.\n",
    "# I will take the same approach with this data set.\n",
    "\n",
    "svmtrain <- train\n",
    "\n",
    "svm_scaled <- scale(svmtrain[, -1])\n",
    "summary(svm_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach response variable.\n",
    "\n",
    "svm_scaled <- as.data.frame(cbind(svmtrain$Type, svm_scaled),\n",
    "                            row.names=rownames(svmtrain))\n",
    "colnames(svm_scaled) <- colnames(svmtrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1  2  3 class.error\n",
      "1 48 11  0      0.1864\n",
      "2 10 56  5      0.2113\n",
      "3  0  3 45      0.0625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "''"
      ],
      "text/latex": [
       "''"
      ],
      "text/markdown": [
       "''"
      ],
      "text/plain": [
       "[1] \"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Accuracy score for svm model: 0.8371'"
      ],
      "text/latex": [
       "'Accuracy score for svm model: 0.8371'"
      ],
      "text/markdown": [
       "'Accuracy score for svm model: 0.8371'"
      ],
      "text/plain": [
       "[1] \"Accuracy score for svm model: 0.8371\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try with kernel = radial basis function.\n",
    "\n",
    "svm01 <- svm(I(as.factor(Type)) ~ ., data=svm_scaled, kernel=\"radial\",\n",
    "             gamma= 0.01, cost= 30, scale=FALSE)\n",
    "\n",
    "preds <- as.factor(fitted(svm01))\n",
    "ans <- get_confusion(preds, svm_scaled[, \"Type\", drop=FALSE])\n",
    "print(ans[[1]])\n",
    "\"\"\n",
    "paste0(\"Accuracy score for svm model: \", as.character(ans[[2]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the svm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute an accuracy score for an svm cv-fold.\n",
    "\n",
    "get_Acc_svm <- function(traindat, valdat, gamma, cost) {\n",
    "    \n",
    "    # Scale traindat.\n",
    "    train_scaled <- scale(traindat[, -1])\n",
    "    train_centers <- attr(train_scaled, \"scaled:center\")\n",
    "    train_scales <- attr(train_scaled, \"scaled:scale\")\n",
    "    train_scaled <- as.data.frame(cbind(traindat$Type, train_scaled),\n",
    "                                  row.names=rownames(traindat))\n",
    "    colnames(train_scaled) <- colnames(traindat)\n",
    "    \n",
    "    svmmod <- svm(I(as.factor(Type)) ~ ., data= train_scaled, gamma=gamma,\n",
    "                    cost=cost, scale=FALSE, kernel=\"radial\")\n",
    "    \n",
    "    # Scale valdat.\n",
    "    test_scaled <- scale(valdat[, -1], center=train_centers,\n",
    "                         scale=train_scales)\n",
    "    test_scaled <- as.data.frame(test_scaled, row.names=rownames(valdat))\n",
    "    \n",
    "    preds <- as.factor(predict(svmmod, newdata= test_scaled))\n",
    "    ans <- get_confusion(preds, valdat[, \"Type\", drop=FALSE])\n",
    "    return(ans[[2]])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This grid search searches for the best parameters for svm\n",
    "# modeling of the data. \n",
    "\n",
    "gridSearch_svm <- function(seedv, dat, gammav, costv, folds=5) {\n",
    "    \n",
    "    gamma_len <- length(gammav)\n",
    "    cost_len <- length(costv)\n",
    "    # We need to capture the gridSearch parameters as well as \n",
    "    # the cross-val  scores.\n",
    "    datout <- rep(NA, 2 * gamma_len * cost_len)\n",
    "    dim(datout) <- c((gamma_len * cost_len), 2)\n",
    "    datout <- as.data.frame(datout)\n",
    "    colnames(datout) <- c(\"params\", \"Acc\")\n",
    "    datout$params <- \"\"\n",
    "    \n",
    "    # Divide dat by the number of folds to get a\n",
    "    # size for each fold.\n",
    "    segment_size <- round(nrow(dat)/folds)\n",
    "    diff <- nrow(dat) - folds * segment_size\n",
    "    last_seg_size <- segment_size + diff\n",
    "    segmentsv <- c(rep(segment_size, (folds - 1)), last_seg_size)\n",
    "    stopifnot(sum(segmentsv) == nrow(dat))\n",
    "    \n",
    "    index <- 0\n",
    "    for(i in 1:gamma_len) {\n",
    "        gamma <- gammav[i]\n",
    "        for(j in 1:cost_len) {\n",
    "            index <- index + 1\n",
    "            cost <- costv[j]\n",
    "            param_string <- paste(as.character(gamma), \n",
    "                                  as.character(cost), sep= \"--\")\n",
    "            datout$params[index] <- param_string\n",
    "            \n",
    "            # Each set of parameters gets tested over many folds.\n",
    "            # The different folds are created using different seeds.\n",
    "    \n",
    "            # Create a vector to store the Acc score for each seed.\n",
    "            seedv_len <- length(seedv)\n",
    "            seed_scores <- rep(NA, seedv_len)\n",
    "    \n",
    "            for(h in 1:seedv_len) {\n",
    "                # shuffle dat\n",
    "                cur_seed <- seedv[h]\n",
    "                set.seed(cur_seed)\n",
    "                smp <- sample(rownames(dat), nrow(dat), replace= FALSE)\n",
    "                dat <- dat[smp,]\n",
    "    \n",
    "                # Each element of row_list will be the rows we pick\n",
    "                # out for one of the folds.  E.g., the first element\n",
    "                # of row_list will contain the rows we want for the\n",
    "                # first fold, the second element of row_list will\n",
    "                # contain the rows we want for the second fold, and\n",
    "                # so forth.\n",
    "                row_list <- vector(\"list\", length=folds)\n",
    "                names(row_list) <- as.character(1:folds)\n",
    "                startpt <- 1\n",
    "                for(k in 1:folds) {\n",
    "                    endpt <- startpt + segmentsv[k] - 1\n",
    "                    stopifnot(endpt <= nrow(dat))\n",
    "                    row_list[[k]] <- rownames(dat)[startpt:endpt]\n",
    "                    startpt <- endpt + 1\n",
    "                }\n",
    "                \n",
    "                train_list <- test_list <- vector(\"list\", length= folds)\n",
    "                for(k in 1:folds) {\n",
    "                    testdat <- dat[row_list[[k]],]\n",
    "                    traindat <- dat[which(!(rownames(dat) %in% rownames(testdat))),]\n",
    "                    stopifnot((length(rownames(traindat)) + length(rownames(testdat))) == nrow(dat))\n",
    "                    test_list[[k]] <- testdat\n",
    "                    train_list[[k]] <- traindat\n",
    "                }\n",
    "                \n",
    "                # When there are only 5 folds, only 5 cores get used.\n",
    "                scores <- mcmapply(get_Acc_svm, train_list, test_list,\n",
    "                                   MoreArgs= list(gamma=gamma, cost=cost),\n",
    "                                   SIMPLIFY= TRUE, mc.cores=5)\n",
    "                # For the current seed, store the average of the accuracy\n",
    "                # scores, the average taken over the folds.\n",
    "                seed_scores[h] <- round(mean(scores), 5)\n",
    "        \n",
    "            } ## end of for-loop, index h\n",
    "            \n",
    "            # Here I am taking an average of average scores.  This\n",
    "            # could be improved by simply taking a single average.\n",
    "            datout$Acc[index] <- round(mean(seed_scores), 5)\n",
    "            \n",
    "        } ## end of for-loop, index j\n",
    "    } ## end of for-loop, index i\n",
    "    \n",
    "    return(datout)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-05-30 07:41:47'"
      ],
      "text/latex": [
       "'Start time: 2021-05-30 07:41:47'"
      ],
      "text/markdown": [
       "'Start time: 2021-05-30 07:41:47'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-05-30 07:41:47\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 5.19 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'0.03--30'"
      ],
      "text/latex": [
       "'0.03--30'"
      ],
      "text/markdown": [
       "'0.03--30'"
      ],
      "text/plain": [
       "[1] \"0.03--30\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.82814"
      ],
      "text/latex": [
       "0.82814"
      ],
      "text/markdown": [
       "0.82814"
      ],
      "text/plain": [
       "[1] 0.82814"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the best set of parameters.\n",
    "\n",
    "set.seed(7543)\n",
    "seed_vector <- sample(1:9999, 200, replace=FALSE)\n",
    "\n",
    "gamma_v <- seq(0.01, 0.1, by=0.01)\n",
    "cost_v <- seq(10, 50, by=10)\n",
    "\n",
    "start <- Sys.time()\n",
    "paste(\"Start time: \", start, sep=\"\")\n",
    "ans <- gridSearch_svm(seed_vector, svmtrain, gamma_v, cost_v)\n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 5.19 mins\n",
    "\n",
    "(best_params <- ans[which(ans$Acc == max(ans$Acc)),]$params)\n",
    "# '0.03--30'\n",
    "\n",
    "(best_Acc <- ans[which(ans$Acc == max(ans$Acc)),]$Acc)\n",
    "# 0.8281\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-05-30 07:48:50'"
      ],
      "text/latex": [
       "'Start time: 2021-05-30 07:48:50'"
      ],
      "text/markdown": [
       "'Start time: 2021-05-30 07:48:50'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-05-30 07:48:50\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 1.17 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'0.03--25'"
      ],
      "text/latex": [
       "'0.03--25'"
      ],
      "text/markdown": [
       "'0.03--25'"
      ],
      "text/plain": [
       "[1] \"0.03--25\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.82811"
      ],
      "text/latex": [
       "0.82811"
      ],
      "text/markdown": [
       "0.82811"
      ],
      "text/plain": [
       "[1] 0.82811"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Refine the search.\n",
    "\n",
    "set.seed(1981)\n",
    "seed_vector <- sample(1:9999, 250, replace=FALSE)\n",
    "\n",
    "gamma_v <- seq(0.02, 0.04, by=0.01)\n",
    "cost_v <- c(25, 30, 35)\n",
    "\n",
    "start <- Sys.time()\n",
    "paste(\"Start time: \", start, sep=\"\")\n",
    "ans <- gridSearch_svm(seed_vector, svmtrain, gamma_v, cost_v)\n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 1.17 mins\n",
    "\n",
    "(best_params <- ans[which(ans$Acc == max(ans$Acc)),]$params)\n",
    "# '0.03--25'\n",
    "\n",
    "(best_Acc <- ans[which(ans$Acc == max(ans$Acc)),]$Acc)\n",
    "# 0.8281\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get scores for best svm (svm02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1  2  3 class.error\n",
      "1 55  4  0      0.0678\n",
      "2 12 53  6      0.2535\n",
      "3  0  3 45      0.0625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "''"
      ],
      "text/latex": [
       "''"
      ],
      "text/markdown": [
       "''"
      ],
      "text/plain": [
       "[1] \"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Accuracy score for svm02 (best svm): 0.8596'"
      ],
      "text/latex": [
       "'Accuracy score for svm02 (best svm): 0.8596'"
      ],
      "text/markdown": [
       "'Accuracy score for svm02 (best svm): 0.8596'"
      ],
      "text/plain": [
       "[1] \"Accuracy score for svm02 (best svm): 0.8596\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construct an svm with the identified parameters.\n",
    "\n",
    "# Set probability=TRUE in order to get probability estimates\n",
    "# from the output.\n",
    "svm02 <- svm(I(as.factor(Type)) ~ ., data=svm_scaled, kernel=\"radial\",\n",
    "             gamma= 0.03, cost= 25, scale=FALSE, probability=TRUE)\n",
    "\n",
    "preds <- as.factor(fitted(svm02))\n",
    "ans <- get_confusion(preds, svm_scaled[, \"Type\", drop=FALSE])\n",
    "print(ans[[1]])\n",
    "\"\"\n",
    "paste0(\"Accuracy score for svm02 (best svm): \", as.character(ans[[2]]))\n",
    "# 0.8596\n",
    "\n",
    "# 25 of the 178 records are misclassified.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get comparative cross-val score for best svm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain a cross-validation score, averaging the\n",
    "# accuracy scores of the folds.  This function is called from\n",
    "# compute_cvScore_svm.\n",
    "\n",
    "get_cvScore_svm02 <- function(seed, dat, folds= 5) {\n",
    "    \n",
    "    # divide dat by the number of folds \n",
    "    segment_size <- round(nrow(dat)/folds)\n",
    "    diff <- nrow(dat) - folds * segment_size\n",
    "    last_seg_size <- segment_size + diff\n",
    "    segmentsv <- c(rep(segment_size, (folds - 1)), last_seg_size)\n",
    "    stopifnot(sum(segmentsv) == nrow(dat))\n",
    "    \n",
    "    # shuffle dat\n",
    "    set.seed(seed)\n",
    "    smp <- sample(rownames(dat), nrow(dat), replace= FALSE)\n",
    "    dat <- dat[smp,]\n",
    "    \n",
    "    # split the data into the folds\n",
    "    row_list <- vector(\"list\", length= folds)\n",
    "    names(row_list) <- as.character(1:folds)\n",
    "    startpt <- 1\n",
    "    for(i in 1:folds) {\n",
    "        endpt <- startpt + segmentsv[i] - 1\n",
    "        stopifnot(endpt <= nrow(dat))\n",
    "        row_list[[i]] <- rownames(dat)[startpt:endpt]\n",
    "        startpt <- endpt + 1\n",
    "    }\n",
    "    \n",
    "    train_list <- test_list <- vector(\"list\", length= folds)\n",
    "    for(j in 1:folds) {\n",
    "        testdat <- dat[row_list[[j]],]\n",
    "        traindat <- dat[which(!(rownames(dat) %in% rownames(testdat))),]\n",
    "        stopifnot((length(rownames(traindat)) + length(rownames(testdat))) == dim(dat)[1])\n",
    "        test_list[[j]] <- testdat\n",
    "        train_list[[j]] <- traindat\n",
    "    }\n",
    "\n",
    "    scores <- mcmapply(get_Acc_svm, train_list, test_list,\n",
    "                       MoreArgs= list(gamma=0.03, cost=25),\n",
    "                       SIMPLIFY= TRUE, mc.cores=5)\n",
    "    \n",
    "    # The following average is over the 5 folds created using\n",
    "    # the current seed.\n",
    "    return(round(mean(scores), 5))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get a cross-val accuracy score over many \n",
    "# folds for the svm02 model.\n",
    "\n",
    "compute_cvScore_svm <- function(seedv, dat) {\n",
    "    \n",
    "    seedv_len <- length(seedv)\n",
    "    result <- rep(NA, length=seedv_len)\n",
    "    names(result) <- as.character(seedv)\n",
    "    \n",
    "    for(i in 1:seedv_len) {\n",
    "        cur.seed <- seedv[i]\n",
    "        # For each seed in seedv, compute a cross-val\n",
    "        # accuracy score.\n",
    "        result[i] <- get_cvScore_svm02(cur.seed, dat)\n",
    "    }\n",
    "    return(result)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-05-30 07:53:25'"
      ],
      "text/latex": [
       "'Start time: 2021-05-30 07:53:25'"
      ],
      "text/markdown": [
       "'Start time: 2021-05-30 07:53:25'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-05-30 07:53:25\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 1.04 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Again, use the same initial seed we used for\n",
    "# these scores above.  The result is over 10000 folds.\n",
    "\n",
    "set.seed(1931)\n",
    "seed_vector <- sample(1:9999, 2000, replace=FALSE)\n",
    "\n",
    "start <- Sys.time()\n",
    "paste(\"Start time: \", start, sep=\"\")\n",
    "ans <- compute_cvScore_svm(seed_vector, svmtrain)\n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 1.04 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "  0.782   0.820   0.827   0.828   0.837   0.866 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.8278"
      ],
      "text/latex": [
       "0.8278"
      ],
      "text/markdown": [
       "0.8278"
      ],
      "text/plain": [
       "[1] 0.8278"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is our comparative cross-val accuracy score for the\n",
    "# current best svm model.\n",
    "\n",
    "round(mean(ans), 4)\n",
    "# 0.8278\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.8271"
      ],
      "text/latex": [
       "0.8271"
      ],
      "text/markdown": [
       "0.8271"
      ],
      "text/plain": [
       "[1] 0.8271"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.012713"
      ],
      "text/latex": [
       "0.012713"
      ],
      "text/markdown": [
       "0.012713"
      ],
      "text/plain": [
       "[1] 0.012713"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(median(ans), 4)\n",
    "round(sd(ans), 6)\n",
    "# median: 0.8271\n",
    "# sd: 0.012713\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAMAAAC323mdAAAC+lBMVEUAAAABAQECAgIDAwME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",
      "text/plain": [
       "Plot with title “Distribution of cross-val accuracy scores for svm02”"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width= 10, repr.plot.height= 6)\n",
    "hist(ans, breaks=16, xlab=\"accuracy\",\n",
    "     main=\"Distribution of cross-val accuracy scores for svm02\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMMENTS (RESULTS THUS FAR):\n",
    "\n",
    "# Thus far, svm02 is our best model.  It has a cross-val score \n",
    "# of 0.8278.  This equates to an average of 30.65 misclassified\n",
    "# for every 178 records.\n",
    "# The next best model is rfclf_best.  It has a cross-val score\n",
    "# of 0.8074; this equates to an average of 34.28 misclassified\n",
    "# for every 178 records.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: k-means models, base and initial hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base k-means model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Parts 1 and 2 we were able to find a k-means hybrid model which outperformed all competing models.  One thing that likely made this possible was that the base k-means model itself was nearly as good classifying the data as any of the other best models.  With the current example, the base k-means model does not perform nearly as well as the models we have already looked at.\n",
    "\n",
    "Among other things, this means that it will likely be more difficult to construct a hybrid k-means model which outperforms svm02.  It is much more difficult for the k-means algorithm to contribute something additional to the classification task when it has low performance on that task relative to the other models.  Another disadvantage for our hybrid model, relative to what we saw in Parts 1 and 2, is that here we have to beat an accuracy score of almost 83% on 178 records, whereas in Part 2 (for example) we had to beat an accuracy score of around 70.5% on 400 records.  Thus, with the wine dataset, the bar is much higher.  I could lower it a bit by choosing a different set of 3 predictors, but let's see what happens.\n",
    "\n",
    "\n",
    "\n",
    "                                    * * * * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Hue           Phenols        Alcalinity   \n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.000  \n",
       " 1st Qu.:0.246   1st Qu.:0.263   1st Qu.:0.340  \n",
       " Median :0.394   Median :0.474   Median :0.459  \n",
       " Mean   :0.388   Mean   :0.453   Mean   :0.459  \n",
       " 3rd Qu.:0.520   3rd Qu.:0.628   3rd Qu.:0.562  \n",
       " Max.   :1.000   Max.   :1.000   Max.   :1.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First scale the data.  Two kinds of scaling are\n",
    "# being applied here.  In Section 5 below, I employ\n",
    "# a different approach to scaling.\n",
    "\n",
    "df <- train\n",
    "\n",
    "df02 <- scale(df[, -1], center=TRUE, scale=TRUE)\n",
    "\n",
    "# Apply min-max scaling, moving all values between 0 and 1.\n",
    "df_scaled <- apply(as.matrix(df02), MARGIN=2, range01)\n",
    "df_scaled <- as.data.frame(cbind(df$Type, df_scaled),\n",
    "                           row.names=rownames(df))\n",
    "colnames(df_scaled) <- colnames(df)\n",
    "summary(df_scaled[, -1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 74 44 60\n"
     ]
    }
   ],
   "source": [
    "# Run k-means with number of clusters set to 3.\n",
    "\n",
    "set.seed(1233)\n",
    "fit_km <- kmeans(df_scaled[, -1], 3, iter.max = 50, nstart = 30)\n",
    "print(fit_km$size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Type</th><th scope=col>cluster</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>113</th><td>2</td><td>2</td></tr>\n",
       "\t<tr><th scope=row>159</th><td>3</td><td>2</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>1</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>131</th><td>3</td><td>3</td></tr>\n",
       "\t<tr><th scope=row>137</th><td>3</td><td>3</td></tr>\n",
       "\t<tr><th scope=row>133</th><td>3</td><td>3</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & Type & cluster\\\\\n",
       "  & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t113 & 2 & 2\\\\\n",
       "\t159 & 3 & 2\\\\\n",
       "\t21 & 1 & 1\\\\\n",
       "\t131 & 3 & 3\\\\\n",
       "\t137 & 3 & 3\\\\\n",
       "\t133 & 3 & 3\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | Type &lt;dbl&gt; | cluster &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 113 | 2 | 2 |\n",
       "| 159 | 3 | 2 |\n",
       "| 21 | 1 | 1 |\n",
       "| 131 | 3 | 3 |\n",
       "| 137 | 3 | 3 |\n",
       "| 133 | 3 | 3 |\n",
       "\n"
      ],
      "text/plain": [
       "    Type cluster\n",
       "113 2    2      \n",
       "159 3    2      \n",
       "21  1    1      \n",
       "131 3    3      \n",
       "137 3    3      \n",
       "133 3    3      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datout <- as.data.frame(cbind(df_scaled$Type, fit_km$cluster))\n",
    "colnames(datout) <- c(\"Type\", \"cluster\")\n",
    "rownames(datout) <- rownames(df_scaled)\n",
    "head(datout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "     1  2  3\n",
       "  1 50  9  0\n",
       "  2 24 32 15\n",
       "  3  0  3 45"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We need to map cluster to Type level.\n",
    "\n",
    "table(datout$Type, as.factor(datout$cluster))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 \n",
      "1 2 3 \n"
     ]
    }
   ],
   "source": [
    "ans <- as.matrix(table(datout$Type, as.factor(datout$cluster)))\n",
    "print(apply(ans, MARGIN=2, which.max))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 3 × 2 of type int</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>1</th><th scope=col>2</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>c1levs</th><td>1</td><td>2</td></tr>\n",
       "\t<tr><th scope=row>c2levs</th><td>1</td><td>2</td></tr>\n",
       "\t<tr><th scope=row>c3levs</th><td>2</td><td>3</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 3 × 2 of type int\n",
       "\\begin{tabular}{r|ll}\n",
       "  & 1 & 2\\\\\n",
       "\\hline\n",
       "\tc1levs & 1 & 2\\\\\n",
       "\tc2levs & 1 & 2\\\\\n",
       "\tc3levs & 2 & 3\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 3 × 2 of type int\n",
       "\n",
       "| <!--/--> | 1 | 2 |\n",
       "|---|---|---|\n",
       "| c1levs | 1 | 2 |\n",
       "| c2levs | 1 | 2 |\n",
       "| c3levs | 2 | 3 |\n",
       "\n"
      ],
      "text/plain": [
       "       1 2\n",
       "c1levs 1 2\n",
       "c2levs 1 2\n",
       "c3levs 2 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code snippet from get_mapping function (see below).\n",
    "# (The point of this cell is to show output for a \n",
    "# section of the code in get_mapping.)\n",
    "\n",
    "ans <- table(datout$Type, as.factor(datout$cluster))\n",
    "    \n",
    "    # For each cluster, pick out the row (i.e., Type level) which\n",
    "    # the cluster will almost certainly not map to.\n",
    "    min_levs <- apply(ans, MARGIN=2, which.min)\n",
    "    c1_minlev <- as.numeric(min_levs[\"1\"])\n",
    "    c2_minlev <- as.numeric(min_levs[\"2\"])\n",
    "    c3_minlev <- as.numeric(min_levs[\"3\"])\n",
    "    \n",
    "    # For each cluster, identify the remaining Type levels to\n",
    "    # which it could map.\n",
    "    c1levs <- c(1:3)[which(!(1:3 %in% c1_minlev))]\n",
    "    c2levs <- c(1:3)[which(!(1:3 %in% c2_minlev))]\n",
    "    c3levs <- c(1:3)[which(!(1:3 %in% c3_minlev))]\n",
    "    tmpdat <- rbind(c1levs, c2levs, c3levs)\n",
    "    colnames(tmpdat) <- 1:(dim(ans)[1] - 1)\n",
    "\n",
    "tmpdat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#&* Bookmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for function valid_mappings.\n",
    "\n",
    "all_levels <- function(rowvals, levs) {\n",
    "    \n",
    "    n_levels <- length(levs)\n",
    "    result <- FALSE\n",
    "    \n",
    "    if(sum(levs %in% rowvals) == n_levels) result <- TRUE\n",
    "    return(result)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>178</li><li>2</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 178\n",
       "\\item 2\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 178\n",
       "2. 2\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 178   2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply mapping resulting from fit_km above.\n",
    "\n",
    "tmpdat <- datout\n",
    "tmpdat[which(tmpdat$cluster== 1),]$Type <- 1\n",
    "tmpdat[which(tmpdat$cluster== 2),]$Type <- 2\n",
    "tmpdat[which(tmpdat$cluster== 3),]$Type <- 3\n",
    "dim(tmpdat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1  2  3 class.error\n",
      "1 50  9  0      0.1525\n",
      "2 24 32 15      0.5493\n",
      "3  0  3 45      0.0625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "''"
      ],
      "text/latex": [
       "''"
      ],
      "text/markdown": [
       "''"
      ],
      "text/plain": [
       "[1] \"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy score for the base k-means model: 0.7135\"\n"
     ]
    }
   ],
   "source": [
    "# Generate confusion matrix for the k-means clusters.\n",
    "# Output accuracy for this confusion matrix.\n",
    "\n",
    "preds <- as.factor(tmpdat$Type)\n",
    "names(preds) <- rownames(tmpdat)\n",
    "ans <- get_confusion(preds, df_scaled[, \"Type\", drop=FALSE])\n",
    "print(ans$matrix)\n",
    "''\n",
    "print(paste(\"Accuracy score for the base k-means model: \", as.character(ans[[2]]), sep=\"\"))\n",
    "# 0.7135\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get comparative cross-val score for the base k-means model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1  2  3 \n",
      "59 71 48 \n"
     ]
    }
   ],
   "source": [
    "ans <- as.vector(table(train$Type))\n",
    "names(ans) <- levels(train$Type); print(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function returning a list of possible mappings \n",
    "# between the k-means clusters and the Type levels.\n",
    "\n",
    "valid_mappings <- function(df, levs) {\n",
    "    \n",
    "    # Row 1 of df is for cluster 1, row 2 for \n",
    "    # cluster 2, and so forth.  Each row of df\n",
    "    # lists the Type levels the given cluster\n",
    "    # might be assigned to.\n",
    "    df_asList <- split(df, seq(nrow(df)))\n",
    "    ans <- expand.grid(df_asList, KEEP.OUT.ATTRS=FALSE)\n",
    "    valid_rows <- apply(as.matrix(ans), MARGIN=1, FUN=all_levels, levs=levs)\n",
    "    return(ans[valid_rows,])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function returning mapping between clusters and\n",
    "# Type levels.  As currently written, this function\n",
    "# only works for 3-cluster solutions.  We choose the\n",
    "# mapping that yields the best accuracy score.\n",
    "\n",
    "### NOTE: Choosing the mapping that yields the best\n",
    "### accuracy score does not give the k-means algorithm\n",
    "### an advantage over other algorithms.  This is \n",
    "### because we are comparing models based on how they\n",
    "### perform on new data, and the mapping we settle upon\n",
    "### is based on the training set data, not the validation\n",
    "### set.\n",
    "\n",
    "get_mapping <- function(dat, type_levels=c(1,2,3)) {\n",
    "    \n",
    "    # Returns a named vector on which a lookup can be done\n",
    "    # by cluster name.  Values of the vector are the Type\n",
    "    # levels.\n",
    "    \n",
    "    # dat is a dataframe with 2 columns, c(\"Type\",\"cluster\");\n",
    "    # nrow(dat) = number of predictions from the model;\n",
    "    # dat$Type = traindat$Type (from the calling function)\n",
    "    \n",
    "    # We find the correct mapping between cluster number and \n",
    "    # Type level by computing accuracy scores for the different\n",
    "    # valid mappings.   We choose the mapping with the best\n",
    "    # accuracy score.\n",
    "    \n",
    "    tbl <- as.matrix(table(dat$Type, as.factor(dat$cluster)))\n",
    "    # The colnames of tbl refer to the names of the clusters.\n",
    "    # initial_map <- apply(tbl, MARGIN=2, which.max)\n",
    "    # The names for initial_map are the cluster names; the\n",
    "    # values are the Type levels.\n",
    "    # c1_init <- as.numeric(initial_map[\"1\"])\n",
    "    # c2_init <- as.numeric(initial_map[\"2\"])\n",
    "    # c3_init <- as.numeric(initial_map[\"3\"])\n",
    "    # Ideally we have c1_init <> c2_init, c1_init <> c3_init, \n",
    "    # and c2_init <> c3_init\n",
    "    \n",
    "    # For each cluster, pick out the row (i.e., Type level) which\n",
    "    # the cluster will almost certainly not map to.\n",
    "    min_levs <- apply(tbl, MARGIN=2, which.min)\n",
    "    c1_minlev <- as.numeric(min_levs[\"1\"])\n",
    "    c2_minlev <- as.numeric(min_levs[\"2\"])\n",
    "    c3_minlev <- as.numeric(min_levs[\"3\"])\n",
    "    \n",
    "    # For each cluster, identify the remaining Type levels to\n",
    "    # which it could map.\n",
    "    c1levs <- c(1:3)[which(!(1:3 %in% c1_minlev))]\n",
    "    c2levs <- c(1:3)[which(!(1:3 %in% c2_minlev))]\n",
    "    c3levs <- c(1:3)[which(!(1:3 %in% c3_minlev))]\n",
    "    tmpdat01 <- rbind(c1levs, c2levs, c3levs)\n",
    "    colnames(tmpdat01) <- 1:(dim(tbl)[1] - 1)\n",
    "    \n",
    "    \n",
    "    # Identify valid candidate mappings.\n",
    "    df_maps <- valid_mappings(tmpdat01, type_levels)\n",
    "    rownames(df_maps) <- 1:nrow(df_maps)\n",
    "    \n",
    "    scores <- rep(NA, nrow(df_maps))    \n",
    "    for(i in 1:nrow(df_maps)) {\n",
    "        \n",
    "        cand_levs <- df_maps[i,]\n",
    "        # colnames(df_maps) are the cluster names:\n",
    "        names(cand_levs) <- colnames(df_maps)\n",
    "        \n",
    "        tmpdat <- dat\n",
    "        tmpdat[which(tmpdat$cluster== 1),]$Type <- as.numeric(cand_levs[\"1\"])\n",
    "        tmpdat[which(tmpdat$cluster== 2),]$Type <- as.numeric(cand_levs[\"2\"])\n",
    "        tmpdat[which(tmpdat$cluster== 3),]$Type <- as.numeric(cand_levs[\"3\"])\n",
    "        \n",
    "        preds <- as.factor(tmpdat$Type)\n",
    "        names(preds) <- rownames(tmpdat)\n",
    "        ans <- get_confusion(preds, dat[, \"Type\", drop=FALSE])\n",
    "        scores[i] <- ans[[2]]\n",
    "    }\n",
    "    \n",
    "    # I am transposing the extracted row in order to convert\n",
    "    # object to a vector.\n",
    "    vals <- t(df_maps[which.max(scores)[1],])[, 1]\n",
    "    vals <- as.vector(vals)\n",
    "    names(vals) <- colnames(df_maps)\n",
    "    return(vals)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for obtaining average of confusion matrix \n",
    "# accuracy score. This function is called from compute_cvScore_km.\n",
    "\n",
    "get_cvScore_km <- function(traindat, valdat) {\n",
    "    \n",
    "    # Transform and scale training set data \n",
    "    df <- scale(traindat[, -1], center=TRUE, scale=TRUE)\n",
    "    centers <- attr(df, \"scaled:center\")\n",
    "    scales <- attr(df, \"scaled:scale\")\n",
    "    df <- as.matrix(df)\n",
    "    traindat_scaled <- apply(df, MARGIN=2, range01)\n",
    "    colnames(traindat_scaled) <- colnames(traindat)[-1]\n",
    "    rownames(traindat_scaled) <- rownames(traindat)\n",
    "    \n",
    "    # Get mins and maxs for scaling of valdat.\n",
    "    traindat_mins <- as.numeric(apply(df, MARGIN=2, min))\n",
    "    traindat_maxs <- as.numeric(apply(df, MARGIN=2, max))\n",
    "    \n",
    "    \n",
    "    ############################\n",
    "    # Transform and scale valdat.\n",
    "    df02 <- scale(valdat[, -1], center=centers, scale=scales)\n",
    "    df02_t <- t(as.matrix(df02))\n",
    "    df02_asList <- split(df02_t, seq(nrow(df02_t)))\n",
    "    names(df02_asList) <- colnames(valdat)[-1]\n",
    "\n",
    "    valdat_scaled <- mapply(range02, df02_asList, traindat_mins, \n",
    "                            traindat_maxs)\n",
    "    # The next step is crucial.\n",
    "    valdat_scaled <- as.data.frame(valdat_scaled, row.names=rownames(valdat))\n",
    "    colnames(valdat_scaled) <- colnames(valdat)[-1]\n",
    "    \n",
    "    \n",
    "    #########################\n",
    "    # Construct k-means model.\n",
    "\n",
    "    kmod <- suppressWarnings(kmeans(traindat_scaled, 3, iter.max = 50, nstart=30))\n",
    "    \n",
    "    # See how the clusters are associated with Type level.\n",
    "    dfout <- as.data.frame(cbind(traindat$Type, kmod$cluster))\n",
    "    colnames(dfout) <- c(\"Type\", \"cluster\")\n",
    "    rownames(dfout) <- rownames(traindat)\n",
    "    mapping <- get_mapping(dfout)\n",
    "    \n",
    "    #############################\n",
    "    # Apply the k-means model to valdat_scaled.\n",
    "    \n",
    "    # Each element of the following list is a row of valdat_wghts.\n",
    "    valdat_asList <- split(valdat_scaled[, colnames(kmod$centers)],\n",
    "                           seq(nrow(valdat_scaled)))\n",
    "    \n",
    "    ctr_list <- vector(\"list\", length= nrow(valdat))\n",
    "    for(i in 1:nrow(valdat)) {\n",
    "        \n",
    "        ctr_list[[i]] <- kmod$centers\n",
    "    }\n",
    "    names(ctr_list) <- rownames(valdat)\n",
    "    \n",
    "    \n",
    "    # Get the predictions for the validation set.\n",
    "    preds <- mcmapply(getCluster, valdat_asList, ctr_list,\n",
    "                      SIMPLIFY=TRUE, USE.NAMES= FALSE, mc.cores=6)\n",
    "    \n",
    "    valdat_scaled$cluster <- as.numeric(preds)\n",
    "    \n",
    "    valdat_scaled$pred_Type <- NA\n",
    "    \n",
    "    # Apply mapping to the assigned clusters.  Since valdat is \n",
    "    # quite small (around 35 records if folds = 5), and there \n",
    "    # are 3 clusters, it is possible that one of the LHS expressions\n",
    "    # below is NA.  I will make the changes if the program fails. \n",
    "    valdat_scaled[which(valdat_scaled$cluster==1), c(\"pred_Type\")] <- as.numeric(mapping[\"1\"])\n",
    "    valdat_scaled[which(valdat_scaled$cluster==2), c(\"pred_Type\")] <- as.numeric(mapping[\"2\"])\n",
    "    valdat_scaled[which(valdat_scaled$cluster==3), c(\"pred_Type\")] <- as.numeric(mapping[\"3\"])\n",
    "    \n",
    "    # Generate confusion matrix for the k-means clusters and\n",
    "    # the corresponding f-score.\n",
    "    preds <- as.factor(valdat_scaled$pred_Type)\n",
    "    names(preds) <- rownames(valdat)\n",
    "    ans <- get_confusion(preds, valdat[, \"Type\", drop=FALSE])\n",
    "    return(ans[[2]])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for computing the cross-val score for the base\n",
    "# k-means model, the hybrid k-means model, and the hybrid\n",
    "# k-means model with weights.  The mapply line in the \n",
    "# following function needs to be altered to call the \n",
    "# appropriate function for the model we are working with.\n",
    "\n",
    "compute_cvScore_km <- function(seed_vector, dat, folds=5) {\n",
    "    \n",
    "    n_seeds <- length(seed_vector)\n",
    "    datout <- rep(NA, 2*n_seeds)\n",
    "    dim(datout) <- c(n_seeds, 2)\n",
    "    datout <- as.data.frame(datout)\n",
    "    colnames(datout) <- c(\"seed\", \"Acc\")\n",
    "    datout$seed <- seed_vector  \n",
    "    \n",
    "    #############################\n",
    "    # Partition the data into folds.\n",
    "        \n",
    "    # divide dat by the number of folds \n",
    "    segment_size <- round(nrow(dat)/folds)\n",
    "    diff <- nrow(dat) - folds * segment_size\n",
    "    last_seg_size <- segment_size + diff\n",
    "    segmentsv <- c(rep(segment_size, (folds - 1)), last_seg_size)\n",
    "    stopifnot(sum(segmentsv) == nrow(dat))\n",
    "\n",
    "    \n",
    "    for(h in 1:n_seeds) {\n",
    "        # shuffle dat\n",
    "        cur_seed <- seed_vector[h]\n",
    "        set.seed(cur_seed)\n",
    "        smp <- sample(rownames(dat), nrow(dat), replace= FALSE)\n",
    "        dat <- dat[smp,]\n",
    "        \n",
    "        # Each element of row_list will be the rows we pick\n",
    "        # out for one of the folds.  E.g., the first element\n",
    "        # of row_list will contain the rows we want for the\n",
    "        # first fold, the second element of row_list will\n",
    "        # contain the rows we want for the second fold, and\n",
    "        # so forth.\n",
    "        row_list <- vector(\"list\", length=folds)\n",
    "        names(row_list) <- as.character(1:folds)\n",
    "        startpt <- 1\n",
    "        for(i in 1:folds) {\n",
    "            endpt <- startpt + segmentsv[i] - 1\n",
    "            stopifnot(endpt <= nrow(dat))\n",
    "            row_list[[i]] <- rownames(dat)[startpt:endpt]\n",
    "            startpt <- endpt + 1\n",
    "        }\n",
    "    \n",
    "        train_list <- test_list <- vector(\"list\", length= folds)\n",
    "        for(j in 1:folds) {\n",
    "            testdat <- dat[row_list[[j]],]\n",
    "            traindat <- dat[which(!(rownames(dat) %in% rownames(testdat))),]\n",
    "            stopifnot((length(rownames(traindat)) + length(rownames(testdat))) == nrow(dat))\n",
    "            test_list[[j]] <- testdat\n",
    "            train_list[[j]] <- traindat\n",
    "        }\n",
    "        # When there are only 5 folds, only 5 cores get used.\n",
    "        # The next line varies based on which model we are trying to \n",
    "        # evaluate.  [*** TURN OFF mcmapply WHEN USING xgboost ***]\n",
    "        scores <- mcmapply(get_cvScore_pcaHybrid_wghts, train_list, test_list,\n",
    "                           SIMPLIFY= TRUE, mc.cores=5)\n",
    "            \n",
    "        # For the current seed, store the average of the accuracy\n",
    "        # scores, the average taken over the folds.\n",
    "        datout$Acc[h] <- round(mean(scores), 5)\n",
    "\n",
    "    } ## end of for-loop, index h\n",
    "    \n",
    "    return(datout)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-05-30 08:02:33'"
      ],
      "text/latex": [
       "'Start time: 2021-05-30 08:02:33'"
      ],
      "text/markdown": [
       "'Start time: 2021-05-30 08:02:33'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-05-30 08:02:33\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 5.48 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Again, use the same initial seed that we have \n",
    "# been using for this score.\n",
    "\n",
    "set.seed(1931)\n",
    "seed_vector <- sample(1:9999, 2000, replace=FALSE)\n",
    "\n",
    "start <- Sys.time()\n",
    "paste(\"Start time: \", start, sep=\"\")\n",
    "ans <- compute_cvScore_km(seed_vector, train)\n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 5.48 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "  0.624   0.692   0.708   0.710   0.725   0.792 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(ans$Acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.7095"
      ],
      "text/latex": [
       "0.7095"
      ],
      "text/markdown": [
       "0.7095"
      ],
      "text/plain": [
       "[1] 0.7095"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(mean(ans$Acc), 4)\n",
    "# 0.7095\n",
    "\n",
    "# svm02 has an accuracy score that is more than 11 percentage\n",
    "# points greater.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.7085"
      ],
      "text/latex": [
       "0.7085"
      ],
      "text/markdown": [
       "0.7085"
      ],
      "text/plain": [
       "[1] 0.7085"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.024145"
      ],
      "text/latex": [
       "0.024145"
      ],
      "text/markdown": [
       "0.024145"
      ],
      "text/plain": [
       "[1] 0.024145"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(median(ans$Acc), 4)\n",
    "round(sd(ans$Acc), 6)\n",
    "# median: 0.7085\n",
    "# sd: 0.024145\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAMAAAC323mdAAAC/VBMVEUAAAABAQECAgIDAwME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\nYAGwBsECYI3/B3MXTJ9xuXYoAAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title “Distribution of cross-val accuracy scores for base k-means model”"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width= 10, repr.plot.height= 6)\n",
    "hist(ans$Acc, breaks=16, xlab=\"accuracy\",\n",
    "     main=\"Distribution of cross-val accuracy scores for base k-means model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First hybrid k-means model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0.014</li><li>0.721</li><li>0.001</li><li>0.752</li><li>0.863</li><li>0.965</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.014\n",
       "\\item 0.721\n",
       "\\item 0.001\n",
       "\\item 0.752\n",
       "\\item 0.863\n",
       "\\item 0.965\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.014\n",
       "2. 0.721\n",
       "3. 0.001\n",
       "4. 0.752\n",
       "5. 0.863\n",
       "6. 0.965\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.014 0.721 0.001 0.752 0.863 0.965"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0.02</li><li>0.051</li><li>0.919</li><li>0.011</li><li>0.002</li><li>0</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.02\n",
       "\\item 0.051\n",
       "\\item 0.919\n",
       "\\item 0.011\n",
       "\\item 0.002\n",
       "\\item 0\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.02\n",
       "2. 0.051\n",
       "3. 0.919\n",
       "4. 0.011\n",
       "5. 0.002\n",
       "6. 0\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.020 0.051 0.919 0.011 0.002 0.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the probability columns, use the output from svm02.\n",
    "\n",
    "preds <- predict(svm02, newdata=svm_scaled, scale=FALSE, probability=TRUE)\n",
    "prob01 <- as.numeric(attr(preds, \"probabilities\")[, 2])\n",
    "prob02 <- as.numeric(attr(preds, \"probabilities\")[, 3])\n",
    "round(head(prob01), 3)\n",
    "round(head(prob02), 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num [1:178] 0.0143 0.7209 0.0013 0.7522 0.8629 ...\n"
     ]
    }
   ],
   "source": [
    "str(prob01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Hue           Phenols        Alcalinity        prob01       \n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :0.00000  \n",
       " 1st Qu.:0.246   1st Qu.:0.263   1st Qu.:0.340   1st Qu.:0.00468  \n",
       " Median :0.394   Median :0.474   Median :0.459   Median :0.02751  \n",
       " Mean   :0.388   Mean   :0.453   Mean   :0.459   Mean   :0.27161  \n",
       " 3rd Qu.:0.520   3rd Qu.:0.628   3rd Qu.:0.562   3rd Qu.:0.56923  \n",
       " Max.   :1.000   Max.   :1.000   Max.   :1.000   Max.   :1.00000  \n",
       "     prob02       \n",
       " Min.   :0.00000  \n",
       " 1st Qu.:0.00744  \n",
       " Median :0.18072  \n",
       " Mean   :0.35828  \n",
       " 3rd Qu.:0.77070  \n",
       " Max.   :1.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df <- train\n",
    "\n",
    "df$prob01 <- prob01\n",
    "df$prob02 <- prob02\n",
    "\n",
    "df02 <- scale(df[, -1], center=TRUE, scale=TRUE)\n",
    "df_scaled <- apply(as.matrix(df02), MARGIN=2, range01)\n",
    "df_scaled <- as.data.frame(cbind(df$Type, df_scaled),\n",
    "                           row.names=rownames(df))\n",
    "colnames(df_scaled) <- colnames(df)\n",
    "summary(df_scaled[, -1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 68 59 51\n"
     ]
    }
   ],
   "source": [
    "# Run k-means with number of clusters set to 3.\n",
    "\n",
    "set.seed(1233)\n",
    "fit_km <- kmeans(df_scaled[, -1], 3, iter.max = 50, nstart = 30)\n",
    "print(fit_km$size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Type</th><th scope=col>cluster</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>113</th><td>2</td><td>2</td></tr>\n",
       "\t<tr><th scope=row>159</th><td>3</td><td>3</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>1</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>131</th><td>3</td><td>3</td></tr>\n",
       "\t<tr><th scope=row>137</th><td>3</td><td>3</td></tr>\n",
       "\t<tr><th scope=row>133</th><td>3</td><td>3</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & Type & cluster\\\\\n",
       "  & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t113 & 2 & 2\\\\\n",
       "\t159 & 3 & 3\\\\\n",
       "\t21 & 1 & 1\\\\\n",
       "\t131 & 3 & 3\\\\\n",
       "\t137 & 3 & 3\\\\\n",
       "\t133 & 3 & 3\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | Type &lt;dbl&gt; | cluster &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 113 | 2 | 2 |\n",
       "| 159 | 3 | 3 |\n",
       "| 21 | 1 | 1 |\n",
       "| 131 | 3 | 3 |\n",
       "| 137 | 3 | 3 |\n",
       "| 133 | 3 | 3 |\n",
       "\n"
      ],
      "text/plain": [
       "    Type cluster\n",
       "113 2    2      \n",
       "159 3    3      \n",
       "21  1    1      \n",
       "131 3    3      \n",
       "137 3    3      \n",
       "133 3    3      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datout <- as.data.frame(cbind(df_scaled$Type, fit_km$cluster))\n",
    "colnames(datout) <- c(\"Type\", \"cluster\")\n",
    "rownames(datout) <- rownames(df_scaled)\n",
    "head(datout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "     1  2  3\n",
       "  1 55  4  0\n",
       "  2 13 52  6\n",
       "  3  0  3 45"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map cluster to Type level.\n",
    "\n",
    "table(datout$Type, as.factor(datout$cluster))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>178</li><li>2</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 178\n",
       "\\item 2\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 178\n",
       "2. 2\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 178   2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmpdat <- datout\n",
    "tmpdat[which(tmpdat$cluster== 1),]$Type <- 1\n",
    "tmpdat[which(tmpdat$cluster== 2),]$Type <- 2\n",
    "tmpdat[which(tmpdat$cluster== 3),]$Type <- 3\n",
    "dim(tmpdat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1  2  3 class.error\n",
      "1 55  4  0      0.0678\n",
      "2 13 52  6      0.2676\n",
      "3  0  3 45      0.0625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "''"
      ],
      "text/latex": [
       "''"
      ],
      "text/markdown": [
       "''"
      ],
      "text/plain": [
       "[1] \"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy score for the hybrid k-means model: 0.8539\"\n"
     ]
    }
   ],
   "source": [
    "# Generate confusion matrix for the k-means clusters.\n",
    "\n",
    "preds <- as.factor(tmpdat$Type)\n",
    "names(preds) <- rownames(tmpdat)\n",
    "ans <- get_confusion(preds, df_scaled[, \"Type\", drop=FALSE])\n",
    "print(ans$matrix)\n",
    "''\n",
    "print(paste(\"Accuracy score for the hybrid k-means model: \", as.character(ans[[2]]), sep=\"\"))\n",
    "# 0.8539\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get comparative cross-val score for the hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for obtaining average of confusion matrix accuracy\n",
    "# score. This function is called from compute_cvScore_km.\n",
    "\n",
    "get_cvScore_hybrid <- function(traindat, valdat) {\n",
    "    \n",
    "    # Scale traindat for purpose of an svm model.\n",
    "    svm_scaled <- scale(traindat[, -1])\n",
    "    svm_centers <- attr(svm_scaled, \"scaled:center\")\n",
    "    svm_scales <- attr(svm_scaled, \"scaled:scale\")\n",
    "    svm_scaled <- as.data.frame(cbind(traindat$Type, svm_scaled),\n",
    "                                row.names=rownames(traindat))\n",
    "    colnames(svm_scaled) <- colnames(traindat)\n",
    "    \n",
    "    # This is our current best svm model for the trainset data\n",
    "    svmod <- svm(I(as.factor(Type)) ~ ., data=svm_scaled, kernel=\"radial\",\n",
    "                 gamma= 0.03, cost= 25, scale=FALSE, probability=TRUE)\n",
    "    \n",
    "    \n",
    "    preds <- predict(svmod, newdata=svm_scaled, scale=FALSE, probability=TRUE)\n",
    "    traindat$prob01 <- as.numeric(attr(preds, \"probabilities\")[, 2])\n",
    "    traindat$prob02 <- as.numeric(attr(preds, \"probabilities\")[, 3])\n",
    "    \n",
    "    \n",
    "    #############################\n",
    "    # Scale training set data for the k-means model.\n",
    "    \n",
    "    df <- scale(traindat[, -1], center=TRUE, scale=TRUE)\n",
    "    centers <- attr(df, \"scaled:center\")\n",
    "    scales <- attr(df, \"scaled:scale\")\n",
    "    df <- as.matrix(df)\n",
    "    # Move the scaled data between 0 and 1.\n",
    "    traindat_scaled <- apply(df, MARGIN=2, range01)\n",
    "    colnames(traindat_scaled) <- colnames(traindat)[-1]\n",
    "    rownames(traindat_scaled) <- rownames(traindat)\n",
    "    \n",
    "    # Get mins and maxs for scaling of valdat.\n",
    "    traindat_mins <- as.numeric(apply(df, MARGIN=2, min))\n",
    "    traindat_maxs <- as.numeric(apply(df, MARGIN=2, max))\n",
    "    \n",
    "    \n",
    "    ############################\n",
    "    # Prepare valdat for svm modeling.\n",
    "    \n",
    "    svmval_scaled <- scale(valdat[, -1], center=svm_centers, scale=svm_scales)\n",
    "    svmval_scaled <- as.data.frame(svmval_scaled, row.names=rownames(valdat))\n",
    "    \n",
    "    # Compute prob01 and prob02 columns.\n",
    "    preds01_b <- predict(svmod, newdata=svmval_scaled, scale=FALSE, probability=TRUE)\n",
    "    valdat$prob01 <- as.numeric(attr(preds01_b, \"probabilities\")[, 2])\n",
    "    valdat$prob02 <- as.numeric(attr(preds01_b, \"probabilities\")[, 3])\n",
    "\n",
    "    \n",
    "    # Scale valdat.\n",
    "    df02 <- scale(valdat[, -1], center=centers, scale=scales)\n",
    "    df02_t <- t(as.matrix(df02))\n",
    "    df02_asList <- split(df02_t, seq(nrow(df02_t)))\n",
    "    names(df02_asList) <- colnames(valdat)[-1]\n",
    "    # Applying min-max scaling here:\n",
    "    valdat_scaled <- mapply(range02, df02_asList, traindat_mins, \n",
    "                            traindat_maxs)\n",
    "    # The next step is crucial.\n",
    "    valdat_scaled <- as.data.frame(valdat_scaled, row.names=rownames(valdat))\n",
    "    colnames(valdat_scaled) <- colnames(valdat)[-1]\n",
    "    \n",
    "    \n",
    "    #############################\n",
    "    # Construct k-means model.\n",
    "\n",
    "    kmod <- kmeans(traindat_scaled, 3, iter.max = 50, nstart=30)\n",
    "    \n",
    "    # See how the clusters are associated with Type level.\n",
    "    dfout <- as.data.frame(cbind(traindat$Type, kmod$cluster))\n",
    "    colnames(dfout) <- c(\"Type\", \"cluster\")\n",
    "    rownames(dfout) <- rownames(traindat)\n",
    "    mapping <- get_mapping(dfout)\n",
    "    \n",
    "    #############################\n",
    "    # Apply the k-means model to valdat_scaled.\n",
    "    \n",
    "    # Each element of the following list is a row of valdat_scaled.\n",
    "    valdat_asList <- split(valdat_scaled[, colnames(kmod$centers)],\n",
    "                           seq(nrow(valdat_scaled)))\n",
    "    \n",
    "    ctr_list <- vector(\"list\", length= nrow(valdat))\n",
    "    for(i in 1:nrow(valdat)) {\n",
    "        \n",
    "        ctr_list[[i]] <- kmod$centers\n",
    "    }\n",
    "    names(ctr_list) <- rownames(valdat)\n",
    "    \n",
    "    \n",
    "    # Get the predictions for the validation set.\n",
    "    cluster_assgns <- mcmapply(getCluster, valdat_asList, ctr_list,\n",
    "                               SIMPLIFY=TRUE, USE.NAMES= FALSE, mc.cores=6)\n",
    "    \n",
    "    valdat_scaled$cluster <- as.numeric(cluster_assgns)\n",
    "    \n",
    "    valdat_scaled$pred_Type <- NA\n",
    "    \n",
    "    # Apply mapping to the assigned clusters.  Since valdat is \n",
    "    # quite small (around 35 records if folds = 5), and there \n",
    "    # are 3 clusters, it is possible that one of the LHS expressions\n",
    "    # below is NA.  I will make the changes if the program fails. \n",
    "    valdat_scaled[which(valdat_scaled$cluster==1), c(\"pred_Type\")] <- as.numeric(mapping[\"1\"])\n",
    "    valdat_scaled[which(valdat_scaled$cluster==2), c(\"pred_Type\")] <- as.numeric(mapping[\"2\"])\n",
    "    valdat_scaled[which(valdat_scaled$cluster==3), c(\"pred_Type\")] <- as.numeric(mapping[\"3\"])\n",
    "    \n",
    "    # Generate confusion matrix for the k-means clusters and\n",
    "    # the corresponding f-score.\n",
    "    preds <- as.factor(valdat_scaled$pred_Type)\n",
    "    names(preds) <- rownames(valdat)\n",
    "    ans <- get_confusion(preds, valdat[, \"Type\", drop=FALSE])\n",
    "    return(ans[[2]])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-05-30 08:43:33'"
      ],
      "text/latex": [
       "'Start time: 2021-05-30 08:43:33'"
      ],
      "text/markdown": [
       "'Start time: 2021-05-30 08:43:33'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-05-30 08:43:33\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 6.83 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the same initial seed as we have been using for\n",
    "# this score.\n",
    "\n",
    "set.seed(1931)\n",
    "seed_vector <- sample(1:9999, 2000, replace=FALSE)\n",
    "\n",
    "start <- Sys.time()\n",
    "paste(\"Start time: \", start, sep=\"\")\n",
    "ans <- compute_cvScore_km(seed_vector, train)\n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 6.83 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "  0.775   0.821   0.831   0.830   0.837   0.860 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(ans$Acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.8295"
      ],
      "text/latex": [
       "0.8295"
      ],
      "text/markdown": [
       "0.8295"
      ],
      "text/plain": [
       "[1] 0.8295"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(mean(ans$Acc), 4)\n",
    "# 0.8295\n",
    "\n",
    "# For svm02, this score was 0.8278.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.8314"
      ],
      "text/latex": [
       "0.8314"
      ],
      "text/markdown": [
       "0.8314"
      ],
      "text/plain": [
       "[1] 0.8314"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.012021"
      ],
      "text/latex": [
       "0.012021"
      ],
      "text/markdown": [
       "0.012021"
      ],
      "text/plain": [
       "[1] 0.012021"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(median(ans$Acc), 4)\n",
    "round(sd(ans$Acc), 6)\n",
    "# median: 0.8314\n",
    "# sd: 0.012021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAMAAAC323mdAAAC+lBMVEUAAAABAQECAgIDAwME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\nAmANggXAGv8PW3ggh7/ZhbIAAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title “Distribution of cross-val accuracy scores for hybrid k-means model”"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width= 10, repr.plot.height= 6)\n",
    "hist(ans$Acc, breaks=14, xlab=\"accuracy\",\n",
    "     main=\"Distribution of cross-val accuracy scores for hybrid k-means model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMMENT:\n",
    "\n",
    "# At this point we already have a better model than our \n",
    "# previous best model, svm02.  The difference in means\n",
    "# is 0.0017.  This yields an F-statistic of 4.34, giving \n",
    "# us a two-tailed p-value of 1.42e-05.\n",
    "# The difference in median cross-val accuracy scores is\n",
    "# 0.0043.\n",
    "\n",
    "# On average, the hybrid model would misclassify 30.35 of\n",
    "# 178 new records.  svm02  would misclassify 30.65 of the\n",
    "# 178 new records.  While the improvement in the accuracy\n",
    "# score is small, it is real and shows that the k-means\n",
    "# algorithm does have something to add to the modeling.\n",
    "# In Parts 1 and 2 we saw around a 3% improvement in the \n",
    "# accuracy score, but there the number we had to beat was\n",
    "# around 70%, not the nearly 83% score we are trying to\n",
    "# beat here.  Also, in this example we are working with\n",
    "# less than half of the records of the cow data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Hybrid k-means model with weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best weights for the above hybrid model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the best weights using cross-validation.  We then get the comparative cross-val score that we need.  We expect to get a slightly better score than what we have already seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for obtaining average of confusion matrix \n",
    "# accuracy score. This function is called from gridSearch03.\n",
    "\n",
    "get_cvScore_kmWghts <- function(traindat, valdat, wghts) {\n",
    "    \n",
    "    # Scale traindat for purpose of an svm model.\n",
    "    svm_scaled <- scale(traindat[, -1])\n",
    "    svm_centers <- attr(svm_scaled, \"scaled:center\")\n",
    "    svm_scales <- attr(svm_scaled, \"scaled:scale\")\n",
    "    svm_scaled <- as.data.frame(cbind(traindat$Type, svm_scaled),\n",
    "                                row.names=rownames(traindat))\n",
    "    colnames(svm_scaled) <- colnames(traindat)\n",
    "    \n",
    "    # This is our current best svm model for the trainset data\n",
    "    svmod <- svm(I(as.factor(Type)) ~ ., data=svm_scaled, kernel=\"radial\",\n",
    "                 gamma= 0.03, cost= 25, scale=FALSE, probability=TRUE)\n",
    "    \n",
    "    preds <- predict(svmod, newdata=svm_scaled, scale=FALSE, probability=TRUE)\n",
    "    traindat$prob01 <- as.numeric(attr(preds, \"probabilities\")[, 2])\n",
    "    traindat$prob02 <- as.numeric(attr(preds, \"probabilities\")[, 3])\n",
    "    \n",
    "    #############################\n",
    "    # Scale training set data for the k-means model.\n",
    "    \n",
    "    df <- scale(traindat[, -1], center=TRUE, scale=TRUE)\n",
    "    centers <- attr(df, \"scaled:center\")\n",
    "    scales <- attr(df, \"scaled:scale\")\n",
    "    df <- as.matrix(df)\n",
    "    traindat_scaled <- apply(df, MARGIN=2, range01)\n",
    "    colnames(traindat_scaled) <- colnames(traindat)[-1]\n",
    "    rownames(traindat_scaled) <- rownames(traindat)\n",
    "    \n",
    "    # Get mins and maxs for scaling of valdat.\n",
    "    traindat_mins <- as.numeric(apply(df, MARGIN=2, min))\n",
    "    traindat_maxs <- as.numeric(apply(df, MARGIN=2, max))\n",
    "    \n",
    "    #############################\n",
    "    # Apply weights to traindat.  The sqrt should have\n",
    "    # been taken in the calling function.\n",
    "    cols <- names(wghts)\n",
    "    df2 <- t(t(traindat_scaled[, cols]) * as.numeric(wghts[cols]))\n",
    "    traindat_wghts <- as.data.frame(df2, row.names=rownames(traindat))\n",
    "    \n",
    "    \n",
    "    #############################################\n",
    "    # Prepare valdat.\n",
    "    #############################################\n",
    "    \n",
    "    svmval_scaled <- scale(valdat[, -1], center=svm_centers, scale=svm_scales)\n",
    "    svmval_scaled <- as.data.frame(svmval_scaled, row.names=rownames(valdat))\n",
    "    \n",
    "    # Compute prob01 and prob02 columns.\n",
    "    preds01_b <- predict(svmod, newdata=svmval_scaled, scale=FALSE, probability=TRUE)\n",
    "    valdat$prob01 <- as.numeric(attr(preds01_b, \"probabilities\")[, 2])\n",
    "    valdat$prob02 <- as.numeric(attr(preds01_b, \"probabilities\")[, 3])\n",
    "\n",
    "    # Scale valdat.\n",
    "    df02 <- scale(valdat[, -1], center=centers, scale=scales)\n",
    "    df02_t <- t(as.matrix(df02))\n",
    "    df02_asList <- split(df02_t, seq(nrow(df02_t)))\n",
    "    names(df02_asList) <- colnames(valdat)[-1]\n",
    "\n",
    "    valdat_scaled <- mapply(range02, df02_asList, traindat_mins, \n",
    "                            traindat_maxs)\n",
    "    # The next step is crucial.\n",
    "    valdat_scaled <- as.data.frame(valdat_scaled, row.names=rownames(valdat))\n",
    "    colnames(valdat_scaled) <- colnames(valdat)[-1]\n",
    "    \n",
    "    # Apply weights to valdat_scaled.\n",
    "    df4 <- t(t(valdat_scaled[, cols]) * as.numeric(wghts[cols]))\n",
    "    valdat_wghts <- as.data.frame(df4, row.names=rownames(valdat))\n",
    "    \n",
    "    \n",
    "    #############################################\n",
    "    # Construct k-means model.\n",
    "\n",
    "    kmod <- kmeans(traindat_wghts, 3, iter.max = 50, nstart=30)\n",
    "    \n",
    "    # See how the clusters are associated with Type level.\n",
    "    dfout <- as.data.frame(cbind(traindat$Type, kmod$cluster), \n",
    "                           row.names=rownames(traindat))\n",
    "    colnames(dfout) <- c(\"Type\", \"cluster\")\n",
    "    mapping <- get_mapping(dfout)\n",
    "    \n",
    "    \n",
    "    #############################\n",
    "    # Apply the k-means model to valdat_wghts.\n",
    "    \n",
    "    # Each element of the following list is a row of valdat_wghts.\n",
    "    valdat_asList <- split(valdat_wghts[, colnames(kmod$centers)],\n",
    "                           seq(nrow(valdat_wghts)))\n",
    "    \n",
    "    ctr_list <- vector(\"list\", length= nrow(valdat))\n",
    "    for(i in 1:nrow(valdat)) {\n",
    "        \n",
    "        ctr_list[[i]] <- kmod$centers\n",
    "    }\n",
    "    names(ctr_list) <- rownames(valdat)\n",
    "    \n",
    "    \n",
    "    # Get the predictions for the validation set.\n",
    "    cluster_assgns <- mcmapply(getCluster, valdat_asList, ctr_list,\n",
    "                               SIMPLIFY=TRUE, USE.NAMES= FALSE, mc.cores=6)\n",
    "    \n",
    "    valdat_wghts$cluster <- as.numeric(cluster_assgns)\n",
    "    \n",
    "    valdat_wghts$pred_Type <- NA\n",
    "    \n",
    "    # Apply mapping to the assigned clusters.  Since valdat is \n",
    "    # quite small (around 35 records if folds = 5), and there \n",
    "    # are 3 clusters, it is possible that one of the LHS expressions\n",
    "    # below is NA.  I will make the changes if the program fails. \n",
    "    valdat_wghts[which(valdat_wghts$cluster==1), c(\"pred_Type\")] <- as.numeric(mapping[\"1\"])\n",
    "    valdat_wghts[which(valdat_wghts$cluster==2), c(\"pred_Type\")] <- as.numeric(mapping[\"2\"])\n",
    "    valdat_wghts[which(valdat_wghts$cluster==3), c(\"pred_Type\")] <- as.numeric(mapping[\"3\"])\n",
    "    \n",
    "    # Generate confusion matrix for the k-means clusters and\n",
    "    # the corresponding f-score.\n",
    "    preds <- as.factor(valdat_wghts$pred_Type)\n",
    "    names(preds) <- rownames(valdat)\n",
    "    ans <- get_confusion(preds, valdat[, \"Type\", drop=FALSE])\n",
    "    return(ans[[2]])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This grid search searches for the best set of weights to use\n",
    "# in our k-means hybrid model.  The best weights are those\n",
    "# which generalize best to the validation set.  So we look for\n",
    "# the best cross-validation accuracy score.\n",
    "# Because our training set is so small---only 178 records---we\n",
    "# need to run the gridSearch over many seeds.  Otherwise, we \n",
    "# will not get a meaningful result.\n",
    "\n",
    "gridSearch03 <- function(seed_vector, dat, df_params, folds=5) {\n",
    "    \n",
    "    datout <- rep(NA, 2*nrow(df_params))\n",
    "    dim(datout) <- c(nrow(df_params), 2)\n",
    "    datout <- as.data.frame(datout)\n",
    "    colnames(datout) <- c(\"row\", \"Acc\")\n",
    "    datout$row <- rownames(df_params)\n",
    "    \n",
    "    # We want the sqrt of the weights.\n",
    "    df_params <- df_params^0.5\n",
    "    params_rows <- rownames(df_params)\n",
    "    \n",
    "    #############################\n",
    "    # Partition the data into folds.\n",
    "        \n",
    "    # divide dat by the number of folds \n",
    "    segment_size <- round(nrow(dat)/folds)\n",
    "    diff <- nrow(dat) - folds * segment_size\n",
    "    last_seg_size <- segment_size + diff\n",
    "    segmentsv <- c(rep(segment_size, (folds - 1)), last_seg_size)\n",
    "    stopifnot(sum(segmentsv) == nrow(dat))\n",
    "    \n",
    "    \n",
    "    # Create a dataframe, each row for a distinct seed.\n",
    "    # Each column of the dataframe is for a distinct set\n",
    "    # of weights.  The entries in the cells are accuracy \n",
    "    # scores.\n",
    "    seedv_len <- length(seed_vector)\n",
    "    df_scores <- rep(NA, seedv_len*nrow(df_params))\n",
    "    dim(df_scores) <- c(seedv_len, nrow(df_params))\n",
    "    df_scores <- as.data.frame(df_scores)\n",
    "    colnames(df_scores) <- rownames(df_params)\n",
    "    rownames(df_scores) <- as.character(seed_vector)\n",
    "    \n",
    "    for(h in 1:seedv_len) {\n",
    "        # shuffle dat\n",
    "        cur_seed <- seed_vector[h]\n",
    "        set.seed(cur_seed)\n",
    "        smp <- sample(rownames(dat), nrow(dat), replace= FALSE)\n",
    "        dat <- dat[smp,]\n",
    "        \n",
    "        # Each element of row_list will be the rows we pick\n",
    "        # out for one of the folds.  E.g., the first element\n",
    "        # of row_list will contain the rows we want for the\n",
    "        # first fold, the second element of row_list will\n",
    "        # contain the rows we want for the second fold, and\n",
    "        # so forth.\n",
    "        row_list <- vector(\"list\", length=folds)\n",
    "        names(row_list) <- as.character(1:folds)\n",
    "        startpt <- 1\n",
    "        for(i in 1:folds) {\n",
    "            endpt <- startpt + segmentsv[i] - 1\n",
    "            stopifnot(endpt <= nrow(dat))\n",
    "            row_list[[i]] <- rownames(dat)[startpt:endpt]\n",
    "            startpt <- endpt + 1\n",
    "        }\n",
    "    \n",
    "        for(i in 1:nrow(df_params)) {\n",
    "            \n",
    "            cur_row <- params_rows[i]\n",
    "            wghts <- as.numeric(df_params[i,])\n",
    "            names(wghts) <- colnames(df_params)\n",
    "            train_list <- test_list <- vector(\"list\", length= folds)\n",
    "        \n",
    "            for(j in 1:folds) {\n",
    "                testdat <- dat[row_list[[j]],]\n",
    "                traindat <- dat[which(!(rownames(dat) %in% rownames(testdat))),]\n",
    "                stopifnot((length(rownames(traindat)) + length(rownames(testdat))) == nrow(dat))\n",
    "                test_list[[j]] <- testdat\n",
    "                train_list[[j]] <- traindat\n",
    "            }\n",
    "            ### Do NOT use multiple cores if xgboost is used.\n",
    "            scores <- mcmapply(get_cvScore_hybrid_pcaWghts, train_list, test_list,\n",
    "                               MoreArgs= list(wghts=wghts),\n",
    "                               SIMPLIFY= TRUE, mc.cores=5)\n",
    "            \n",
    "            # For the current seed, store the average of the accuracy\n",
    "            # scores, the average taken over the folds.\n",
    "            df_scores[as.character(cur_seed), cur_row] <- round(mean(scores), 5)\n",
    "        \n",
    "        } # end of for-loop, index i\n",
    "    } ## end of for-loop, index h\n",
    "    \n",
    "    # Compute the average over the seeds of the accuracy scores\n",
    "    # obtained for each set of parameters in df_params.\n",
    "    datout$Acc <- round(apply(df_scores, MARGIN=2, mean), 5)\n",
    "    return(datout)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>8801</li><li>5</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 8801\n",
       "\\item 5\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 8801\n",
       "2. 5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 8801    5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# There are 5 parameter lists to work with.  Start by \n",
    "# exploring the region around the space where all \n",
    "# parameters have an equal weight---in this case, a \n",
    "# weight of 0.20.\n",
    "\n",
    "lst <- vector(\"list\", length= 5)\n",
    "names(lst) <- c(colnames(train)[-1], \"prob01\",\"prob02\")\n",
    "\n",
    "lst[[1]] <- lst[[2]] <- lst[[3]] <- lst[[4]] <- lst[[5]] <- seq(0.10, 0.30, by=0.02)\n",
    "\n",
    "start <- Sys.time()\n",
    "dfc01 <- generate_combs(lst)\n",
    "stop <- Sys.time()\n",
    "# round(stop - start, 2)\n",
    "\n",
    "dim(dfc01)\n",
    "#  8,801     5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Hue</th><th scope=col>Phenols</th><th scope=col>Alcalinity</th><th scope=col>prob01</th><th scope=col>prob02</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>47656</th><td>0.16</td><td>0.28</td><td>0.26</td><td>0.14</td><td>0.16</td></tr>\n",
       "\t<tr><th scope=row>94566</th><td>0.28</td><td>0.20</td><td>0.10</td><td>0.20</td><td>0.22</td></tr>\n",
       "\t<tr><th scope=row>26846</th><td>0.20</td><td>0.28</td><td>0.12</td><td>0.28</td><td>0.12</td></tr>\n",
       "\t<tr><th scope=row>10006</th><td>0.22</td><td>0.24</td><td>0.20</td><td>0.24</td><td>0.10</td></tr>\n",
       "\t<tr><th scope=row>136376</th><td>0.26</td><td>0.10</td><td>0.20</td><td>0.16</td><td>0.28</td></tr>\n",
       "\t<tr><th scope=row>73086</th><td>0.12</td><td>0.10</td><td>0.30</td><td>0.30</td><td>0.18</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & Hue & Phenols & Alcalinity & prob01 & prob02\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t47656 & 0.16 & 0.28 & 0.26 & 0.14 & 0.16\\\\\n",
       "\t94566 & 0.28 & 0.20 & 0.10 & 0.20 & 0.22\\\\\n",
       "\t26846 & 0.20 & 0.28 & 0.12 & 0.28 & 0.12\\\\\n",
       "\t10006 & 0.22 & 0.24 & 0.20 & 0.24 & 0.10\\\\\n",
       "\t136376 & 0.26 & 0.10 & 0.20 & 0.16 & 0.28\\\\\n",
       "\t73086 & 0.12 & 0.10 & 0.30 & 0.30 & 0.18\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 5\n",
       "\n",
       "| <!--/--> | Hue &lt;dbl&gt; | Phenols &lt;dbl&gt; | Alcalinity &lt;dbl&gt; | prob01 &lt;dbl&gt; | prob02 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 47656 | 0.16 | 0.28 | 0.26 | 0.14 | 0.16 |\n",
       "| 94566 | 0.28 | 0.20 | 0.10 | 0.20 | 0.22 |\n",
       "| 26846 | 0.20 | 0.28 | 0.12 | 0.28 | 0.12 |\n",
       "| 10006 | 0.22 | 0.24 | 0.20 | 0.24 | 0.10 |\n",
       "| 136376 | 0.26 | 0.10 | 0.20 | 0.16 | 0.28 |\n",
       "| 73086 | 0.12 | 0.10 | 0.30 | 0.30 | 0.18 |\n",
       "\n"
      ],
      "text/plain": [
       "       Hue  Phenols Alcalinity prob01 prob02\n",
       "47656  0.16 0.28    0.26       0.14   0.16  \n",
       "94566  0.28 0.20    0.10       0.20   0.22  \n",
       "26846  0.20 0.28    0.12       0.28   0.12  \n",
       "10006  0.22 0.24    0.20       0.24   0.10  \n",
       "136376 0.26 0.10    0.20       0.16   0.28  \n",
       "73086  0.12 0.10    0.30       0.30   0.18  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Work with a random sample of 1000 from dfc01.  Because\n",
    "# we are looking at only around 11% of the 8,801 records,\n",
    "# we might not find the best set of weights among these\n",
    "# 8,801 records.\n",
    "\n",
    "set.seed(42)\n",
    "smp <- sample(rownames(dfc01), 1000, replace=FALSE)\n",
    "tst_params <- dfc01[smp,]\n",
    "head(tst_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time difference of 37.75 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the best weights of those in tst_params.\n",
    "# Use 11 seeds.\n",
    "\n",
    "set.seed(1233)\n",
    "seed_vector <- sample(1:9999, 11, replace=FALSE)\n",
    "\n",
    "start <- Sys.time()\n",
    "dat_result <- gridSearch03(seed_vector, train, tst_params) \n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 37.75 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "  0.816   0.823   0.825   0.825   0.827   0.833 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(dat_result$Acc)\n",
    "\n",
    "# The interquartile range is about 0.004.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.00235"
      ],
      "text/latex": [
       "0.00235"
      ],
      "text/markdown": [
       "0.00235"
      ],
      "text/plain": [
       "[1] 0.00235"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If we have only a small amount of variance in the \n",
    "# resulting accuracy scores, then weights are likely\n",
    "# not worth the trouble.  [* What I don't know at \n",
    "# this point is what is \"small\" and what is \"large\".\n",
    "# It turns out I will need much more variance than\n",
    "# 0.00235 in order for weights to make a difference\n",
    "# in the cross-val accuracy score measured over \n",
    "# 2000 folds. *]\n",
    "\n",
    "round(sd(dat_result$Acc), 5)\n",
    "# 0.00235\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 15 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>row</th><th scope=col>Acc</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>917</th><td>41936 </td><td>0.83262</td></tr>\n",
       "\t<tr><th scope=row>510</th><td>83046 </td><td>0.83167</td></tr>\n",
       "\t<tr><th scope=row>704</th><td>68186 </td><td>0.83165</td></tr>\n",
       "\t<tr><th scope=row>524</th><td>72166 </td><td>0.83108</td></tr>\n",
       "\t<tr><th scope=row>430</th><td>73916 </td><td>0.83057</td></tr>\n",
       "\t<tr><th scope=row>819</th><td>155896</td><td>0.83054</td></tr>\n",
       "\t<tr><th scope=row>726</th><td>65866 </td><td>0.83010</td></tr>\n",
       "\t<tr><th scope=row>749</th><td>28266 </td><td>0.83006</td></tr>\n",
       "\t<tr><th scope=row>995</th><td>150556</td><td>0.83004</td></tr>\n",
       "\t<tr><th scope=row>216</th><td>74986 </td><td>0.83001</td></tr>\n",
       "\t<tr><th scope=row>667</th><td>117226</td><td>0.82960</td></tr>\n",
       "\t<tr><th scope=row>238</th><td>83896 </td><td>0.82959</td></tr>\n",
       "\t<tr><th scope=row>1</th><td>47656 </td><td>0.82956</td></tr>\n",
       "\t<tr><th scope=row>117</th><td>101196</td><td>0.82956</td></tr>\n",
       "\t<tr><th scope=row>251</th><td>42786 </td><td>0.82956</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 15 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & row & Acc\\\\\n",
       "  & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t917 & 41936  & 0.83262\\\\\n",
       "\t510 & 83046  & 0.83167\\\\\n",
       "\t704 & 68186  & 0.83165\\\\\n",
       "\t524 & 72166  & 0.83108\\\\\n",
       "\t430 & 73916  & 0.83057\\\\\n",
       "\t819 & 155896 & 0.83054\\\\\n",
       "\t726 & 65866  & 0.83010\\\\\n",
       "\t749 & 28266  & 0.83006\\\\\n",
       "\t995 & 150556 & 0.83004\\\\\n",
       "\t216 & 74986  & 0.83001\\\\\n",
       "\t667 & 117226 & 0.82960\\\\\n",
       "\t238 & 83896  & 0.82959\\\\\n",
       "\t1 & 47656  & 0.82956\\\\\n",
       "\t117 & 101196 & 0.82956\\\\\n",
       "\t251 & 42786  & 0.82956\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 15 × 2\n",
       "\n",
       "| <!--/--> | row &lt;chr&gt; | Acc &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 917 | 41936  | 0.83262 |\n",
       "| 510 | 83046  | 0.83167 |\n",
       "| 704 | 68186  | 0.83165 |\n",
       "| 524 | 72166  | 0.83108 |\n",
       "| 430 | 73916  | 0.83057 |\n",
       "| 819 | 155896 | 0.83054 |\n",
       "| 726 | 65866  | 0.83010 |\n",
       "| 749 | 28266  | 0.83006 |\n",
       "| 995 | 150556 | 0.83004 |\n",
       "| 216 | 74986  | 0.83001 |\n",
       "| 667 | 117226 | 0.82960 |\n",
       "| 238 | 83896  | 0.82959 |\n",
       "| 1 | 47656  | 0.82956 |\n",
       "| 117 | 101196 | 0.82956 |\n",
       "| 251 | 42786  | 0.82956 |\n",
       "\n"
      ],
      "text/plain": [
       "    row    Acc    \n",
       "917 41936  0.83262\n",
       "510 83046  0.83167\n",
       "704 68186  0.83165\n",
       "524 72166  0.83108\n",
       "430 73916  0.83057\n",
       "819 155896 0.83054\n",
       "726 65866  0.83010\n",
       "749 28266  0.83006\n",
       "995 150556 0.83004\n",
       "216 74986  0.83001\n",
       "667 117226 0.82960\n",
       "238 83896  0.82959\n",
       "1   47656  0.82956\n",
       "117 101196 0.82956\n",
       "251 42786  0.82956"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dat01 <- dat_result\n",
    "dat01 <- dat01[order(dat01$Acc, decreasing=TRUE),]\n",
    "dat01[1:15,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 10 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Hue</th><th scope=col>Phenols</th><th scope=col>Alcalinity</th><th scope=col>prob01</th><th scope=col>prob02</th><th scope=col>acc</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>41936</th><td>0.16</td><td>0.22</td><td>0.20</td><td>0.28</td><td>0.14</td><td>0.83262</td></tr>\n",
       "\t<tr><th scope=row>83046</th><td>0.22</td><td>0.16</td><td>0.18</td><td>0.24</td><td>0.20</td><td>0.83167</td></tr>\n",
       "\t<tr><th scope=row>68186</th><td>0.24</td><td>0.20</td><td>0.14</td><td>0.24</td><td>0.18</td><td>0.83165</td></tr>\n",
       "\t<tr><th scope=row>72166</th><td>0.20</td><td>0.18</td><td>0.14</td><td>0.30</td><td>0.18</td><td>0.83108</td></tr>\n",
       "\t<tr><th scope=row>73916</th><td>0.22</td><td>0.28</td><td>0.20</td><td>0.10</td><td>0.20</td><td>0.83057</td></tr>\n",
       "\t<tr><th scope=row>155896</th><td>0.16</td><td>0.18</td><td>0.12</td><td>0.24</td><td>0.30</td><td>0.83054</td></tr>\n",
       "\t<tr><th scope=row>65866</th><td>0.26</td><td>0.16</td><td>0.20</td><td>0.20</td><td>0.18</td><td>0.83010</td></tr>\n",
       "\t<tr><th scope=row>28266</th><td>0.22</td><td>0.22</td><td>0.14</td><td>0.30</td><td>0.12</td><td>0.83006</td></tr>\n",
       "\t<tr><th scope=row>150556</th><td>0.28</td><td>0.14</td><td>0.12</td><td>0.16</td><td>0.30</td><td>0.83004</td></tr>\n",
       "\t<tr><th scope=row>74986</th><td>0.28</td><td>0.24</td><td>0.16</td><td>0.12</td><td>0.20</td><td>0.83001</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 10 × 6\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & Hue & Phenols & Alcalinity & prob01 & prob02 & acc\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t41936 & 0.16 & 0.22 & 0.20 & 0.28 & 0.14 & 0.83262\\\\\n",
       "\t83046 & 0.22 & 0.16 & 0.18 & 0.24 & 0.20 & 0.83167\\\\\n",
       "\t68186 & 0.24 & 0.20 & 0.14 & 0.24 & 0.18 & 0.83165\\\\\n",
       "\t72166 & 0.20 & 0.18 & 0.14 & 0.30 & 0.18 & 0.83108\\\\\n",
       "\t73916 & 0.22 & 0.28 & 0.20 & 0.10 & 0.20 & 0.83057\\\\\n",
       "\t155896 & 0.16 & 0.18 & 0.12 & 0.24 & 0.30 & 0.83054\\\\\n",
       "\t65866 & 0.26 & 0.16 & 0.20 & 0.20 & 0.18 & 0.83010\\\\\n",
       "\t28266 & 0.22 & 0.22 & 0.14 & 0.30 & 0.12 & 0.83006\\\\\n",
       "\t150556 & 0.28 & 0.14 & 0.12 & 0.16 & 0.30 & 0.83004\\\\\n",
       "\t74986 & 0.28 & 0.24 & 0.16 & 0.12 & 0.20 & 0.83001\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 10 × 6\n",
       "\n",
       "| <!--/--> | Hue &lt;dbl&gt; | Phenols &lt;dbl&gt; | Alcalinity &lt;dbl&gt; | prob01 &lt;dbl&gt; | prob02 &lt;dbl&gt; | acc &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 41936 | 0.16 | 0.22 | 0.20 | 0.28 | 0.14 | 0.83262 |\n",
       "| 83046 | 0.22 | 0.16 | 0.18 | 0.24 | 0.20 | 0.83167 |\n",
       "| 68186 | 0.24 | 0.20 | 0.14 | 0.24 | 0.18 | 0.83165 |\n",
       "| 72166 | 0.20 | 0.18 | 0.14 | 0.30 | 0.18 | 0.83108 |\n",
       "| 73916 | 0.22 | 0.28 | 0.20 | 0.10 | 0.20 | 0.83057 |\n",
       "| 155896 | 0.16 | 0.18 | 0.12 | 0.24 | 0.30 | 0.83054 |\n",
       "| 65866 | 0.26 | 0.16 | 0.20 | 0.20 | 0.18 | 0.83010 |\n",
       "| 28266 | 0.22 | 0.22 | 0.14 | 0.30 | 0.12 | 0.83006 |\n",
       "| 150556 | 0.28 | 0.14 | 0.12 | 0.16 | 0.30 | 0.83004 |\n",
       "| 74986 | 0.28 | 0.24 | 0.16 | 0.12 | 0.20 | 0.83001 |\n",
       "\n"
      ],
      "text/plain": [
       "       Hue  Phenols Alcalinity prob01 prob02 acc    \n",
       "41936  0.16 0.22    0.20       0.28   0.14   0.83262\n",
       "83046  0.22 0.16    0.18       0.24   0.20   0.83167\n",
       "68186  0.24 0.20    0.14       0.24   0.18   0.83165\n",
       "72166  0.20 0.18    0.14       0.30   0.18   0.83108\n",
       "73916  0.22 0.28    0.20       0.10   0.20   0.83057\n",
       "155896 0.16 0.18    0.12       0.24   0.30   0.83054\n",
       "65866  0.26 0.16    0.20       0.20   0.18   0.83010\n",
       "28266  0.22 0.22    0.14       0.30   0.12   0.83006\n",
       "150556 0.28 0.14    0.12       0.16   0.30   0.83004\n",
       "74986  0.28 0.24    0.16       0.12   0.20   0.83001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bestrows <- as.character(dat01$row)[1:10]\n",
    "acc <- dat01[1:10, c(\"Acc\")]\n",
    "dat02 <- cbind(dfc01[bestrows, ], acc)\n",
    "dat02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMMENT:\n",
    "\n",
    "# Use weights in row 41936: 16, 22, 20, 28, 14.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>235</li><li>5</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 235\n",
       "\\item 5\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 235\n",
       "2. 5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 235   5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Refine search.\n",
    "\n",
    "lst <- vector(\"list\", length= 5)\n",
    "names(lst) <- c(colnames(train)[-1], \"prob01\",\"prob02\")\n",
    "\n",
    "lst[[1]] <- seq(0.15, 0.17, by=0.01)\n",
    "lst[[2]] <- seq(0.20, 0.24, by=0.01)\n",
    "lst[[3]] <- seq(0.18, 0.21, by=0.01)\n",
    "lst[[4]] <- seq(0.27, 0.31, by=0.01)\n",
    "lst[[5]] <- seq(0.12, 0.19, by=0.01)\n",
    "\n",
    "start <- Sys.time()\n",
    "dfc02 <- generate_combs(lst)\n",
    "stop <- Sys.time()\n",
    "# round(stop - start, 2)\n",
    "\n",
    "dim(dfc02)\n",
    "#  235     5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-05-30 10:22:31'"
      ],
      "text/latex": [
       "'Start time: 2021-05-30 10:22:31'"
      ],
      "text/markdown": [
       "'Start time: 2021-05-30 10:22:31'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-05-30 10:22:31\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 8.52 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the best weights of those in dfc02 (235 rows,\n",
    "# 11 seeds, 5 folds).  \n",
    "\n",
    "set.seed(1981)\n",
    "seed_vector <- sample(1:9999, 11, replace=FALSE)\n",
    "\n",
    "start <- Sys.time()\n",
    "paste(\"Start time: \", start, sep=\"\")\n",
    "dat_result <- gridSearch03(seed_vector, train, dfc02) \n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 8.52 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params <- dat_result[which(dat_result$Acc == \n",
    "                                max(dat_result$Acc, na.rm=TRUE)),]$row\n",
    "length(best_params)\n",
    "\n",
    "best_Acc <- dat_result[which(dat_result$Acc == \n",
    "                                max(dat_result$Acc, na.rm=TRUE)),]$Acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 1 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Hue</th><th scope=col>Phenols</th><th scope=col>Alcalinity</th><th scope=col>prob01</th><th scope=col>prob02</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>684</th><td>0.17</td><td>0.22</td><td>0.19</td><td>0.28</td><td>0.14</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & Hue & Phenols & Alcalinity & prob01 & prob02\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t684 & 0.17 & 0.22 & 0.19 & 0.28 & 0.14\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 5\n",
       "\n",
       "| <!--/--> | Hue &lt;dbl&gt; | Phenols &lt;dbl&gt; | Alcalinity &lt;dbl&gt; | prob01 &lt;dbl&gt; | prob02 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 684 | 0.17 | 0.22 | 0.19 | 0.28 | 0.14 |\n",
       "\n"
      ],
      "text/plain": [
       "    Hue  Phenols Alcalinity prob01 prob02\n",
       "684 0.17 0.22    0.19       0.28   0.14  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfc02[best_params,]\n",
    "#       \t Hue \t Phenols \t Alcalinity \tprob01  \tprob02\n",
    "\n",
    "# 684   \t0.17    \t0.22 \t       0.19 \t  0.28  \t  0.14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.83494"
      ],
      "text/latex": [
       "0.83494"
      ],
      "text/markdown": [
       "0.83494"
      ],
      "text/plain": [
       "[1] 0.83494"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_Acc\n",
    "# 0.8349\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 15 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>row</th><th scope=col>Acc</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>98</th><td>684 </td><td>0.83494</td></tr>\n",
       "\t<tr><th scope=row>134</th><td>914 </td><td>0.83446</td></tr>\n",
       "\t<tr><th scope=row>174</th><td>1211</td><td>0.83446</td></tr>\n",
       "\t<tr><th scope=row>188</th><td>1280</td><td>0.83440</td></tr>\n",
       "\t<tr><th scope=row>152</th><td>997 </td><td>0.83345</td></tr>\n",
       "\t<tr><th scope=row>141</th><td>948 </td><td>0.83342</td></tr>\n",
       "\t<tr><th scope=row>194</th><td>1325</td><td>0.83337</td></tr>\n",
       "\t<tr><th scope=row>176</th><td>1221</td><td>0.83336</td></tr>\n",
       "\t<tr><th scope=row>191</th><td>1294</td><td>0.83336</td></tr>\n",
       "\t<tr><th scope=row>207</th><td>1520</td><td>0.83336</td></tr>\n",
       "\t<tr><th scope=row>115</th><td>757 </td><td>0.83298</td></tr>\n",
       "\t<tr><th scope=row>150</th><td>993 </td><td>0.83292</td></tr>\n",
       "\t<tr><th scope=row>213</th><td>1565</td><td>0.83289</td></tr>\n",
       "\t<tr><th scope=row>95</th><td>655 </td><td>0.83286</td></tr>\n",
       "\t<tr><th scope=row>20</th><td>194 </td><td>0.83244</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 15 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & row & Acc\\\\\n",
       "  & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t98 & 684  & 0.83494\\\\\n",
       "\t134 & 914  & 0.83446\\\\\n",
       "\t174 & 1211 & 0.83446\\\\\n",
       "\t188 & 1280 & 0.83440\\\\\n",
       "\t152 & 997  & 0.83345\\\\\n",
       "\t141 & 948  & 0.83342\\\\\n",
       "\t194 & 1325 & 0.83337\\\\\n",
       "\t176 & 1221 & 0.83336\\\\\n",
       "\t191 & 1294 & 0.83336\\\\\n",
       "\t207 & 1520 & 0.83336\\\\\n",
       "\t115 & 757  & 0.83298\\\\\n",
       "\t150 & 993  & 0.83292\\\\\n",
       "\t213 & 1565 & 0.83289\\\\\n",
       "\t95 & 655  & 0.83286\\\\\n",
       "\t20 & 194  & 0.83244\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 15 × 2\n",
       "\n",
       "| <!--/--> | row &lt;chr&gt; | Acc &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 98 | 684  | 0.83494 |\n",
       "| 134 | 914  | 0.83446 |\n",
       "| 174 | 1211 | 0.83446 |\n",
       "| 188 | 1280 | 0.83440 |\n",
       "| 152 | 997  | 0.83345 |\n",
       "| 141 | 948  | 0.83342 |\n",
       "| 194 | 1325 | 0.83337 |\n",
       "| 176 | 1221 | 0.83336 |\n",
       "| 191 | 1294 | 0.83336 |\n",
       "| 207 | 1520 | 0.83336 |\n",
       "| 115 | 757  | 0.83298 |\n",
       "| 150 | 993  | 0.83292 |\n",
       "| 213 | 1565 | 0.83289 |\n",
       "| 95 | 655  | 0.83286 |\n",
       "| 20 | 194  | 0.83244 |\n",
       "\n"
      ],
      "text/plain": [
       "    row  Acc    \n",
       "98  684  0.83494\n",
       "134 914  0.83446\n",
       "174 1211 0.83446\n",
       "188 1280 0.83440\n",
       "152 997  0.83345\n",
       "141 948  0.83342\n",
       "194 1325 0.83337\n",
       "176 1221 0.83336\n",
       "191 1294 0.83336\n",
       "207 1520 0.83336\n",
       "115 757  0.83298\n",
       "150 993  0.83292\n",
       "213 1565 0.83289\n",
       "95  655  0.83286\n",
       "20  194  0.83244"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dat01 <- dat_result\n",
    "dat01 <- dat01[order(dat01$Acc, decreasing=TRUE),]\n",
    "dat01[1:15,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Hue</th><th scope=col>Phenols</th><th scope=col>Alcalinity</th><th scope=col>prob01</th><th scope=col>prob02</th><th scope=col>acc</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>684</th><td>0.17</td><td>0.22</td><td>0.19</td><td>0.28</td><td>0.14</td><td>0.83494</td></tr>\n",
       "\t<tr><th scope=row>914</th><td>0.16</td><td>0.24</td><td>0.18</td><td>0.27</td><td>0.15</td><td>0.83446</td></tr>\n",
       "\t<tr><th scope=row>1211</th><td>0.16</td><td>0.23</td><td>0.18</td><td>0.27</td><td>0.16</td><td>0.83446</td></tr>\n",
       "\t<tr><th scope=row>1280</th><td>0.16</td><td>0.21</td><td>0.19</td><td>0.28</td><td>0.16</td><td>0.83440</td></tr>\n",
       "\t<tr><th scope=row>997</th><td>0.15</td><td>0.22</td><td>0.20</td><td>0.28</td><td>0.15</td><td>0.83345</td></tr>\n",
       "\t<tr><th scope=row>948</th><td>0.17</td><td>0.20</td><td>0.21</td><td>0.27</td><td>0.15</td><td>0.83342</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 6\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & Hue & Phenols & Alcalinity & prob01 & prob02 & acc\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t684 & 0.17 & 0.22 & 0.19 & 0.28 & 0.14 & 0.83494\\\\\n",
       "\t914 & 0.16 & 0.24 & 0.18 & 0.27 & 0.15 & 0.83446\\\\\n",
       "\t1211 & 0.16 & 0.23 & 0.18 & 0.27 & 0.16 & 0.83446\\\\\n",
       "\t1280 & 0.16 & 0.21 & 0.19 & 0.28 & 0.16 & 0.83440\\\\\n",
       "\t997 & 0.15 & 0.22 & 0.20 & 0.28 & 0.15 & 0.83345\\\\\n",
       "\t948 & 0.17 & 0.20 & 0.21 & 0.27 & 0.15 & 0.83342\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 6\n",
       "\n",
       "| <!--/--> | Hue &lt;dbl&gt; | Phenols &lt;dbl&gt; | Alcalinity &lt;dbl&gt; | prob01 &lt;dbl&gt; | prob02 &lt;dbl&gt; | acc &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 684 | 0.17 | 0.22 | 0.19 | 0.28 | 0.14 | 0.83494 |\n",
       "| 914 | 0.16 | 0.24 | 0.18 | 0.27 | 0.15 | 0.83446 |\n",
       "| 1211 | 0.16 | 0.23 | 0.18 | 0.27 | 0.16 | 0.83446 |\n",
       "| 1280 | 0.16 | 0.21 | 0.19 | 0.28 | 0.16 | 0.83440 |\n",
       "| 997 | 0.15 | 0.22 | 0.20 | 0.28 | 0.15 | 0.83345 |\n",
       "| 948 | 0.17 | 0.20 | 0.21 | 0.27 | 0.15 | 0.83342 |\n",
       "\n"
      ],
      "text/plain": [
       "     Hue  Phenols Alcalinity prob01 prob02 acc    \n",
       "684  0.17 0.22    0.19       0.28   0.14   0.83494\n",
       "914  0.16 0.24    0.18       0.27   0.15   0.83446\n",
       "1211 0.16 0.23    0.18       0.27   0.16   0.83446\n",
       "1280 0.16 0.21    0.19       0.28   0.16   0.83440\n",
       "997  0.15 0.22    0.20       0.28   0.15   0.83345\n",
       "948  0.17 0.20    0.21       0.27   0.15   0.83342"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bestrows <- as.character(dat01$row)[1:6]\n",
    "acc <- dat01[1:6, c(\"Acc\")]\n",
    "dat02 <- cbind(dfc02[bestrows, ], acc)\n",
    "dat02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-05-30 11:19:42'"
      ],
      "text/latex": [
       "'Start time: 2021-05-30 11:19:42'"
      ],
      "text/markdown": [
       "'Start time: 2021-05-30 11:19:42'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-05-30 11:19:42\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 20.42 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the best weights of those in dat02 (6 rows,\n",
    "# 1000 seeds, 5 folds).\n",
    "### NOTE: Before running the following, I should \n",
    "### have added rep(0.20, 5) to dat02 to compare\n",
    "### the above weight combinations with no weights.\n",
    "\n",
    "set.seed(1931)\n",
    "seed_vector <- sample(1:9999, 1000, replace=FALSE)\n",
    "\n",
    "start <- Sys.time()\n",
    "paste(\"Start time: \", start, sep=\"\")\n",
    "dat_result <- gridSearch03(seed_vector, train, dat02[, 1:5]) \n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 20.42 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>row</th><th scope=col>Acc</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>4</th><td>1280</td><td>0.82947</td></tr>\n",
       "\t<tr><th scope=row>1</th><td>684 </td><td>0.82931</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>948 </td><td>0.82923</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>997 </td><td>0.82907</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>1211</td><td>0.82896</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>914 </td><td>0.82874</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & row & Acc\\\\\n",
       "  & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t4 & 1280 & 0.82947\\\\\n",
       "\t1 & 684  & 0.82931\\\\\n",
       "\t6 & 948  & 0.82923\\\\\n",
       "\t5 & 997  & 0.82907\\\\\n",
       "\t3 & 1211 & 0.82896\\\\\n",
       "\t2 & 914  & 0.82874\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | row &lt;chr&gt; | Acc &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 4 | 1280 | 0.82947 |\n",
       "| 1 | 684  | 0.82931 |\n",
       "| 6 | 948  | 0.82923 |\n",
       "| 5 | 997  | 0.82907 |\n",
       "| 3 | 1211 | 0.82896 |\n",
       "| 2 | 914  | 0.82874 |\n",
       "\n"
      ],
      "text/plain": [
       "  row  Acc    \n",
       "4 1280 0.82947\n",
       "1 684  0.82931\n",
       "6 948  0.82923\n",
       "5 997  0.82907\n",
       "3 1211 0.82896\n",
       "2 914  0.82874"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dat_result[order(dat_result$Acc, decreasing=TRUE),]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params <- dat_result[which(dat_result$Acc == \n",
    "                                max(dat_result$Acc, na.rm=TRUE)),]$row\n",
    "length(best_params)\n",
    "\n",
    "best_Acc <- dat_result[which(dat_result$Acc == \n",
    "                                max(dat_result$Acc, na.rm=TRUE)),]$Acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 1 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Hue</th><th scope=col>Phenols</th><th scope=col>Alcalinity</th><th scope=col>prob01</th><th scope=col>prob02</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1280</th><td>0.16</td><td>0.21</td><td>0.19</td><td>0.28</td><td>0.16</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & Hue & Phenols & Alcalinity & prob01 & prob02\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1280 & 0.16 & 0.21 & 0.19 & 0.28 & 0.16\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 5\n",
       "\n",
       "| <!--/--> | Hue &lt;dbl&gt; | Phenols &lt;dbl&gt; | Alcalinity &lt;dbl&gt; | prob01 &lt;dbl&gt; | prob02 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 1280 | 0.16 | 0.21 | 0.19 | 0.28 | 0.16 |\n",
       "\n"
      ],
      "text/plain": [
       "     Hue  Phenols Alcalinity prob01 prob02\n",
       "1280 0.16 0.21    0.19       0.28   0.16  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.82947"
      ],
      "text/latex": [
       "0.82947"
      ],
      "text/markdown": [
       "0.82947"
      ],
      "text/plain": [
       "[1] 0.82947"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dat02[best_params, 1:5]\n",
    "#       \t Hue \t Phenols \t Alcalinity \tprob01  \tprob02\n",
    "\n",
    "# 1280  \t0.16    \t0.21 \t       0.19 \t  0.28  \t  0.16\n",
    "\n",
    "\n",
    "best_Acc\n",
    "# 0.8295\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get comparative cross-val score for the hybrid model with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for obtaining average of confusion matrix \n",
    "# accuracy score. This function is called from compute_cvScore_km.\n",
    "\n",
    "# We need to take the square root of the weights.\n",
    "wghts <- c(0.16, 0.21, 0.19, 0.28, 0.16)^0.5\n",
    "names(wghts) <- c(colnames(train)[-1], \"prob01\",\"prob02\")\n",
    "\n",
    "get_cvScore_wghts <- function(traindat, valdat) {\n",
    "    \n",
    "    # Scale traindat for purpose of an svm model.\n",
    "    svm_scaled <- scale(traindat[, -1])\n",
    "    svm_centers <- attr(svm_scaled, \"scaled:center\")\n",
    "    svm_scales <- attr(svm_scaled, \"scaled:scale\")\n",
    "    svm_scaled <- as.data.frame(cbind(traindat$Type, svm_scaled),\n",
    "                                row.names=rownames(traindat))\n",
    "    colnames(svm_scaled) <- colnames(traindat)\n",
    "    \n",
    "    # This is our current best svm model for the trainset data\n",
    "    svmod <- svm(I(as.factor(Type)) ~ ., data=svm_scaled, kernel=\"radial\",\n",
    "                 gamma= 0.03, cost= 25, scale=FALSE, probability=TRUE)\n",
    "    \n",
    "    preds <- predict(svmod, newdata=svm_scaled, scale=FALSE, probability=TRUE)\n",
    "    traindat$prob01 <- as.numeric(attr(preds, \"probabilities\")[, 2])\n",
    "    traindat$prob02 <- as.numeric(attr(preds, \"probabilities\")[, 3])\n",
    "    \n",
    "    #############################\n",
    "    # Scale training set data for the k-means model.\n",
    "    \n",
    "    df <- scale(traindat[, -1], center=TRUE, scale=TRUE)\n",
    "    centers <- attr(df, \"scaled:center\")\n",
    "    scales <- attr(df, \"scaled:scale\")\n",
    "    df <- as.matrix(df)\n",
    "    traindat_scaled <- apply(df, MARGIN=2, range01)\n",
    "    colnames(traindat_scaled) <- colnames(traindat)[-1]\n",
    "    rownames(traindat_scaled) <- rownames(traindat)\n",
    "    \n",
    "    # Get mins and maxs for scaling of valdat.\n",
    "    traindat_mins <- as.numeric(apply(df, MARGIN=2, min))\n",
    "    traindat_maxs <- as.numeric(apply(df, MARGIN=2, max))\n",
    "    \n",
    "    #############################\n",
    "    # Apply weights to traindat.\n",
    "    cols <- names(wghts)\n",
    "    df2 <- t(t(traindat_scaled[, cols]) * as.numeric(wghts[cols]))\n",
    "    traindat_wghts <- as.data.frame(df2, row.names=rownames(traindat))\n",
    "    \n",
    "    \n",
    "    #############################################\n",
    "    # Prepare valdat.\n",
    "    #############################################\n",
    "    \n",
    "    svmval_scaled <- scale(valdat[, -1], center=svm_centers, scale=svm_scales)\n",
    "    svmval_scaled <- as.data.frame(svmval_scaled, row.names=rownames(valdat))\n",
    "    \n",
    "    # Compute prob01 and prob02 columns.\n",
    "    preds01_b <- predict(svmod, newdata=svmval_scaled, scale=FALSE, probability=TRUE)\n",
    "    valdat$prob01 <- as.numeric(attr(preds01_b, \"probabilities\")[, 2])\n",
    "    valdat$prob02 <- as.numeric(attr(preds01_b, \"probabilities\")[, 3])\n",
    "\n",
    "    # Scale valdat.\n",
    "    df02 <- scale(valdat[, -1], center=centers, scale=scales)\n",
    "    df02_t <- t(as.matrix(df02))\n",
    "    df02_asList <- split(df02_t, seq(nrow(df02_t)))\n",
    "    names(df02_asList) <- colnames(valdat)[-1]\n",
    "\n",
    "    valdat_scaled <- mapply(range02, df02_asList, traindat_mins, \n",
    "                            traindat_maxs)\n",
    "    # The next step is crucial.\n",
    "    valdat_scaled <- as.data.frame(valdat_scaled, row.names=rownames(valdat))\n",
    "    colnames(valdat_scaled) <- colnames(valdat)[-1]\n",
    "    \n",
    "    # Apply weights to valdat_scaled.\n",
    "    df4 <- t(t(valdat_scaled[, cols]) * as.numeric(wghts[cols]))\n",
    "    valdat_wghts <- as.data.frame(df4, row.names=rownames(valdat))\n",
    "    colnames(valdat_wghts) <- colnames(valdat)[-1]\n",
    "    \n",
    "    \n",
    "    #############################################\n",
    "    # Construct k-means model.\n",
    "\n",
    "    kmod <- kmeans(traindat_wghts, 3, iter.max = 50, nstart=30)\n",
    "    \n",
    "    # See how the clusters are associated with Type level.\n",
    "    dfout <- as.data.frame(cbind(traindat$Type, kmod$cluster), \n",
    "                           row.names=rownames(traindat))\n",
    "    colnames(dfout) <- c(\"Type\", \"cluster\")\n",
    "    mapping <- get_mapping(dfout)\n",
    "    \n",
    "    \n",
    "    #############################\n",
    "    # Apply the k-means model to valdat_wghts.\n",
    "    \n",
    "    # Each element of the following list is a row of valdat_wghts.\n",
    "    valdat_asList <- split(valdat_wghts[, colnames(kmod$centers)],\n",
    "                           seq(nrow(valdat_wghts)))\n",
    "    \n",
    "    ctr_list <- vector(\"list\", length= nrow(valdat))\n",
    "    for(i in 1:nrow(valdat)) {\n",
    "        \n",
    "        ctr_list[[i]] <- kmod$centers\n",
    "    }\n",
    "    names(ctr_list) <- rownames(valdat)\n",
    "    \n",
    "    \n",
    "    # Get the predictions for the validation set.\n",
    "    cluster_assgns <- mcmapply(getCluster, valdat_asList, ctr_list,\n",
    "                               SIMPLIFY=TRUE, USE.NAMES= FALSE, mc.cores=6)\n",
    "    \n",
    "    valdat_wghts$cluster <- as.numeric(cluster_assgns)\n",
    "    \n",
    "    valdat_wghts$pred_Type <- NA\n",
    "    \n",
    "    # Apply mapping to the assigned clusters.  Since valdat is \n",
    "    # quite small (around 35 records if folds = 5), and there \n",
    "    # are 3 clusters, it is possible that one of the LHS expressions\n",
    "    # below is NA.  I will make the changes if the program fails. \n",
    "    valdat_wghts[which(valdat_wghts$cluster==1), c(\"pred_Type\")] <- as.numeric(mapping[\"1\"])\n",
    "    valdat_wghts[which(valdat_wghts$cluster==2), c(\"pred_Type\")] <- as.numeric(mapping[\"2\"])\n",
    "    valdat_wghts[which(valdat_wghts$cluster==3), c(\"pred_Type\")] <- as.numeric(mapping[\"3\"])\n",
    "    \n",
    "    # Generate confusion matrix for the k-means clusters and\n",
    "    # the corresponding f-score.\n",
    "    preds <- as.factor(valdat_wghts$pred_Type)\n",
    "    names(preds) <- rownames(valdat)\n",
    "    ans <- get_confusion(preds, valdat[, \"Type\", drop=FALSE])\n",
    "    return(ans[[2]])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-05-30 12:09:57'"
      ],
      "text/latex": [
       "'Start time: 2021-05-30 12:09:57'"
      ],
      "text/markdown": [
       "'Start time: 2021-05-30 12:09:57'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-05-30 12:09:57\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 6.54 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the correct seed, i.e., the seed we have been\n",
    "# using for this comparative score.\n",
    "\n",
    "set.seed(1931)\n",
    "seed_vector <- sample(1:9999, 2000, replace=FALSE)\n",
    "\n",
    "start <- Sys.time()\n",
    "paste(\"Start time: \", start, sep=\"\")\n",
    "dat_result <- compute_cvScore_km(seed_vector, train) \n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 6.71 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "  0.780   0.821   0.831   0.829   0.837   0.860 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(dat_result$Acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.8292"
      ],
      "text/latex": [
       "0.8292"
      ],
      "text/markdown": [
       "0.8292"
      ],
      "text/plain": [
       "[1] 0.8292"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(mean(dat_result$Acc), 4)\n",
    "\n",
    "# Accuracy over 2000 seeds is 0.8292.  Without weights,\n",
    "# this score was 0.8295.  svm02 had an average\n",
    "# cross-val accuracy score of 0.8278.\n",
    "\n",
    "# One thing this shows is that I need far more than 11\n",
    "# seeds (giving us 55 folds) in the initial search for\n",
    "# weights.  But if I were to use many more seeds, the\n",
    "# search would take far more time.  It would also help to\n",
    "# look at some of the 7,800 weight combinations that were\n",
    "# not included in the 1000 that were in my sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.831"
      ],
      "text/latex": [
       "0.831"
      ],
      "text/markdown": [
       "0.831"
      ],
      "text/plain": [
       "[1] 0.831"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.012081"
      ],
      "text/latex": [
       "0.012081"
      ],
      "text/markdown": [
       "0.012081"
      ],
      "text/plain": [
       "[1] 0.012081"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(median(dat_result$Acc), 4)\n",
    "round(sd(dat_result$Acc), 6)\n",
    "# median: 0.8310\n",
    "# sd: 0.012081\n",
    "\n",
    "# The median accuracy score for svm02 was 0.8271.\n",
    "# Without weights, the hybrid model had a median\n",
    "# accuracy score of 0.8314.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>seed</th><th scope=col>Acc</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>6276</td><td>0.83238</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>8252</td><td>0.82058</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>6728</td><td>0.83104</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>9082</td><td>0.84316</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>7952</td><td>0.82550</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>8360</td><td>0.84280</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & seed & Acc\\\\\n",
       "  & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 6276 & 0.83238\\\\\n",
       "\t2 & 8252 & 0.82058\\\\\n",
       "\t3 & 6728 & 0.83104\\\\\n",
       "\t4 & 9082 & 0.84316\\\\\n",
       "\t5 & 7952 & 0.82550\\\\\n",
       "\t6 & 8360 & 0.84280\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | seed &lt;int&gt; | Acc &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 1 | 6276 | 0.83238 |\n",
       "| 2 | 8252 | 0.82058 |\n",
       "| 3 | 6728 | 0.83104 |\n",
       "| 4 | 9082 | 0.84316 |\n",
       "| 5 | 7952 | 0.82550 |\n",
       "| 6 | 8360 | 0.84280 |\n",
       "\n"
      ],
      "text/plain": [
       "  seed Acc    \n",
       "1 6276 0.83238\n",
       "2 8252 0.82058\n",
       "3 6728 0.83104\n",
       "4 9082 0.84316\n",
       "5 7952 0.82550\n",
       "6 8360 0.84280"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>2000</li><li>2</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2000\n",
       "\\item 2\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2000\n",
       "2. 2\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2000    2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(dat_result)\n",
    "dim(dat_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAMAAAC323mdAAAC/VBMVEUAAAABAQECAgIDAwME\nBAQFBQUGBgYHBwcICAgJCQkKCgoLCwsMDAwNDQ0ODg4PDw8QEBARERESEhITExMUFBQVFRUW\nFhYXFxcYGBgZGRkaGhobGxscHBwdHR0eHh4fHx8gICAhISEiIiIjIyMkJCQlJSUmJiYnJyco\nKCgpKSkqKiorKyssLCwtLS0uLi4vLy8wMDAxMTEyMjIzMzM0NDQ1NTU2NjY3Nzc4ODg5OTk6\nOjo7Ozs8PDw9PT0+Pj4/Pz9AQEBBQUFCQkJDQ0NERERFRUVGRkZHR0dISEhJSUlKSkpLS0tM\nTExNTU1OTk5PT09QUFBRUVFSUlJTU1NUVFRVVVVWVlZXV1dYWFhZWVlaWlpbW1tcXFxdXV1e\nXl5fX19gYGBhYWFiYmJjY2NkZGRlZWVmZmZnZ2doaGhpaWlqampra2tsbGxtbW1ubm5vb29w\ncHBxcXFycnJzc3N0dHR1dXV2dnZ3d3d4eHh5eXl6enp7e3t8fHx9fX1+fn5/f3+AgICBgYGC\ngoKDg4OEhISFhYWGhoaHh4eIiIiJiYmKioqLi4uMjIyNjY2Ojo6Pj4+QkJCRkZGSkpKTk5OU\nlJSVlZWWlpaXl5eYmJiZmZmampqbm5ucnJydnZ2enp6fn5+goKChoaGioqKjo6OkpKSlpaWm\npqanp6eoqKipqamqqqqrq6usrKytra2urq6vr6+wsLCxsbGysrKzs7O0tLS1tbW2tra3t7e4\nuLi5ubm6urq7u7u8vLy9vb2+vr6/v7/AwMDBwcHCwsLDw8PExMTFxcXGxsbHx8fIyMjJycnL\ny8vMzMzNzc3Ozs7Pz8/Q0NDR0dHS0tLT09PU1NTV1dXW1tbX19fY2NjZ2dna2trb29vc3Nzd\n3d3e3t7f39/g4ODh4eHi4uLj4+Pk5OTl5eXm5ubn5+fo6Ojp6enq6urr6+vs7Ozt7e3u7u7v\n7+/w8PDx8fHy8vLz8/P09PT19fX29vb39/f4+Pj5+fn6+vr7+/v8/Pz9/f3+/v7///+a7cvV\nAAAACXBIWXMAABJ0AAASdAHeZh94AAAgAElEQVR4nO3deZwU5Z348e8MICCXIioIqBwC4g0m\nEAQ8wooi6kbjgReYEEUl0bi7SeTnlcTNYTRrdnXjrsequaOr2URjPGKMIYk5PNBETTyiIhoV\nFBXlmqnXr6q6e7qqpvp52uqarvp2fd5/TF9VXc9TXf2ZmZ5uEAcAlJCsBwAA9SJYANQgWADU\nIFgA1CBYANQgWADUIFgA1CBYANQgWADUIFgA1CBYANQgWADUIFgA1CBYANQgWADUIFgA1CBY\nANQgWADUIFgA1CBYANQgWADUIFgA1CBYANQgWADUIFgA1CBYANQgWADUIFgA1CBYANQgWADU\nIFgA1CBYANQgWADUIFgA1CBYANQgWADUIFgA1CBYANQgWADUUBGsJ6Vk8PiT7/WvuFpkoHWt\n8kJLRGbaN1HXPdaw6fNj+wz4VtK1379GxppD9e0+w6RrPcKRVX7mHkGvW1fKUHiAJdbHOrJA\nsmMjdq18HmaqguVZtNmJ35cd8+fPfyB4RV3BqqzVyKPzDW9c1yZd+/3L55GUWH27j2DFKy/Q\n2HFcT7C6Pb+yoS5YssyJ38Gb3du+H7yirmBV1mokAnNEhp61POna71+LBau+3Uew4pUXaOw4\nridY3Z5f2VATrMs3b97wyOfbRXo/6Tidmzdvji7UbYeWF6ovWHH3WK9dRT6VdN0kWixY9e2+\nBMGKPKatGazyJBsLVuzRT7AS84J1hX/uBvfcObHL/GW5e9MXH3y72w3GI7PmWu/HJJHzG7qD\n96nFglXf7ksQrIi6g9VRx529P/XdY6JglXQdxykeG+G7SuWZkgJlweocIzKqui87b507tt/Y\nOTdtcpyPln5hfNC5WGS8c+veE4K/Er76qX223PPrnd4qi0UO8E6vdX9WC6zV9ehsvPyIMYM/\n9IkV/gXvvjoum9xvp488ERpQcKHyXVxcvXXNZw7aZvgBX99YvgN/MJE7Do48cqHMXbOvf3Ts\nLvIRd+3rD9ip7+gZ3/CuihyUwZtCGw9dCM87MLBaqy8S6bXGu+pIkTldGwsPNbSxbnuuPPFH\nPj5lwLhjfx2zemT31boDnz/p/96z/86nPhcdW+QRjh4AjvPXY4Zte+RtscFyl5Hru648x73y\n0RltW+x+vbP+kv0Hjzt1lX91cAbB3RU9PGIexxr3GD4YogMMbC/0WO8vMt89+aK73CuO81v3\n5NflBcLHcWU3mdaL38q6z+4xcM6f3YvTI3u8uoXYo7V5lAXL+Zx79qXKDu48svy61pS3w8H6\ndpvsHAjWHhP8245+17EGa8WepWv6XOQd/O59jVvgX+77aGA8oYW6BevnO5Sumfh3pzqYyB0H\nRx6+UPGUe/k29/Ql9/QHzvrp5UX2eDsarNBNoY2HLsQEyx9YzdXvcU++6161cZDINZWNhYca\n2li3PVee+Ne3KF3/mc7YmVZ3X607KPEmfY5/+7BXImOLPMLRA8D5xVD/xmOke7Du7S1ySXVf\nuhsYvZW/8GUH+icj33TCMwjtrsjhEfc4xt9jeKrRAQa3F3qsvywy1L1uvnvbTxznCpGtNscF\nq2s3mdaL3crKid41253VFazqXXVtIfZobR5twfpP9+yvKjvY+/vShKOmt4ksqv6O7R5F228j\noWCJtO3sHpnyCafbEzfyu/+7Y93LO36gr5S+717srzvCW3dudTjhhZ5YvqPIKctfqNy62j36\n+kzZx73x4MBgInccGnnoQpcpIh93T/5HZMA6v9OT9t/e/XphNFihm0IbD13oHqzSwGquvnm4\nyAnukve7V62ubCw01ND9d99zpfu/y71ixqkf8J6xsTPt2n217qDsav+h2N5dVU6NjC3yCEcP\ngNfcqsnwgf6TLBKsp7YWOSOwz/3n54AtS0/IYd6XLzjhGYR2V+TwiHscY+8xMtXIAEPbCz3W\nD7vXPek424r/S7SbymPiXnSv7ibTerFbOcLL1QDvLqZ3u6vKFuKP1qbRFqxb3bP/V9nBh4qc\n7Ph71v0GEgiWbHHGNd8NBmu3Z5w1/+Ae3M/bgnW+SPt1jrNqX/foWlO6r4+85rzuPq6Dq8OJ\nLBR5EeaT7rWPOc733VX/XB1MZJ3QyEMXunxNZIR78XiRBf4L0xeUJnxINFihm0IbD13oHqzS\nwGqvfrbI1pv8p+i8ro2FhhpaOmbPefe/eXJp57g3D1wdP9NJXUvE3UFlKe/ps9+LzrPjRHZ3\nwmOLPMLRA+DTbjF+7Gz6bPdgrdnFfXiDry95ebmgY91SrydPOisGer+Nh2cQ2l2RwyNudnH3\nGJ1qeIDh7YUe687hXuGedTPifYtwq3ddbLCqu6n2erFbudl7nnVu/GQ1WIG7qmwh/mhtGm3B\nui0YrKnuT9jfdL8333///ZtCwbrVWzQQrN+5p6+63zm+bAvWpNJ3buexNv9O3PvawvvB91uh\nYz2yUCRYO4mc550ePH7896qDiawTGnnowivLfe85L7pL/sHpGObNt/P73//+a47z1myRfSPB\nCt8U2njoQkywbjWv/jt3kV86jvsT1E1dWwsNNbR09z3n3//j7nPzDff0LffHkO+FVw/szvNj\nd31pz5V5T5+/uKdfFennhMcWeYSjB8Ag/6chf+FwsD7o/pI24z33fNc+d/OyrRsw96kt33Cv\nP8H7KSw0g/DuihwecbOLu8foVMMDDO+x8DenhSKLne+KHCZbdb7qLr0yNljV3VR7vditHOcW\nyj3pmNQVrMBdVbYQ+xg2j7ZgfdM9+0BlB1/g/xQ94Yxb1jmhXwkH+YtWg7WDf7n0rcEYrA3u\nw3eLv/AEkX/172usd8l7zaTrJYHoQuFgvecehHd2XaoMJrpOaOShC9eWfnt42nFme6/s/F5k\nyHr36k3Lv3DMXt7vENFghW4KbTw8ku7BGmRe3XHcb63/4rzSJn3Xdl0VHGpo6Zg959//LVJ1\nUXimFaXdV+sOKtxJ9/dOrymNPzi2yCMcOQBWult8xLt4aTRYntlOcJ+7eZnqXn7dvXCHU/61\nMTyD0AMROTziZhd3j5GpRgYY3l74sf6eyGT3p8vhN4o89RORPZ24YAV3U831Yrfi/tT1JW/x\n8yvBCt5VZQuxj2HzaAvWef73h/IO3rCs9GqlDL4mFKxx/qLVYE31L5/mH57GYHnfCH/rL3yQ\n/wrSxd4fnFz3BoMVXSgcLO/F8j92XaoMJrpOaOShC9VguW3+gHNJ6QWEh91jqW38cYfGBCt4\nU2jj4ZF0D9Y48+r+oTnJudH/JaYiONTQ0jF7zr//ywNPjE+GZ1pR2n217qCiMuny+INjizzC\nkQPg5+4dv+ZdvDkuWP6DHwyWu3/9vPzMKeclPIPQAxE5POJmF3ePkalGBhjeXvixfr1d2tZM\nl6PcJ8RNblU+48QFK7ibaq4Xt5XOPiI3eIv/d/WvhE63Z0rsY9g8yoLVOS70tgZn0y8/t5e3\n89pWBIPlH0XdfsI6XGSh/8Td37tU8yes//UXnuj/4So2WNGFwsF6y1307q5LlTvotk5w5KEL\n1WC91lvaXnZ/zLrLcdaPFTn+FT/X0WCFbgptPDySyLwrA6u9uuM84Y3jhMjbBatDDS1da8/9\nUGSr5WXPRKddUv0JK+4OKiJPn+DYIo9w5ADwfnv0N3Z9t2BN/qDI6HWWYIVmEH4guh0e3WcX\nd4+RqUYGGN5jkZ+mp4nc1lcu6xwiS+eI/MKpM1jd14vdynD/FXj//Q+1gxX7GDaPsmB92z13\ndmVfvv3444+7163y3l9ylSlY8nv3dM1gka86zunlVyO/GPsalnsEneTd+qd2kZtrBCu6UOQ1\nrB1KL8s6h++++y3VwYTXCY08PI2Aee6s+8iwTaUnnfdywvzuwQrfFNp46EJk3pWBGVb3X1S5\nfJhs+U7XxsJDDS1dY889KtLur//qK6+si59peffVuIOK6DMxMLbIIxw5ANa4t37eu3h0NFjb\nvei9GfKCwEbi8hKaQXh3hQ+P2NnF3WNkqpEBhrYXDdZFIv/gvYtqjkwdIgM3OvUGq9t6sVvZ\n3/97r+NMNwSr5tHaJJqC1fGnL/UqfTSntC+fKn+L/3tfkZ/6O/Q6Jz5Ye73ovOUeY1u4P7d8\nyf3O8CP3GNuq+jBcV13Y/c7ZfqPjvPwB9xvQq7WCFVkoEqxFIls/5Hgvccqz1cGE1wmNPDyN\ngG+JbFP6s7v3Ion7w/pP2roHK3xTaOOhC5F5VwZmWN3/Q6UbpeOqIwoPNbR0jT23cYzIuY7/\n7oz2P8fPtLz7atxBRfSZGBhb5BGOHgC7uCc/czr9z1hH34d1pEi/56obictLaAbh3RU+PGJn\nFxusyFTDAwxtLxos702fssV6Z5l3emRgkpHjOBqsbuvFbuXL/uw63LrVCNZ10UOg+dQEq4v3\nh6nyvhwv0mv2CYe531i3e8tx3KfiTkufjQ2WtO/ivU3Oe4Tu8y4O39r76j+i5bXKC6/b2b1+\n3Iz+UnqzZHywIgtFgrVqkEifD+4r/rtdugYTWSc08vA0qt72lvb+GOa80u49J/fw3hKzeyRY\n4ZtCGw9diMy7MjDD6o7zonej//bVitBQQ0vX2HPO/7pX7H3qvu3+e6RiZ1refbXuoCz6TAyM\nLfIIRw8A//1Eo/yZdwvWn93vgEdVNxKbl+AMwrsrcnjEzS72HiNTjQwwtMciweoYWorJj7xl\nrw7ul/BxHA1W9/XitrJuuDeQIRIbrMoWah2tTaIuWIu8v6WW9+UT25Sv7Oc9q4/1zj0YF6yt\n+vpLHe3/DFx6o+6ApeWHobxW5dF5eLfSPfY5v/J2a+/acLAiC0U/DPfjYaVbP/BW8GkXXic0\n8vA0Ary3Pu/gv0/o0/7tYxe4g34schCHbgptPHwhPO+ugRlWd5wD3LOD3wuMKDzU0NLxe85x\nzu9Vuv7kzTVmWtl9te7ACT6a1WdidWyRRzh6AKzfv3S/h0vMR3MWu1fe23VlbF5CMwjtrsjh\nETe7+HsMTzU6wOD2IsHy3nngVXmVd/tzwf0SOY4jweq+XuxWSm+53+Ko2GCVt1DzaG0OVcEa\nNO7E8D/g9+YVs8f2HzblnJe8C68tHNF/0p/igjXziRMn9dvtG6X3uW388j4Dhn7kz5WHobxW\n14Gx4dL5Ow+a9vHSJ3Eujg9WeKFun979+zmzth5x0DUdTuhpF14nNPLQhQDvTWelj3p3/Pue\nA6acu/b//CvCB3HoptDGwxfC8+4amGl1789FckpoSOGhhpaO3XOuX5+4e/9djn4gZvXI7qt1\nB75uz8Tq2CKPcPQAcH+aOHbMsEO/e2dcsFa6P+bsFnzXVExegjMI7a7o4REzuxr3GD4YogMM\nbC8aLPdXOP9101HeX0mDC0SO42iwuq0Xv5VnTp24zWHLvxkbrPIWah6tzaEiWMjI6rbS24fy\nKM9jU+6C8ksCeUSwUNvfRIZuzHoQNeR5bEqdNX78tHcdZ9Pk0huic4lgoZY3nz+k9HHiHMrz\n2NT6d/f3xqPuunuOyJDnsh5LLQQLtfj/LMofsh5FvDyPTa2OY8ovFg+4zb5wRggWanGj0OvS\nrAdRQ57Hpti9R+y65fAP/dPfsx5HbQQLtfzXpd96Pusx1JLnsaEHESwAahAsAGoQLABqECwA\nahAsAGoQLABqECwAahAsAGoQLABqECwAahAsAGoQLABqECwAahAsAGoQLABqECwAahAsAGoQ\nLABqECwAahAsAGoQLABqECwAahAsAGoQLABqECwAahAsAGoQLABqECwAahAsAGoQLABqECwA\nahAsAGoQLABqECwAahAsAGoQLABqECwAahAsAGoQLABqECwAahAsAGoQLABqECwAahAsAGoQ\nLABqECwAahAsAGoQLABqECwAahAsAGoQLABqECwAahAsFNi9c5Ja0Jn12IuJYKHAvrD9x5I5\nTDZlPfZiIlgosC9MeSyZGwlWNggWCoxgaUOwUGAESxuChQIjWNoQLBQYwdKGYEG/5+9JaCHB\nUoZgQb+DJSmCpQzBgn4HLUnYnWkESxmCBf0IVmEQLOhHsAqDYEE/glUYBAv6EazCIFjQj2AV\nBsGCfgSrMAgW9CNYhUGwoB/BKgyCBf0IVmEQLOhHsAqDYEE/glUYBAv6EazCIFjQj2AVBsGC\nfgSrMAgW9CNYhUGwoB/BKgyCBf0IVmEQLOhHsAqDYEE/glUYBAv6EazCIFjQj2AVBsGCfgSr\nMAgW9CNYhUGwoB/BKgyCBf0IVmEQLOhHsAqDYEE/glUYBAv6EazCIFjQj2AVBsGCfgSrMAgW\n9CNYhUGwoB/BKgyCBf0IVmEQLOhHsAqDYEE/glUYBAv6EazCIFjQj2AVBsGCfgSrMAgW9CNY\nhUGwoB/BKgyCBf0IVmEQLOhHsAqDYEE/glUYBAv6EazCIFjQj2AVBsGCfgSrMAgW9CNYhUGw\noB/BKgyCBf0IVmEQLOhHsAqDYEE/glUYBAv6EazCIFjQj2AVBsGCfgSrMAgW9CNYhUGwoB/B\nKgyCBf0IVmEQLOhHsAqDYEE/glUYBAv6EazCIFjQj2AVBsGCfgSrMAgW9CNYhdFYsNauXNWR\n0kCAxAhWYTQQrMdOGS4ivUYuWJ7ecIAECFZhJA/W0jYZMW3evOmjRBanOCDgfSNYhZE4WFfJ\n3IdK5x4/Ti5PazgospPnJDSUYBVF4mDNmNj1iHXO2i+dwaDY2uZ9LJm+BKsoEgdr8MLq+WVD\n0hgKiq7tuoT5GEywiiL5T1iTNnedP5CfsJACggWbBl7DOnRF6dxTJ8ilaQ0HRUawYJP8r4RL\nREbPPOLI2WNEFnWmOCIUFsGCTQPvw3p4wTDvfVgjFtyf3nBQZAQLNo290/2NF17mne5IC8GC\nDR/NQW4QLNjw0RzkBsGCDR/NQW4QLNjw0RzkBsGCTc98NKfz/nu63P29xINDsRAs2PTMR3Oe\n6S8BG5NuA8VCsGDT8x/N+bVsSLoNFAvBgk3PfzSHYKFOBAs2Pf/RHIKFOhEs2PT8R3MIFupE\nsGDT8x/NIVioE8GCTeP/zdcaS7IIFupEsGCTPFjv/cep//oX57YdZOCRL5mWI1ioE8GCTeJg\nvTFZRLb/Y9/BB+4u268xLEiwUCeCBZvEwfpnOXfFPeMH7Oj+dPU9+SfDggQLdSJYsEkcrMnT\n3S93yJe88wfsbViQYKFOBAs2iYPVf4n7ZaX80Dt/xpaGBQkW6kSwYJM4WGM/7H55d8kj3vmj\nhxkWJFioE8GCTeJgHdfnx5WzT/efZ1iQYKFOBAs2iYP1zJZtU3/inXnsU0PafmFYkGChTgQL\nNsnfh/XXo7a/0ju9Wrb/oWk5goU6ESzYNPROd/897k//2vzvXREs1Ilgwabxj+bYECzUiWDB\nhmAhNwgWbAgWcoNgwYZgITcIFmwIFnKDYMGGYCE3CBZsCBZyg2DBhmAhNwgWbAgWcoNgwYZg\nITcIFmwIFnKDYMGGYCE3CBZsCBZyg2DBhmAhNwgWbAgWcoNgwYZgITcIFmwIFnKDYMGGYCE3\nCBZsCBZyg2DBhmAhNwgWbAgWcoNgwYZgITcIFmwIFnKDYMGGYCE3CBZsCBZyg2DBhmAhNwgW\nbAgWcoNgwYZgITcIFmwIFnKDYMGGYCE3CBZsCBZyg2DBhmAhNwgWbAgWcoNgwYZgITcIFmwI\nFnKDYMGGYCE3CBZsCBZyg2DBhmAhNwgWbAgWcoNgwYZgITcIFmwIFnKDYMGGYCE3CBZsCBZy\ng2DBhmAhNwgWbAgWcoNgwYZgITcIFmwIFnKDYMGGYCE3CBZsCBZyg2DBhmAhNwgWbAgWcoNg\nwYZgITcIFmwIFnKDYMGGYCE3CBZsCBZyg2DBhmAhNwgWbAgWcoNgwYZgITcIFmwIFnKDYMGG\nYCE3CBZsCBZyg2DBhmAhNwgWbAgWcoNgwYZgITcIFmwIFnKDYMGGYCE3CBZsCBZyg2DBhmAh\nNwgWbAgWcoNgwYZgITcIFmwIFnKDYMGGYCE3CBZsCBZyQ1GwvimLT0tm6WtZ72bVCBZyQ1Gw\n/p8cnFD73VnvZtUIFnJDVbAeSbhmb4LVCIKF3CBYsCFYyA2CBRuChdwgWLAhWMgNggUbgoXc\nIFiwCQbrhrU9sQWChToRLNgEgyX9jvrhu6lvgWChTgQLNsFgXbV/uww86faN6W6BYKFOBAs2\n4dewXr7SbdbQT9zXkeIWCBbqRLBg0+1F95evnN0uI85+MLUtECzUiWDBpvtfCR+5eIy4JtyS\n0hYIFupEsGATDtam+87eSWTEkrv/eO7Att+nswWChToRLNgEg3XLyVuLjPvn33R6Fx6Sz6Wz\nBYKFOhEs2ITe1iB7Xfxo5cLaYV9LZwsEC3UiWLAJBuuyZ3piCwQLdSJYsAm/hvWXe9wvVz+Z\n6hYIFupEsGATCtbZbTPdr73bzu2sc+21K1dZ37JFsFAnggWbYLCulxl3uCd3HijX1bPqY6cM\nF5FeIxcsNy5GsFAnggWbYLAO3KX0qZxNk/etY82lbTJi2rx500eJLDYtR7BQJ4IFm2Cwtjq9\nfObMQfYVr5K5D5XOPX6cXG5YkGChTgQLNsFgTTq0fOawCfYVZ0zs+o/ZOmftZ1iQYKFOBAs2\nwWCd1utH/umdvRbZVxy8sHp+2RDDggQLdSJYsAkGa/XOMueSa79yeNt2L9tXnDFpc9f5A/kJ\nCykgWLAJva3h+ZPbvc89H/ZEHSteJYeuKJ176gS51LAgwUKdCBZsIv9aw6vLv3Pvi/WtuURk\n9Mwjjpw9RmSR6X1bBAt1IliwaeA/oXh4wTDvfVgjFtxvXIxgoU4ECzahYN18/JyyOtd+44WX\neac70kKwYBMM1rUiA4eV1Lk2H81BiggWbILB2m2w+UM2EXw0B+kiWLAJBKtzi0++nzX5aA5S\nRrBgEwjW+rZPv48V+WgO0kawYBP8lXD/nd+sf0U+moO0ESzYBIP1/B57/ODp1332FY0fzXl1\nwTFdDpL1aQwUrY9gwSb0rzUMkAr7isaP5qz9f5/tchI/YaE+BAs2wTQtrrKvyEdzkDaCBZvk\n73TnozlIGcGCTSRY61b8tu5V+WgO0kWwYBMK1t+O6iPiXHjiynrX5qM5SBHBgk0wWKtGy4wD\nxfmajFxV17p/f7L8zobXTIUjWKgTwYJNMFhnyU3Ot90rbuh1Zh1rPrynyPAb/LOHmF4JI1io\nE8GCTTA1Ox3o+MFyjtjFvuLT/drnzOsnV3nnCRbSQLBgE0zNgNPLwTpjgH3F49t+6jivju/n\n/TfRBAtpIFiwCaZm2gfLwZoy1b7imLne16f6H+4QLKSDYMEmmJpL5IsdXrAukfPsKw4qvbn0\nAnmAYCEdBAs2wdRsni3jPyRnTpU93rOvOHOyf/LO6N02ECykgmDBJpSaDVfsKCLbnP9WHSue\nJ0v9DzXfIce/R7CQBoIFm2hq3v7T6vpWfG+WDJrvnblARm5LsJACggWb5J8lfONzk0q/Fd4w\n0fivOxAs1IlgwSaYmpOq3td9dD53r+FWgoU6ESzYBIPV9a9hDRqf4hYIFupEsGATDNZ63+v3\n7tf/jhS3QLBQJ4IFm7hXn9ZN3GZjelsgWKgTwYJN7Mvl/yIvpLcFgoU6ESzYxAbr7L7Wf+Wq\nfgQLdSJYsIkJVucvh+yZ4hYIFupEsGATDNbAkr4iN6S4BYKFOhEs2ASDNb/slB+luQWChToR\nLNgkf6d7vQgW6kSwYEOwkBsECzbBYI0KmZnSFggW6kSwYBMM1pKR0rbD1FFtsvNM10dS2gLB\nQp0IFmyCwfpV+8F/dk+enDvybylugWChTgQLNsFgHT7mXf/03bEfTXELBAt1IliwCQZr+4Xl\nMx8bleIWCBbqRLBgE/1/CX1zRqS4BYKFOhEs2ASDdXzbbf7p/7UfkeIWCBbqRLBgEwzW37Zp\nP/a6O68/tr3/oylugWChTgQLNqE3jj5ykP8Pju5u+heP3zeCVTDPTpuakBAsWETe6f74zZff\n9NsU/20Zh2AVzn1tn06IYMEmEqx1K36b9hYIVsHc15bwqfwYwYJNKFh/O6qPiHPhiSvT3ALB\nKhiCZUSwGhIM1qrRMuNAcb4mI1eluAWCVTAEy4hgNSQYrLPkJufb7hU39DozxS0QrIIhWEYE\nqyHRN456wXKO2CXFLRCsgiFYRgSrIcFgDTi9HKwzBqS4BYJVMATLiGA1JBisaR8sB2vK1BS3\nQLAKhmAZEayGBIN1iXyxwwvWJXJeilsgWAVDsIwIVkOCwdo8W8Z/SM6cKnu8l+IWCFbBECwj\ngtWQ0PuwNlyxo4hsc/5baW6BYBUMwTIiWA0JBOudq3/jOG//aXXKWyBYBUOwjAhWQ0J/JTyx\nJ7ZAsAqGYBkRrIYEg3Xmtq/3wBYIVsEQLCOC1ZBgsDadvscP/vrWO54Ut0CwCoZgGRGshgSD\nNXx4LylLcQsEq2AIlhHBakgwTYuqUtwCwSoYgmVEsBpSCdbSG3tqCwSrYAiWEcFqSCVYcpL3\n9frF6W+BYBUMwTIiWA0JB2tRmi9elRGsgiFYRgSrIQQLKSNYRgSrIQQLKSNYRgSrIQQL8TY9\nk9B3CJYJwWoIwUK8r0hSBMuEYDWEYCHehXvdmcxpBMuEYDWkK1g7He8aI8eXpLgFgqXThdMS\nPiP/hWCZEKyGdAUrLMUtECydCJYJwcpIJU1/CEtxCwRLJ4JlQrAy0gMvWkUQLJ0IlgnBygjB\nQjyCZUKwMkKwEI9gmRCsjBAsxCNYJgQrIwQL8QiWCcHKCMFCPIJlQrAyQrAQj2CZEKyMECzE\nI1gmBCsjBAvxCJYJwcoIwUI8gmVCsDJCsBCPYJkQrIwQLMQjWCYEKyMEC/EIlgnBygjBQjyC\nZUKwMkKwEI9gmRCsjBAsxCNYJgQrIwQL8QiWCcHKCMFCPIJlQrAyQrAQj2CZEKyMECzEI1gm\nBCsjBAvxCJYJwcoIwUI8gmVCsDJCsBCPYJkQrIwQLMQjWCYEKyMEC/EIlgnBygjBQjyCZUKw\nMkKwEI9gmRCsjBAsxCvY9YIAABGYSURBVCNYJgQrIwQL8QiWCcHKCMFCPIJlQrAyQrAQj2CZ\nEKyMECzEI1gmBCsjBAvxCJYJwcoIwUI8gmVCsDJCsFrc3+5J6CSCZUCwMkKwWtyBkhTBMiBY\nGSFYLW7W0oRPrKkEy4BgZYRgtTiCZUKwtCFYLY5gmRAsbQhWiyNYJgRLG4LV4giWCcHShmC1\nOIJlQrC0IVgtjmCZECxtCFaLI1gmBEsbgtXiCJYJwdKmsWCtXbmqw7YMwcoUwTIhWNo0EKzH\nThkuIr1GLlhuXIxgZYpgmRAsbZIHa2mbjJg2b970USKLTcsRrEwRLBOCpU3iYF0lcx8qnXv8\nOLncsCDByhTBMiFY2iQO1oyJmypnO2ftZ1iQYGWKYJkQLG0SB2vwwur5ZUMMCxKsTBEsE4Kl\nTfKfsCZt7jp/ID9h5RbBMiFY2jTwGtahK0rnnjpBLjUsSLAyRbBMCJY2yf9KuERk9Mwjjpw9\nRmRRp2E5gpUpgmVCsLRp4H1YDy8Y5r0Pa8SC+42LEaxMESwTgqVNY+90f+OFl3mne74RLBOC\npQ0fzWlxBMuEYGnDR3NaHMEyIVja8NGcFkewTAiWNnw0p8URLBOCpU0PfTRn1TNdbiZYWSJY\nJgRLm575aM7TbcH/QphgZYhgmRAsbXroozkv8BNWThAsE4KlDR/NaXEEy4RgacNHc1ocwTIh\nWNrw0ZwWR7BMCJY2fDSnxREsE4KlDf/NV4sjWCYESxuC1eIIlgnB0oZgtTiCZUKwtCFYLY5g\nmRAsbZIG6z+2CjEsSbAyRbBMCJY2SYP110/1lUG7dzEsSbAyRbBMCJY2yX8l/JnMr2s5gpUp\ngmWSQbDaZx+TzLG/zPpYyoMGXsOaQLAUIFgmGQRLZn00me3Py/pYyoMGgnXiR+pajGBlimCZ\nZBGs/0q44n4Ey+GvhC2PYJkQLG0IVosjWCYESxuC1eIIlgnB0oZgtTiCZUKwtCFYLY5gmRAs\nbQhWiyNYJgRLG4LV4giWCcHShmC1OIJlQrC0IVgtjmCZECxtCFaLI1gmBEsbgtXiCJYJwdKG\nYLU4gmVCsLQhWC2OYJkQLG0IVosjWCYESxuC1eIIlgnB0oZgtTiCZUKwtCFYLY5gmRAsbQhW\niyNYJgRLG4LV4giWCcHShmC1OIJlQrC0IVgtjmCZECxtCJYKHSMlKYJlQLC0IVgqbJLPXJNM\nf4JlQLC0IVgqbJIbEx7mAwmWAcHShmCpQLCMCFZhECwVCJYRwSoMgqUCwTIiWIVBsFQgWEYE\nqzAIlgoEy4hgFQbBUoFgGRGswiBYKhAsI4JVGARLBYJlRLAKg2CpQLCMCFZhECwVCJYRwSoM\ngqUCwTIiWIVBsFQgWEYEqzAIlgoEy4hgFQbBUoFgGRGswiBYKhAsI4JVGARLBYJlRLAKg2Cp\nQLCMCFZhECwVCJYRwSoMgqUCwTIiWIVBsFQgWEYEqzAIlgoEy4hgFQbBUoFgGRGswiBYKhAs\nI4JVGARLBYJlRLAKg2CpQLCMCFZhECwVCJYRwSoMgqUCwTIiWIVBsFQgWEYEqzAIlgoEy4hg\nFQbBUoFgGRGswiBYKhAsI4JVGARLBYJlRLAKg2CpQLCMCFZhEKxmenLS2GTGECwTglUYBKuZ\n7up1UTLLCJYJwSoMgtVMd/VJeLD+gWCZEKzCIFjNRLCMCJYJwfIQrGYiWEYEy4RgeQhWMxEs\nI4JlQrA8BKuZCJYRwTIhWB6C1UwEy4hgmRAsD8FqJoJlRLBMCJaHYDUTwTIiWCYEy0Owmolg\nGREsE4LlIVjNRLCMCJYJwfIQrGYiWEYEy2TvQ/8rod9lfdyniGA1E8EyIlgmWw8alcyQGVkf\n9ykiWM1EsIwIlslWixOueM70rI/7FBGsZiJYRgTLhGB5CFYzESwjgmVCsDwEq5kIlhHBMiFY\nHoLVTATLiGCZECwPwWomgmVEsEwIlodgNRPBMiJYJgTLQ7CaiWAZESwTguUhWM1EsIwIlgnB\n8hCsZiJYRgTLhGB5CFYzESwjgmVCsDwEK4Frtk5oIMEyIVgmBMtDsBI4b+LlyRxGsEwIlgnB\n8hCsBM7bL+GhczbBMiFYJgTLQ7ASIFgmBMuIYDWEYCVAsEwIlhHBagjBSoBgmRAsI4LVEIKV\nAMEyIVhGBKshBCsBgmVCsIwIVkMIVgIEy4RgGRGshhCsBAiWCcEyIlgNIVgJECwTgmVEsBpC\nsBIgWCYEy4hgNYRgJUCwTAiWEcFqCMFKgGCZECwjgtUQgpUAwTIhWEYEqyFFDtYxkhTBMiBY\nRgSrIUUO1vSjrklmHMEyIFhGBKshhQ7WOQmPgL0IlgHBMiJYDSFYCRAsE4JlRLAaQrASIFgm\nBMuIYDWEYCVAsEwIlhHBagjBSoBgmRAsI4LVEIKVAMEyIVhGzQ/Woh2/kswXj0q44le++kZP\nPWkbC9balas6bMv0eLAeuiehXQmWAcEy0RSsmQOnJzNOpiVcs/2nPfVsbyBYj50yXER6jVyw\n3LhYTwdrQ3vi938SLAOCZaIpWPvtmXDFz8sfEq7Z746eeronD9bSNhkxbd686aNEFpuWqzNY\nv+uVuDvfSbhXtyRYBgTLhGAZ5TBYV8nch0rnHj9OLjcsWGewbu+b8G3nVxAsE4JlQrBMWipY\nMyZuqpztnLVf5MZ3Lvpsl5PqDFbvjyVzohyecM0++yZccbuRCVfctz3higvlsIRr9pmScMXh\nOyRccZokXPFjMi/hin33SbjiiO0TrvghOTXhmjI34Yr99ky44qjtEq44UxYmXLN3/oI1eGH1\n/LIhkRtfmTeny+wx1tflPc/MnZPMh0fMTrjmuKkJV9x7QsIVZ45MuOKcHZJOcpcpCVfcJ+kk\nZyWe5MhZCVecsE/CFafsknDFWTskXHHOyJkJV5ywd8IVp45LuOLsER9OuOYhzybtik3yn7Am\nbe46f2D0JywA6AENvIZ16IrSuadOkEvTGg4A1Jb8r4RLREbPPOLI2WNEFnWmOCIAqKGB92E9\nvGCY9z6sEQvuT284AFBbY+90f+OFl+t6RR0AUtDznyUEgJQQLABqECwAahAsAGoQLABqECwA\nahAsAGoQLABqECwAahAsAGoQLABqECwAauQmWDck/j8oAPSI9o1ZZ6Gb3ATrJ/3/0Pqu7JP1\nCJrg6rasR9AE18rvsh5Cz7tB3s06C93kJli3D8h6BE1w1xZZj6AJ7mvLegRN8CvZZF9IuwcJ\nVm0Eq1UQrFZBsAwIVqsgWK2CYBkQrFZBsFoFwTIgWK2CYLUKgmVAsFoFwWoVBMuAYLUKgtUq\nCJYBwWoVBKtVECwDgtUqCFarIFgGBKtVEKxWQbAM7t466xE0wS8GZj2CJljeN+sRNMHv+mzO\negg976FeG7IeQje5CVbHc1mPoAk6n816BE1QjEk+k/UImiGHk8xNsADAhmABUINgAVCDYAFQ\ng2ABUINgAVCDYAFQg2ABUINgAVCDYAFQg2ABUINgAVCDYAFQg2ABUINgAVCDYAGNe/uGF7Me\nQjFkF6z/3G/Ifv/ZdekVqbjWcVafO3nLyeeuyWxo6QlPMjyz6G1qGSa5ftmswWMXPJ3RwNJk\neiRdi+T2DAaVNtMkH/jw4BHHZv9IZhasJTLxlAmytHJxzQElO8lPnDVj5YDT9pfxb2Y1ttRE\nJhmaWfQ2tQyTfHOWTF58cFv/hzMcXjpMj6TrZmmFYJkm+f0tdjjhyF7bPJ/d6EqyCtbDcsgm\nZ9PBbY+Fr3575390nGVylXv2Crkok5GlqNskAzOrsQP0MU3yPDnLPXtH+17ZDS8dpkm6Vg4d\n2ALBMk3y+d7T3GxdIwszHJ8vq2AtkEfdr3+UU8JXn77dq45zmLhfnJfkHzMYV6q6TTIwsxo7\nQB/TJCcNWu9dM0f+ntHg0mKapON0HjRmWQsEyzTJc+W37tnOf/tmVoOryCpYw0b5JyOGh669\nR251v35evut+vUm+1PxhpavbJAMzi98BCpkmOXm+f808eTKToaXHNEnH+Vr7r77SAsEyTXKH\n0VmNKiKjYL0h+/mn0+StwLUbx8/2Tt48oM+Cixb0nvNWzIqadJ9kdWbxO0Ah0yTLXu23vfL/\nxM88yYe3OM9pgWCZJvm2zHrk8O1Gf/Sv2Q2vLKNgvSBH+KfzZGXg2n/3f+50nOt6i0ifb2Uw\nrlTFTLJrZvE7QCHTJEueGi//k8HA0mSc5LuT997QCsEyTfJFGTdwj48d0r7l7zMbXllGwXpZ\njvRP58mq6pVrh5Wu/LIc8ei6Rw6Ty7MYWYq6T7I6s9gdoJFpkp53Luzf78qMxpYa4yTP6ve4\n0wrBMk3yWZHPdTrOPW37ZDe+koyC1dFrtn86vVdH9cp/k7u9k9X9dt3onmzYZcu1GYwsRd0m\nGZhZ7A7QyDRJ9+SnO8p87S9gmSd5r/yb0xLBMk3yFdnG/5+uD878zydZveg+Yqx/Mnpk4Lpd\nd/T31G/kDP/iYsn8588GRScZnFncDlDJNEnnQtntlxmNK1WGSV4WfMuzaoZJdvTb1z+7RP6Y\nxcgCsntbw1Pu18dlQfWqB+QC//Sl8o+mpT+qahadZHBmMTtAJ9Mkb5DjN2Q2sDQZJnnPEs80\nOXTJ8syGlw7TI3nI4Pe8s/u3v5PR4CqyCtb9cpLjdB4nv3Kcja+/4V91jpQf8b16eb8a3tn+\ngYzGlppukwzMLHCbboZJdk4c+V7Ww0uH6ZH0tcCvhMZJ3iVnub/+/EDmZz3IzD6as0gOWjZb\nPu6eu1f29q/Ztd/60k0rBrXNPWNO25AnshpbaqKTDM6septytSf5nGx7SMlrWQ+yUaZH0tMK\nwbIcrnuc9g8yIvOPeGcWrM6vzhg842veuXKwXpTZldtWfWLylpNPfyWjkaWo2yQDM6veplzt\nSf686+Ud5e/dMD+SnpYIlnGSl80cNHlp9v8gAf+8DAA1CBYANQgWADUIFgA1CBYANQgWADUI\nFgA1CBYANQgWADUIFgA1CBYANQgWADUIFgA1CBYANQgWADUIFgA1CBYANQgWADUIFgA1CBYA\nNQgWADUIFgA1CBYANQgWADUIFgA1CBYANQgWADUIFgA1CBYANQgWADUIFgA1CBYANQgWADUI\nFgA1CBYANQgWADUIFjLxTtYDgEoECyl5/uRd+40++hHv7OrTd93qoOtD5+YP9C6ul5McZ9Hw\nTUsHXh27wmXyv97FK+XGLGaA/CNYSMefBvY9+pPzew99yS3Rzr0OOW28nB08FwrW6dsu+HXs\nCs/Iyd5i+/ddm+1kkFcEC+n4pNzhfr1KbnKck+VWx9k4o+0vgXPBYPXa4/VaK+w1dJPjvNx+\nVKZTQX4RLKTjl9/ucL/+VK5wXmv/sHfFHTPvqZ4LBUt+UGsF52K5z/uN8IeZTAH5R7CQlvUr\nfvzVCW5/lssl5Wuq58LB+mutFZxHvV8f9x/4bhOHDU0IFtKxbnF/6T1hvtuf78i15euq58LB\neqvWCo4zbif3N8KTmjlwaEKwkI65beet2Ow86PbnXvlK+brquXKwXi8F651aKzjOP8sjV8rt\nzRw4NCFYSMWbvY/2Tu52+/OiHO6dvbP31dVzzvy+ne65n1eDFbuC4/xGLp49dGM2c0D+ESyk\nYrV4L5yvni1fd5zD2u50nE0HtT0ZOHeKPOA4786sBit+BadzxJj2T2Q8F+QXwUI65sqHlp02\n7MOy5+3OE9v1mn/WZPm0Ezh3mww55zMT+w8K/EoYt4LjLBHvD4VALIKFdKxeMmrwrBudM4cs\ndpxVC3cZOOUa73fA6rn/2b2vDL19fDVY8Su4vyOO6MhyHsg1goVm6Xi+ntem/ui9sQGIR7CQ\nL+fKg1kPAflFsJAnax8aOCHrMSDHCBbyZJi03ZL1GJBjBAt5culnf5/1EJBnBAuAGgQLgBoE\nC4AaBAuAGgQLgBoEC4AaBAuAGgQLgBoEC4AaBAuAGgQLgBoEC4AaBAuAGgQLgBoEC4AaBAuA\nGgQLgBoEC4AaBAuAGgQLgBoEC4AaBAuAGgQLgBoEC4AaBAuAGgQLgBr/H6o6I9uKS631AAAA\nAElFTkSuQmCC",
      "text/plain": [
       "Plot with title “Distribution of cross-val accuracy scores for hybrid k-means model with weights”"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width= 10, repr.plot.height= 6)\n",
    "hist(dat_result$Acc, breaks=16, xlab=\"accuracy\",\n",
    "     main=\"Distribution of cross-val accuracy scores for hybrid k-means model with weights\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Final Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should be able to improve upon the hybrid model that does not use weights, especially given that the standard deviation over the 1000 weight combinations looked at above is 0.00235.  Our cross-val mean accuracy score for the hybrid model with no weights is 0.8295.  I would expect to see around 1 standard deviation of improvement on this.  So we should be able to get a score as high as 0.8318 with appropriate weights.  The 0.8318 score would give us a 0.4 percentage point improvement over the svm02 model; while this isn't much, it is better than the 0.17 percentage point improvement that we are currently seeing with the hybrid model, no weights.\n",
    "\n",
    "Finding good weights is not easy from a computational standpoint.  It looks like I need to test each weight combination on far more seeds (the different seeds give us different partitions of the 178 records, i.e., different cross-val folds).  It would also be good to look at all of the 8,801 combinations in the above dfc01 dataframe.  It is worth trying the method I used in the Addendum of Part 2, a method that looks at the total within-group sum of squares of the different k-means clusterings.  In Part 2, this alternative method of finding weights was 7X faster than the method I have been using.  (The improvement in speed depends on what we are trying to do with the data and the amount of data we are working with.)\n",
    "\n",
    "\n",
    "                                * * * * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Hybrid model with weights found using total withinss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method of finding weights set out in the Addendum of Part 2 is not guaranteed to work.  But it is worth trying out here, in our initial search for weights, when we have the most weight combinations to look through.\n",
    "\n",
    "This alternative approach to finding weights acquires further validation if we can find a set of weights using the method which improve upon our cross-val mean accuracy score of 0.8295.\n",
    "\n",
    "This alternative approach is faster because: (a) we no longer have to call getCluster; (b) we no longer have to apply weights to the training set data; (c) we no longer have to call get_mapping; and (d) we no longer have to apply min-max scaling to the training set.  Of these three operations, (a) and (c) are the more expensive ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for computing the tot.withinss for each set of \n",
    "# weights in df_params (a dataframe, each row of which is\n",
    "# a candidate set of weights).  The optimal set of weights\n",
    "# will be the set that yields the smallest average (over\n",
    "# the folds) for tot.withinss.\n",
    "# This function is called from gridSearch07.\n",
    "\n",
    "get_tot.withinss <- function(traindat, valdat, wghts) {\n",
    "    \n",
    "    # Scale traindat for purpose of an svm model.\n",
    "    svm_scaled <- scale(traindat[, -1])\n",
    "    svm_centers <- attr(svm_scaled, \"scaled:center\")\n",
    "    svm_scales <- attr(svm_scaled, \"scaled:scale\")\n",
    "    svm_scaled <- as.data.frame(cbind(traindat$Type, svm_scaled),\n",
    "                                row.names=rownames(traindat))\n",
    "    colnames(svm_scaled) <- colnames(traindat)\n",
    "    \n",
    "    # This is our current best svm model for the trainset data\n",
    "    svmod <- svm(I(as.factor(Type)) ~ ., data=svm_scaled, kernel=\"radial\",\n",
    "                 gamma= 0.03, cost= 25, scale=FALSE, probability=TRUE)\n",
    "    \n",
    "    preds <- predict(svmod, newdata=svm_scaled, scale=FALSE, probability=TRUE)\n",
    "    traindat$prob01 <- as.numeric(attr(preds, \"probabilities\")[, 2])\n",
    "    traindat$prob02 <- as.numeric(attr(preds, \"probabilities\")[, 3])\n",
    "    \n",
    "    #############################\n",
    "    # Scale training set data for the k-means model.\n",
    "    \n",
    "    df <- scale(traindat[, -1], center=TRUE, scale=TRUE)\n",
    "    centers <- attr(df, \"scaled:center\")\n",
    "    scales <- attr(df, \"scaled:scale\")\n",
    "    df <- as.matrix(df)\n",
    "    \n",
    "    # Get mins and maxs for scaling of valdat.\n",
    "    traindat_mins <- as.numeric(apply(df, MARGIN=2, min))\n",
    "    traindat_maxs <- as.numeric(apply(df, MARGIN=2, max))\n",
    "    \n",
    "\n",
    "    #############################################\n",
    "    # Prepare valdat.\n",
    "    #############################################\n",
    "    \n",
    "    svmval_scaled <- scale(valdat[, -1], center=svm_centers, scale=svm_scales)\n",
    "    svmval_scaled <- as.data.frame(svmval_scaled, row.names=rownames(valdat))\n",
    "    \n",
    "    # Compute prob01 and prob02 columns.\n",
    "    preds01_b <- predict(svmod, newdata=svmval_scaled, scale=FALSE, probability=TRUE)\n",
    "    valdat$prob01 <- as.numeric(attr(preds01_b, \"probabilities\")[, 2])\n",
    "    valdat$prob02 <- as.numeric(attr(preds01_b, \"probabilities\")[, 3])\n",
    "\n",
    "    # Scale valdat.\n",
    "    df02 <- scale(valdat[, -1], center=centers, scale=scales)\n",
    "    df02_t <- t(as.matrix(df02))\n",
    "    df02_asList <- split(df02_t, seq(nrow(df02_t)))\n",
    "    names(df02_asList) <- colnames(valdat)[-1]\n",
    "\n",
    "    valdat_scaled <- mapply(range02, df02_asList, traindat_mins, \n",
    "                            traindat_maxs)\n",
    "    # The next step is crucial.\n",
    "    valdat_scaled <- as.data.frame(valdat_scaled, row.names=rownames(valdat))\n",
    "    colnames(valdat_scaled) <- colnames(valdat)[-1]\n",
    "    \n",
    "    # Apply weights to valdat_scaled.\n",
    "    cols <- names(wghts)\n",
    "    df4 <- t(t(valdat_scaled[, cols]) * as.numeric(wghts[cols]))\n",
    "    valdat_wghts <- as.data.frame(df4, row.names=rownames(valdat))\n",
    "    colnames(valdat_wghts) <- colnames(valdat)[-1]\n",
    "    \n",
    "    \n",
    "    #############################################\n",
    "    # Construct k-means model on the validation set.\n",
    "\n",
    "    kmod <- kmeans(valdat_wghts, 3, iter.max = 50, nstart=30)\n",
    "    \n",
    "    return(kmod$tot.withinss)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This grid search searches for the best set of weights to use\n",
    "# in our k-means clustering model. \n",
    "\n",
    "gridSearch07 <- function(seed_vector, dat, df_params, folds=5) {\n",
    "    \n",
    "    datout <- rep(NA, 2*nrow(df_params))\n",
    "    dim(datout) <- c(nrow(df_params), 2)\n",
    "    datout <- as.data.frame(datout)\n",
    "    colnames(datout) <- c(\"row\", \"tot.withinss\")\n",
    "    datout$row <- params_rows <- rownames(df_params)\n",
    "    \n",
    "    # We want the sqrt of the weights.\n",
    "    df_params <- df_params^0.5\n",
    "    \n",
    "    #############################\n",
    "    # Partition the data into folds.\n",
    "    \n",
    "    segment_size <- round(dim(dat)[1]/folds)\n",
    "    diff <- dim(dat)[1] - folds * segment_size\n",
    "    last_seg_size <- segment_size + diff\n",
    "    segmentsv <- c(rep(segment_size, (folds - 1)), last_seg_size)\n",
    "    stopifnot(sum(segmentsv) == dim(dat)[1])\n",
    "    \n",
    "    \n",
    "    # Create a dataframe, each row for a distinct seed.\n",
    "    # Each column of the dataframe is for a distinct set\n",
    "    # of weights.  The entries in the cells are tot.withinss \n",
    "    # scores.\n",
    "    seedv_len <- length(seed_vector)\n",
    "    df_scores <- rep(NA, seedv_len*nrow(df_params))\n",
    "    dim(df_scores) <- c(seedv_len, nrow(df_params))\n",
    "    df_scores <- as.data.frame(df_scores)\n",
    "    colnames(df_scores) <- rownames(df_params)\n",
    "    rownames(df_scores) <- as.character(seed_vector)\n",
    "    \n",
    "    for(h in 1:seedv_len) {\n",
    "        # shuffle dat\n",
    "        cur_seed <- seed_vector[h]\n",
    "        set.seed(cur_seed)\n",
    "        smp <- sample(rownames(dat), nrow(dat), replace= FALSE)\n",
    "        dat <- dat[smp,]\n",
    "        \n",
    "        # Each element of row_list will be the rows we pick\n",
    "        # out for one of the folds.  E.g., the first element\n",
    "        # of row_list will contain the rows we want for the\n",
    "        # first fold, the second element of row_list will\n",
    "        # contain the rows we want for the second fold, and\n",
    "        # so forth.\n",
    "        row_list <- vector(\"list\", length=folds)\n",
    "        names(row_list) <- as.character(1:folds)\n",
    "        startpt <- 1\n",
    "        for(i in 1:folds) {\n",
    "            endpt <- startpt + segmentsv[i] - 1\n",
    "            stopifnot(endpt <= nrow(dat))\n",
    "            row_list[[i]] <- rownames(dat)[startpt:endpt]\n",
    "            startpt <- endpt + 1\n",
    "        }\n",
    "    \n",
    "        for(i in 1:nrow(df_params)) {\n",
    "            \n",
    "            cur_row <- params_rows[i]\n",
    "            wghts <- as.numeric(df_params[i,])\n",
    "            names(wghts) <- colnames(df_params)\n",
    "            \n",
    "            train_list <- test_list <- vector(\"list\", length= folds)\n",
    "            for(j in 1:folds) {\n",
    "                testdat <- dat[row_list[[j]],]\n",
    "                traindat <- dat[which(!(rownames(dat) %in% rownames(testdat))),]\n",
    "                stopifnot((length(rownames(traindat)) + length(rownames(testdat))) == nrow(dat))\n",
    "                test_list[[j]] <- testdat\n",
    "                train_list[[j]] <- traindat\n",
    "            }\n",
    "            # When there are only 5 folds, only 5 cores get used.\n",
    "            scores <- mcmapply(get_tot.withinss02, train_list, test_list,\n",
    "                               MoreArgs= list(wghts=wghts),\n",
    "                               SIMPLIFY= TRUE, mc.cores=5)\n",
    "            \n",
    "            # For the current seed, store the average of the tot.withinss\n",
    "            # scores, the average taken over the folds.\n",
    "            df_scores[as.character(cur_seed), cur_row] <- round(mean(scores), 5)\n",
    "        \n",
    "        } # end of for-loop, index i\n",
    "    } ## end of for-loop, index h\n",
    "    \n",
    "    # Compute the average over the seeds of the tot.withinss scores\n",
    "    # obtained for each set of parameters in df_params.\n",
    "    datout$tot.withinss <- round(apply(df_scores, MARGIN=2, mean), 5)\n",
    "    return(datout)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>8801</li><li>5</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 8801\n",
       "\\item 5\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 8801\n",
       "2. 5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 8801    5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# There are 5 parameter lists to work with.  Start by \n",
    "# exploring the region around the space where all \n",
    "# parameters have an equal weight---in this case, a \n",
    "# weight of 0.20.\n",
    "\n",
    "lst <- vector(\"list\", length= 5)\n",
    "names(lst) <- c(colnames(train)[-1], \"prob01\",\"prob02\")\n",
    "\n",
    "lst[[1]] <- lst[[2]] <- lst[[3]] <- lst[[4]] <- lst[[5]] <- seq(0.10, 0.30, by=0.02)\n",
    "\n",
    "start <- Sys.time()\n",
    "dfc01 <- generate_combs(lst)\n",
    "stop <- Sys.time()\n",
    "# round(stop - start, 2)\n",
    "\n",
    "dim(dfc01)\n",
    "#  8,801     5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Hue</th><th scope=col>Phenols</th><th scope=col>Alcalinity</th><th scope=col>prob01</th><th scope=col>prob02</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>47656</th><td>0.16</td><td>0.28</td><td>0.26</td><td>0.14</td><td>0.16</td></tr>\n",
       "\t<tr><th scope=row>94566</th><td>0.28</td><td>0.20</td><td>0.10</td><td>0.20</td><td>0.22</td></tr>\n",
       "\t<tr><th scope=row>26846</th><td>0.20</td><td>0.28</td><td>0.12</td><td>0.28</td><td>0.12</td></tr>\n",
       "\t<tr><th scope=row>10006</th><td>0.22</td><td>0.24</td><td>0.20</td><td>0.24</td><td>0.10</td></tr>\n",
       "\t<tr><th scope=row>136376</th><td>0.26</td><td>0.10</td><td>0.20</td><td>0.16</td><td>0.28</td></tr>\n",
       "\t<tr><th scope=row>73086</th><td>0.12</td><td>0.10</td><td>0.30</td><td>0.30</td><td>0.18</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & Hue & Phenols & Alcalinity & prob01 & prob02\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t47656 & 0.16 & 0.28 & 0.26 & 0.14 & 0.16\\\\\n",
       "\t94566 & 0.28 & 0.20 & 0.10 & 0.20 & 0.22\\\\\n",
       "\t26846 & 0.20 & 0.28 & 0.12 & 0.28 & 0.12\\\\\n",
       "\t10006 & 0.22 & 0.24 & 0.20 & 0.24 & 0.10\\\\\n",
       "\t136376 & 0.26 & 0.10 & 0.20 & 0.16 & 0.28\\\\\n",
       "\t73086 & 0.12 & 0.10 & 0.30 & 0.30 & 0.18\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 5\n",
       "\n",
       "| <!--/--> | Hue &lt;dbl&gt; | Phenols &lt;dbl&gt; | Alcalinity &lt;dbl&gt; | prob01 &lt;dbl&gt; | prob02 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 47656 | 0.16 | 0.28 | 0.26 | 0.14 | 0.16 |\n",
       "| 94566 | 0.28 | 0.20 | 0.10 | 0.20 | 0.22 |\n",
       "| 26846 | 0.20 | 0.28 | 0.12 | 0.28 | 0.12 |\n",
       "| 10006 | 0.22 | 0.24 | 0.20 | 0.24 | 0.10 |\n",
       "| 136376 | 0.26 | 0.10 | 0.20 | 0.16 | 0.28 |\n",
       "| 73086 | 0.12 | 0.10 | 0.30 | 0.30 | 0.18 |\n",
       "\n"
      ],
      "text/plain": [
       "       Hue  Phenols Alcalinity prob01 prob02\n",
       "47656  0.16 0.28    0.26       0.14   0.16  \n",
       "94566  0.28 0.20    0.10       0.20   0.22  \n",
       "26846  0.20 0.28    0.12       0.28   0.12  \n",
       "10006  0.22 0.24    0.20       0.24   0.10  \n",
       "136376 0.26 0.10    0.20       0.16   0.28  \n",
       "73086  0.12 0.10    0.30       0.30   0.18  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test on a sample of 100.\n",
    "\n",
    "set.seed(42)\n",
    "smp <- sample(rownames(dfc01), 100, replace=FALSE)\n",
    "tst_params <- dfc01[smp,]\n",
    "head(tst_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time difference of 7.82 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the best weights of those in tst_params.\n",
    "# Use 120 seeds.\n",
    "\n",
    "set.seed(1233)\n",
    "seed_vector <- sample(1:9999, 120, replace=FALSE)\n",
    "\n",
    "start <- Sys.time()\n",
    "dat_result <- gridSearch07(seed_vector, train, tst_params) \n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 7.82 mins (for 100 rows; 120 seeds each row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params <- dat_result[which(dat_result$tot.withinss == \n",
    "                                min(dat_result$tot.withinss, na.rm=TRUE)),]$row\n",
    "length(best_params)\n",
    "\n",
    "best_tot.withinss <- round(dat_result[which(dat_result$tot.withinss == \n",
    "                                min(dat_result$tot.withinss, na.rm=TRUE)),]$tot.withinss, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 1 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Hue</th><th scope=col>Phenols</th><th scope=col>Alcalinity</th><th scope=col>prob01</th><th scope=col>prob02</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>145126</th><td>0.14</td><td>0.18</td><td>0.1</td><td>0.3</td><td>0.28</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & Hue & Phenols & Alcalinity & prob01 & prob02\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t145126 & 0.14 & 0.18 & 0.1 & 0.3 & 0.28\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 5\n",
       "\n",
       "| <!--/--> | Hue &lt;dbl&gt; | Phenols &lt;dbl&gt; | Alcalinity &lt;dbl&gt; | prob01 &lt;dbl&gt; | prob02 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 145126 | 0.14 | 0.18 | 0.1 | 0.3 | 0.28 |\n",
       "\n"
      ],
      "text/plain": [
       "       Hue  Phenols Alcalinity prob01 prob02\n",
       "145126 0.14 0.18    0.1        0.3    0.28  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.55"
      ],
      "text/latex": [
       "0.55"
      ],
      "text/markdown": [
       "0.55"
      ],
      "text/plain": [
       "[1] 0.55"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfc01[best_params,]\n",
    "\n",
    "best_tot.withinss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMMENT:\n",
    "\n",
    "# I will search 5000 of the 8801 weight combinations.  This \n",
    "# should take approximately 6.5 hours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>3801</li><li>5</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 3801\n",
       "\\item 5\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 3801\n",
       "2. 5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 3801    5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(42)\n",
    "smp <- sample(rownames(dfc01), 5000, replace=FALSE)\n",
    "tst_params <- dfc01[smp,]\n",
    "remaining <- dfc01[which(!(rownames(dfc01) %in% rownames(tst_params))),]\n",
    "dim(remaining)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(remaining, file=\"/home/greg/Documents/stat/github_repos/nudging_kmeans/untested_weights.Rdata\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time difference of 7.93 hours"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the best weights of those in tst_params.\n",
    "# Use 120 seeds.\n",
    "\n",
    "set.seed(1233)\n",
    "seed_vector <- sample(1:9999, 120, replace=FALSE)\n",
    "\n",
    "start <- Sys.time()\n",
    "paste0(\"Start time: \", start)\n",
    "dat_result <- gridSearch07(seed_vector, train, tst_params) \n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 7.93 hours (for 5000 rows; 120 seeds each row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(dat_result, file=\"/home/greg/Documents/stat/github_repos/nudging_kmeans/processed_weights.Rdata\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params <- dat_result[which(dat_result$tot.withinss == \n",
    "                                min(dat_result$tot.withinss, na.rm=TRUE)),]$row\n",
    "length(best_params)\n",
    "\n",
    "best_tot.withinss <- round(dat_result[which(dat_result$tot.withinss == \n",
    "                                min(dat_result$tot.withinss, na.rm=TRUE)),]$tot.withinss, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 1 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Hue</th><th scope=col>Phenols</th><th scope=col>Alcalinity</th><th scope=col>prob01</th><th scope=col>prob02</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>159776</th><td>0.1</td><td>0.2</td><td>0.1</td><td>0.3</td><td>0.3</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & Hue & Phenols & Alcalinity & prob01 & prob02\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t159776 & 0.1 & 0.2 & 0.1 & 0.3 & 0.3\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 5\n",
       "\n",
       "| <!--/--> | Hue &lt;dbl&gt; | Phenols &lt;dbl&gt; | Alcalinity &lt;dbl&gt; | prob01 &lt;dbl&gt; | prob02 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 159776 | 0.1 | 0.2 | 0.1 | 0.3 | 0.3 |\n",
       "\n"
      ],
      "text/plain": [
       "       Hue Phenols Alcalinity prob01 prob02\n",
       "159776 0.1 0.2     0.1        0.3    0.3   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.5428"
      ],
      "text/latex": [
       "0.5428"
      ],
      "text/markdown": [
       "0.5428"
      ],
      "text/plain": [
       "[1] 0.5428"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfc01[best_params,]\n",
    "#       \tHue \tPhenols \t Alcalinity  \t prob01 \t prob02\n",
    "\n",
    "# 159776\t0.1     \t0.2         \t0.1     \t0.3     \t0.3\n",
    "\n",
    "\n",
    "best_tot.withinss\n",
    "# 0.5428\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 15 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>row</th><th scope=col>tot.withinss</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>2071</th><td>159776</td><td>0.54280</td></tr>\n",
       "\t<tr><th scope=row>2384</th><td>159756</td><td>0.54420</td></tr>\n",
       "\t<tr><th scope=row>3975</th><td>159766</td><td>0.54421</td></tr>\n",
       "\t<tr><th scope=row>1615</th><td>145146</td><td>0.54453</td></tr>\n",
       "\t<tr><th scope=row>939</th><td>153176</td><td>0.54456</td></tr>\n",
       "\t<tr><th scope=row>2008</th><td>157126</td><td>0.54492</td></tr>\n",
       "\t<tr><th scope=row>3441</th><td>159886</td><td>0.54503</td></tr>\n",
       "\t<tr><th scope=row>4654</th><td>139866</td><td>0.54511</td></tr>\n",
       "\t<tr><th scope=row>515</th><td>151846</td><td>0.54563</td></tr>\n",
       "\t<tr><th scope=row>2091</th><td>153166</td><td>0.54584</td></tr>\n",
       "\t<tr><th scope=row>2748</th><td>129196</td><td>0.54608</td></tr>\n",
       "\t<tr><th scope=row>4255</th><td>127876</td><td>0.54618</td></tr>\n",
       "\t<tr><th scope=row>1465</th><td>115886</td><td>0.54622</td></tr>\n",
       "\t<tr><th scope=row>1647</th><td>159876</td><td>0.54632</td></tr>\n",
       "\t<tr><th scope=row>2642</th><td>158426</td><td>0.54633</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 15 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & row & tot.withinss\\\\\n",
       "  & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t2071 & 159776 & 0.54280\\\\\n",
       "\t2384 & 159756 & 0.54420\\\\\n",
       "\t3975 & 159766 & 0.54421\\\\\n",
       "\t1615 & 145146 & 0.54453\\\\\n",
       "\t939 & 153176 & 0.54456\\\\\n",
       "\t2008 & 157126 & 0.54492\\\\\n",
       "\t3441 & 159886 & 0.54503\\\\\n",
       "\t4654 & 139866 & 0.54511\\\\\n",
       "\t515 & 151846 & 0.54563\\\\\n",
       "\t2091 & 153166 & 0.54584\\\\\n",
       "\t2748 & 129196 & 0.54608\\\\\n",
       "\t4255 & 127876 & 0.54618\\\\\n",
       "\t1465 & 115886 & 0.54622\\\\\n",
       "\t1647 & 159876 & 0.54632\\\\\n",
       "\t2642 & 158426 & 0.54633\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 15 × 2\n",
       "\n",
       "| <!--/--> | row &lt;chr&gt; | tot.withinss &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 2071 | 159776 | 0.54280 |\n",
       "| 2384 | 159756 | 0.54420 |\n",
       "| 3975 | 159766 | 0.54421 |\n",
       "| 1615 | 145146 | 0.54453 |\n",
       "| 939 | 153176 | 0.54456 |\n",
       "| 2008 | 157126 | 0.54492 |\n",
       "| 3441 | 159886 | 0.54503 |\n",
       "| 4654 | 139866 | 0.54511 |\n",
       "| 515 | 151846 | 0.54563 |\n",
       "| 2091 | 153166 | 0.54584 |\n",
       "| 2748 | 129196 | 0.54608 |\n",
       "| 4255 | 127876 | 0.54618 |\n",
       "| 1465 | 115886 | 0.54622 |\n",
       "| 1647 | 159876 | 0.54632 |\n",
       "| 2642 | 158426 | 0.54633 |\n",
       "\n"
      ],
      "text/plain": [
       "     row    tot.withinss\n",
       "2071 159776 0.54280     \n",
       "2384 159756 0.54420     \n",
       "3975 159766 0.54421     \n",
       "1615 145146 0.54453     \n",
       "939  153176 0.54456     \n",
       "2008 157126 0.54492     \n",
       "3441 159886 0.54503     \n",
       "4654 139866 0.54511     \n",
       "515  151846 0.54563     \n",
       "2091 153166 0.54584     \n",
       "2748 129196 0.54608     \n",
       "4255 127876 0.54618     \n",
       "1465 115886 0.54622     \n",
       "1647 159876 0.54632     \n",
       "2642 158426 0.54633     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dat01 <- dat_result[order(dat_result$tot.withinss, decreasing=FALSE),]\n",
    "dat01[1:15,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 10 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Hue</th><th scope=col>Phenols</th><th scope=col>Alcalinity</th><th scope=col>prob01</th><th scope=col>prob02</th><th scope=col>withinss.vals</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>159776</th><td>0.10</td><td>0.20</td><td>0.10</td><td>0.30</td><td>0.30</td><td>0.54280</td></tr>\n",
       "\t<tr><th scope=row>159756</th><td>0.14</td><td>0.16</td><td>0.10</td><td>0.30</td><td>0.30</td><td>0.54420</td></tr>\n",
       "\t<tr><th scope=row>159766</th><td>0.12</td><td>0.18</td><td>0.10</td><td>0.30</td><td>0.30</td><td>0.54421</td></tr>\n",
       "\t<tr><th scope=row>145146</th><td>0.10</td><td>0.22</td><td>0.10</td><td>0.30</td><td>0.28</td><td>0.54453</td></tr>\n",
       "\t<tr><th scope=row>153176</th><td>0.10</td><td>0.30</td><td>0.10</td><td>0.20</td><td>0.30</td><td>0.54456</td></tr>\n",
       "\t<tr><th scope=row>157126</th><td>0.12</td><td>0.22</td><td>0.10</td><td>0.26</td><td>0.30</td><td>0.54492</td></tr>\n",
       "\t<tr><th scope=row>159886</th><td>0.10</td><td>0.18</td><td>0.12</td><td>0.30</td><td>0.30</td><td>0.54503</td></tr>\n",
       "\t<tr><th scope=row>139866</th><td>0.10</td><td>0.30</td><td>0.10</td><td>0.22</td><td>0.28</td><td>0.54511</td></tr>\n",
       "\t<tr><th scope=row>151846</th><td>0.12</td><td>0.30</td><td>0.10</td><td>0.18</td><td>0.30</td><td>0.54563</td></tr>\n",
       "\t<tr><th scope=row>153166</th><td>0.12</td><td>0.28</td><td>0.10</td><td>0.20</td><td>0.30</td><td>0.54584</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 10 × 6\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & Hue & Phenols & Alcalinity & prob01 & prob02 & withinss.vals\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t159776 & 0.10 & 0.20 & 0.10 & 0.30 & 0.30 & 0.54280\\\\\n",
       "\t159756 & 0.14 & 0.16 & 0.10 & 0.30 & 0.30 & 0.54420\\\\\n",
       "\t159766 & 0.12 & 0.18 & 0.10 & 0.30 & 0.30 & 0.54421\\\\\n",
       "\t145146 & 0.10 & 0.22 & 0.10 & 0.30 & 0.28 & 0.54453\\\\\n",
       "\t153176 & 0.10 & 0.30 & 0.10 & 0.20 & 0.30 & 0.54456\\\\\n",
       "\t157126 & 0.12 & 0.22 & 0.10 & 0.26 & 0.30 & 0.54492\\\\\n",
       "\t159886 & 0.10 & 0.18 & 0.12 & 0.30 & 0.30 & 0.54503\\\\\n",
       "\t139866 & 0.10 & 0.30 & 0.10 & 0.22 & 0.28 & 0.54511\\\\\n",
       "\t151846 & 0.12 & 0.30 & 0.10 & 0.18 & 0.30 & 0.54563\\\\\n",
       "\t153166 & 0.12 & 0.28 & 0.10 & 0.20 & 0.30 & 0.54584\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 10 × 6\n",
       "\n",
       "| <!--/--> | Hue &lt;dbl&gt; | Phenols &lt;dbl&gt; | Alcalinity &lt;dbl&gt; | prob01 &lt;dbl&gt; | prob02 &lt;dbl&gt; | withinss.vals &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 159776 | 0.10 | 0.20 | 0.10 | 0.30 | 0.30 | 0.54280 |\n",
       "| 159756 | 0.14 | 0.16 | 0.10 | 0.30 | 0.30 | 0.54420 |\n",
       "| 159766 | 0.12 | 0.18 | 0.10 | 0.30 | 0.30 | 0.54421 |\n",
       "| 145146 | 0.10 | 0.22 | 0.10 | 0.30 | 0.28 | 0.54453 |\n",
       "| 153176 | 0.10 | 0.30 | 0.10 | 0.20 | 0.30 | 0.54456 |\n",
       "| 157126 | 0.12 | 0.22 | 0.10 | 0.26 | 0.30 | 0.54492 |\n",
       "| 159886 | 0.10 | 0.18 | 0.12 | 0.30 | 0.30 | 0.54503 |\n",
       "| 139866 | 0.10 | 0.30 | 0.10 | 0.22 | 0.28 | 0.54511 |\n",
       "| 151846 | 0.12 | 0.30 | 0.10 | 0.18 | 0.30 | 0.54563 |\n",
       "| 153166 | 0.12 | 0.28 | 0.10 | 0.20 | 0.30 | 0.54584 |\n",
       "\n"
      ],
      "text/plain": [
       "       Hue  Phenols Alcalinity prob01 prob02 withinss.vals\n",
       "159776 0.10 0.20    0.10       0.30   0.30   0.54280      \n",
       "159756 0.14 0.16    0.10       0.30   0.30   0.54420      \n",
       "159766 0.12 0.18    0.10       0.30   0.30   0.54421      \n",
       "145146 0.10 0.22    0.10       0.30   0.28   0.54453      \n",
       "153176 0.10 0.30    0.10       0.20   0.30   0.54456      \n",
       "157126 0.12 0.22    0.10       0.26   0.30   0.54492      \n",
       "159886 0.10 0.18    0.12       0.30   0.30   0.54503      \n",
       "139866 0.10 0.30    0.10       0.22   0.28   0.54511      \n",
       "151846 0.12 0.30    0.10       0.18   0.30   0.54563      \n",
       "153166 0.12 0.28    0.10       0.20   0.30   0.54584      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bestrows <- as.character(dat01$row)[1:10]\n",
    "withinss.vals <- dat01[1:10, c(\"tot.withinss\")]\n",
    "dat01_b <- cbind(dfc01[bestrows, ], withinss.vals)\n",
    "dat01_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMMENTS:\n",
    "\n",
    "# The best weights identified are almost all at the limits\n",
    "# of the tested parameter space: 0.10 was the smallest \n",
    "# possible value, and 0.30 was the largest.  Thus, we\n",
    "# might see even smaller total withinss in regions that\n",
    "# have yet to be tested.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>309</li><li>5</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 309\n",
       "\\item 5\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 309\n",
       "2. 5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 309   5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Refine the search a bit.\n",
    "\n",
    "lst <- vector(\"list\", length= 5)\n",
    "names(lst) <- c(colnames(train)[-1], \"prob01\",\"prob02\")\n",
    "\n",
    "lst[[1]] <- seq(0.08, 0.12, by=0.01)\n",
    "lst[[2]] <- seq(0.18, 0.22, by=0.01)\n",
    "lst[[3]] <- seq(0.08, 0.12, by=0.01)\n",
    "lst[[4]] <- seq(0.28, 0.34, by=0.01)\n",
    "lst[[5]] <- seq(0.28, 0.34, by=0.02)\n",
    "\n",
    "start <- Sys.time()\n",
    "dfc02 <- generate_combs(lst)\n",
    "stop <- Sys.time()\n",
    "# round(stop - start, 2)\n",
    "\n",
    "dim(dfc02)\n",
    "#  8,801     5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>310</li><li>5</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 310\n",
       "\\item 5\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 310\n",
       "2. 5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 310   5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add in the no-weights combination.\n",
    "\n",
    "dfc02 <- rbind(dfc02, rep(0.20, 5))\n",
    "dim(dfc02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-06-01 09:12:07'"
      ],
      "text/latex": [
       "'Start time: 2021-06-01 09:12:07'"
      ],
      "text/markdown": [
       "'Start time: 2021-06-01 09:12:07'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-06-01 09:12:07\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 2.11 hours"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the best weights of those in dfc02.\n",
    "# Use 120 seeds.  Use gridSearch03.\n",
    "\n",
    "set.seed(1987)\n",
    "seed_vector <- sample(1:9999, 120, replace=FALSE)\n",
    "\n",
    "start <- Sys.time()\n",
    "paste0(\"Start time: \", start)\n",
    "dat_result <- gridSearch03(seed_vector, train, dfc02) \n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 2.11 hours\n",
    "\n",
    "# This time difference tells us that for this 178 record\n",
    "# dataset, the alternative method of finding weights is\n",
    "# 5.2X faster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "5e-04"
      ],
      "text/latex": [
       "5e-04"
      ],
      "text/markdown": [
       "5e-04"
      ],
      "text/plain": [
       "[1] 5e-04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.0027"
      ],
      "text/latex": [
       "0.0027"
      ],
      "text/markdown": [
       "0.0027"
      ],
      "text/plain": [
       "[1] 0.0027"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(sd(dat_result$Acc), 4)\n",
    "# 0.0005\n",
    "\n",
    "round((max(dat_result$Acc) - min(dat_result$Acc)), 4)\n",
    "# 0.0027\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMMENT:\n",
    "\n",
    "# Note the low standard deviation for the 310 weight \n",
    "# combinations and the low range.  Our \"no weights\"\n",
    "# combination is among the 310.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "2"
      ],
      "text/latex": [
       "2"
      ],
      "text/markdown": [
       "2"
      ],
      "text/plain": [
       "[1] 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params <- dat_result[which(dat_result$Acc == \n",
    "                                max(dat_result$Acc, na.rm=TRUE)),]$row\n",
    "length(best_params)\n",
    "\n",
    "best_Acc <- dat_result[which(dat_result$Acc == \n",
    "                                max(dat_result$Acc, na.rm=TRUE)),]$Acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 2 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Hue</th><th scope=col>Phenols</th><th scope=col>Alcalinity</th><th scope=col>prob01</th><th scope=col>prob02</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>515</th><td>0.12</td><td>0.20</td><td>0.08</td><td>0.32</td><td>0.28</td></tr>\n",
       "\t<tr><th scope=row>1284</th><td>0.11</td><td>0.19</td><td>0.09</td><td>0.31</td><td>0.30</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 2 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & Hue & Phenols & Alcalinity & prob01 & prob02\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t515 & 0.12 & 0.20 & 0.08 & 0.32 & 0.28\\\\\n",
       "\t1284 & 0.11 & 0.19 & 0.09 & 0.31 & 0.30\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 2 × 5\n",
       "\n",
       "| <!--/--> | Hue &lt;dbl&gt; | Phenols &lt;dbl&gt; | Alcalinity &lt;dbl&gt; | prob01 &lt;dbl&gt; | prob02 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 515 | 0.12 | 0.20 | 0.08 | 0.32 | 0.28 |\n",
       "| 1284 | 0.11 | 0.19 | 0.09 | 0.31 | 0.30 |\n",
       "\n"
      ],
      "text/plain": [
       "     Hue  Phenols Alcalinity prob01 prob02\n",
       "515  0.12 0.20    0.08       0.32   0.28  \n",
       "1284 0.11 0.19    0.09       0.31   0.30  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfc02[best_params,]\n",
    "#       \t Hue \t Phenols \t Alcalinity \tprob01  \tprob02\n",
    "\n",
    "# 515   \t0.12    \t0.20 \t       0.08 \t  0.32  \t  0.28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 10 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>row</th><th scope=col>Acc</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>50</th><td>515 </td><td>0.83110</td></tr>\n",
       "\t<tr><th scope=row>159</th><td>1284</td><td>0.83110</td></tr>\n",
       "\t<tr><th scope=row>46</th><td>479 </td><td>0.83107</td></tr>\n",
       "\t<tr><th scope=row>69</th><td>635 </td><td>0.83088</td></tr>\n",
       "\t<tr><th scope=row>261</th><td>2161</td><td>0.83086</td></tr>\n",
       "\t<tr><th scope=row>192</th><td>1532</td><td>0.83082</td></tr>\n",
       "\t<tr><th scope=row>205</th><td>1773</td><td>0.83080</td></tr>\n",
       "\t<tr><th scope=row>308</th><td>3026</td><td>0.83080</td></tr>\n",
       "\t<tr><th scope=row>20</th><td>315 </td><td>0.83079</td></tr>\n",
       "\t<tr><th scope=row>165</th><td>1312</td><td>0.83078</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 10 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & row & Acc\\\\\n",
       "  & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t50 & 515  & 0.83110\\\\\n",
       "\t159 & 1284 & 0.83110\\\\\n",
       "\t46 & 479  & 0.83107\\\\\n",
       "\t69 & 635  & 0.83088\\\\\n",
       "\t261 & 2161 & 0.83086\\\\\n",
       "\t192 & 1532 & 0.83082\\\\\n",
       "\t205 & 1773 & 0.83080\\\\\n",
       "\t308 & 3026 & 0.83080\\\\\n",
       "\t20 & 315  & 0.83079\\\\\n",
       "\t165 & 1312 & 0.83078\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 10 × 2\n",
       "\n",
       "| <!--/--> | row &lt;chr&gt; | Acc &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 50 | 515  | 0.83110 |\n",
       "| 159 | 1284 | 0.83110 |\n",
       "| 46 | 479  | 0.83107 |\n",
       "| 69 | 635  | 0.83088 |\n",
       "| 261 | 2161 | 0.83086 |\n",
       "| 192 | 1532 | 0.83082 |\n",
       "| 205 | 1773 | 0.83080 |\n",
       "| 308 | 3026 | 0.83080 |\n",
       "| 20 | 315  | 0.83079 |\n",
       "| 165 | 1312 | 0.83078 |\n",
       "\n"
      ],
      "text/plain": [
       "    row  Acc    \n",
       "50  515  0.83110\n",
       "159 1284 0.83110\n",
       "46  479  0.83107\n",
       "69  635  0.83088\n",
       "261 2161 0.83086\n",
       "192 1532 0.83082\n",
       "205 1773 0.83080\n",
       "308 3026 0.83080\n",
       "20  315  0.83079\n",
       "165 1312 0.83078"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dat02 <- dat_result[order(dat_result$Acc, decreasing=TRUE),]\n",
    "dat02[1:10,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 3 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Hue</th><th scope=col>Phenols</th><th scope=col>Alcalinity</th><th scope=col>prob01</th><th scope=col>prob02</th><th scope=col>acc</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>515</th><td>0.12</td><td>0.20</td><td>0.08</td><td>0.32</td><td>0.28</td><td>0.83110</td></tr>\n",
       "\t<tr><th scope=row>1284</th><td>0.11</td><td>0.19</td><td>0.09</td><td>0.31</td><td>0.30</td><td>0.83110</td></tr>\n",
       "\t<tr><th scope=row>479</th><td>0.11</td><td>0.18</td><td>0.12</td><td>0.31</td><td>0.28</td><td>0.83107</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 3 × 6\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & Hue & Phenols & Alcalinity & prob01 & prob02 & acc\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t515 & 0.12 & 0.20 & 0.08 & 0.32 & 0.28 & 0.83110\\\\\n",
       "\t1284 & 0.11 & 0.19 & 0.09 & 0.31 & 0.30 & 0.83110\\\\\n",
       "\t479 & 0.11 & 0.18 & 0.12 & 0.31 & 0.28 & 0.83107\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 3 × 6\n",
       "\n",
       "| <!--/--> | Hue &lt;dbl&gt; | Phenols &lt;dbl&gt; | Alcalinity &lt;dbl&gt; | prob01 &lt;dbl&gt; | prob02 &lt;dbl&gt; | acc &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 515 | 0.12 | 0.20 | 0.08 | 0.32 | 0.28 | 0.83110 |\n",
       "| 1284 | 0.11 | 0.19 | 0.09 | 0.31 | 0.30 | 0.83110 |\n",
       "| 479 | 0.11 | 0.18 | 0.12 | 0.31 | 0.28 | 0.83107 |\n",
       "\n"
      ],
      "text/plain": [
       "     Hue  Phenols Alcalinity prob01 prob02 acc    \n",
       "515  0.12 0.20    0.08       0.32   0.28   0.83110\n",
       "1284 0.11 0.19    0.09       0.31   0.30   0.83110\n",
       "479  0.11 0.18    0.12       0.31   0.28   0.83107"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bestrows <- as.character(dat02$row)[1:3]\n",
    "acc <- dat02[1:3, c(\"Acc\")]\n",
    "dat02_b <- cbind(dfc02[bestrows, ], acc)\n",
    "dat02_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Hue</th><th scope=col>Phenols</th><th scope=col>Alcalinity</th><th scope=col>prob01</th><th scope=col>prob02</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>2926</th><td>0.08</td><td>0.18</td><td>0.10</td><td>0.30</td><td>0.34</td></tr>\n",
       "\t<tr><th scope=row>3002</th><td>0.09</td><td>0.18</td><td>0.08</td><td>0.31</td><td>0.34</td></tr>\n",
       "\t<tr><th scope=row>3006</th><td>0.08</td><td>0.19</td><td>0.08</td><td>0.31</td><td>0.34</td></tr>\n",
       "\t<tr><th scope=row>3026</th><td>0.08</td><td>0.18</td><td>0.09</td><td>0.31</td><td>0.34</td></tr>\n",
       "\t<tr><th scope=row>3126</th><td>0.08</td><td>0.18</td><td>0.08</td><td>0.32</td><td>0.34</td></tr>\n",
       "\t<tr><th scope=row>310</th><td>0.20</td><td>0.20</td><td>0.20</td><td>0.20</td><td>0.20</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & Hue & Phenols & Alcalinity & prob01 & prob02\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t2926 & 0.08 & 0.18 & 0.10 & 0.30 & 0.34\\\\\n",
       "\t3002 & 0.09 & 0.18 & 0.08 & 0.31 & 0.34\\\\\n",
       "\t3006 & 0.08 & 0.19 & 0.08 & 0.31 & 0.34\\\\\n",
       "\t3026 & 0.08 & 0.18 & 0.09 & 0.31 & 0.34\\\\\n",
       "\t3126 & 0.08 & 0.18 & 0.08 & 0.32 & 0.34\\\\\n",
       "\t310 & 0.20 & 0.20 & 0.20 & 0.20 & 0.20\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 5\n",
       "\n",
       "| <!--/--> | Hue &lt;dbl&gt; | Phenols &lt;dbl&gt; | Alcalinity &lt;dbl&gt; | prob01 &lt;dbl&gt; | prob02 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 2926 | 0.08 | 0.18 | 0.10 | 0.30 | 0.34 |\n",
       "| 3002 | 0.09 | 0.18 | 0.08 | 0.31 | 0.34 |\n",
       "| 3006 | 0.08 | 0.19 | 0.08 | 0.31 | 0.34 |\n",
       "| 3026 | 0.08 | 0.18 | 0.09 | 0.31 | 0.34 |\n",
       "| 3126 | 0.08 | 0.18 | 0.08 | 0.32 | 0.34 |\n",
       "| 310 | 0.20 | 0.20 | 0.20 | 0.20 | 0.20 |\n",
       "\n"
      ],
      "text/plain": [
       "     Hue  Phenols Alcalinity prob01 prob02\n",
       "2926 0.08 0.18    0.10       0.30   0.34  \n",
       "3002 0.09 0.18    0.08       0.31   0.34  \n",
       "3006 0.08 0.19    0.08       0.31   0.34  \n",
       "3026 0.08 0.18    0.09       0.31   0.34  \n",
       "3126 0.08 0.18    0.08       0.32   0.34  \n",
       "310  0.20 0.20    0.20       0.20   0.20  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tail(dfc02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.83022"
      ],
      "text/latex": [
       "0.83022"
      ],
      "text/markdown": [
       "0.83022"
      ],
      "text/plain": [
       "[1] 0.83022"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dat02[\"310\", c(\"Acc\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMMENT:\n",
    "\n",
    "# Over 120 seeds (600 folds), the current best weights\n",
    "# have a score of 0.83110 and the \"no-weights\" model\n",
    "# has a score of 0.83022.  This is a difference of \n",
    "# 8.8e-04.  In other words, the current best weights\n",
    "# are not helping much at all to improve the average\n",
    "# accuracy score of the k-means hybrid model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine the search.\n",
    "\n",
    "dfc03 <- dat02_b[, 1:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-06-01 11:50:04'"
      ],
      "text/latex": [
       "'Start time: 2021-06-01 11:50:04'"
      ],
      "text/markdown": [
       "'Start time: 2021-06-01 11:50:04'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-06-01 11:50:04\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 12.49 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the best weights of those in dfc03.\n",
    "# Use 1200 seeds.  Use gridSearch03.\n",
    "\n",
    "set.seed(1981)\n",
    "seed_vector <- sample(1:9999, 1200, replace=FALSE)\n",
    "\n",
    "start <- Sys.time()\n",
    "paste0(\"Start time: \", start)\n",
    "dat_result <- gridSearch03(seed_vector, train, dfc03) \n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 12.49 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params <- dat_result[which(dat_result$Acc == \n",
    "                                max(dat_result$Acc, na.rm=TRUE)),]$row\n",
    "length(best_params)\n",
    "\n",
    "best_Acc <- dat_result[which(dat_result$Acc == \n",
    "                                max(dat_result$Acc, na.rm=TRUE)),]$Acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 3 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>row</th><th scope=col>Acc</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>3</th><td>479 </td><td>0.83024</td></tr>\n",
       "\t<tr><th scope=row>1</th><td>515 </td><td>0.83002</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>1284</td><td>0.82997</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 3 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & row & Acc\\\\\n",
       "  & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t3 & 479  & 0.83024\\\\\n",
       "\t1 & 515  & 0.83002\\\\\n",
       "\t2 & 1284 & 0.82997\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 3 × 2\n",
       "\n",
       "| <!--/--> | row &lt;chr&gt; | Acc &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 3 | 479  | 0.83024 |\n",
       "| 1 | 515  | 0.83002 |\n",
       "| 2 | 1284 | 0.82997 |\n",
       "\n"
      ],
      "text/plain": [
       "  row  Acc    \n",
       "3 479  0.83024\n",
       "1 515  0.83002\n",
       "2 1284 0.82997"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dat03 <- dat_result[order(dat_result$Acc, decreasing=TRUE),]\n",
    "dat03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 3 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Hue</th><th scope=col>Phenols</th><th scope=col>Alcalinity</th><th scope=col>prob01</th><th scope=col>prob02</th><th scope=col>acc</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>479</th><td>0.11</td><td>0.18</td><td>0.12</td><td>0.31</td><td>0.28</td><td>0.83024</td></tr>\n",
       "\t<tr><th scope=row>515</th><td>0.12</td><td>0.20</td><td>0.08</td><td>0.32</td><td>0.28</td><td>0.83002</td></tr>\n",
       "\t<tr><th scope=row>1284</th><td>0.11</td><td>0.19</td><td>0.09</td><td>0.31</td><td>0.30</td><td>0.82997</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 3 × 6\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & Hue & Phenols & Alcalinity & prob01 & prob02 & acc\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t479 & 0.11 & 0.18 & 0.12 & 0.31 & 0.28 & 0.83024\\\\\n",
       "\t515 & 0.12 & 0.20 & 0.08 & 0.32 & 0.28 & 0.83002\\\\\n",
       "\t1284 & 0.11 & 0.19 & 0.09 & 0.31 & 0.30 & 0.82997\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 3 × 6\n",
       "\n",
       "| <!--/--> | Hue &lt;dbl&gt; | Phenols &lt;dbl&gt; | Alcalinity &lt;dbl&gt; | prob01 &lt;dbl&gt; | prob02 &lt;dbl&gt; | acc &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 479 | 0.11 | 0.18 | 0.12 | 0.31 | 0.28 | 0.83024 |\n",
       "| 515 | 0.12 | 0.20 | 0.08 | 0.32 | 0.28 | 0.83002 |\n",
       "| 1284 | 0.11 | 0.19 | 0.09 | 0.31 | 0.30 | 0.82997 |\n",
       "\n"
      ],
      "text/plain": [
       "     Hue  Phenols Alcalinity prob01 prob02 acc    \n",
       "479  0.11 0.18    0.12       0.31   0.28   0.83024\n",
       "515  0.12 0.20    0.08       0.32   0.28   0.83002\n",
       "1284 0.11 0.19    0.09       0.31   0.30   0.82997"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bestrows <- as.character(dat03$row)\n",
    "acc <- dat03[, c(\"Acc\")]\n",
    "dat03_b <- cbind(dfc03[bestrows, ], acc)\n",
    "dat03_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMMENT:\n",
    "\n",
    "# As the number of seeds increases, the average\n",
    "# accuracy score decreases toward the 0.8295 \n",
    "# number we are trying to beat. The 0.8295 number\n",
    "# is from the hybrid model without weights.  It \n",
    "# may be that the scaling I am applying, in combination\n",
    "# with looking at many thousands of folds of the \n",
    "# data (for a data set that is only 178 records),\n",
    "# lessens the importance of weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get comparative cross-val score using the new weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for obtaining average of confusion matrix \n",
    "# accuracy score. This function is called from compute_cvScore_km.\n",
    "\n",
    "# This is the same function as above; only the weights have changed.\n",
    "\n",
    "# We need to take the square root of the weights.\n",
    "wghts <- c(0.11, 0.18, 0.12, 0.31, 0.28)^0.5\n",
    "names(wghts) <- c(colnames(train)[-1], \"prob01\",\"prob02\")\n",
    "\n",
    "get_cvScore_wghts <- function(traindat, valdat) {\n",
    "    \n",
    "    # Scale traindat for purpose of an svm model.\n",
    "    svm_scaled <- scale(traindat[, -1])\n",
    "    svm_centers <- attr(svm_scaled, \"scaled:center\")\n",
    "    svm_scales <- attr(svm_scaled, \"scaled:scale\")\n",
    "    svm_scaled <- as.data.frame(cbind(traindat$Type, svm_scaled),\n",
    "                                row.names=rownames(traindat))\n",
    "    colnames(svm_scaled) <- colnames(traindat)\n",
    "    \n",
    "    # This is our current best svm model for the trainset data\n",
    "    svmod <- svm(I(as.factor(Type)) ~ ., data=svm_scaled, kernel=\"radial\",\n",
    "                 gamma= 0.03, cost= 25, scale=FALSE, probability=TRUE)\n",
    "    \n",
    "    preds <- predict(svmod, newdata=svm_scaled, scale=FALSE, probability=TRUE)\n",
    "    traindat$prob01 <- as.numeric(attr(preds, \"probabilities\")[, 2])\n",
    "    traindat$prob02 <- as.numeric(attr(preds, \"probabilities\")[, 3])\n",
    "    \n",
    "    #############################\n",
    "    # Scale training set data for the k-means model.\n",
    "    \n",
    "    df <- scale(traindat[, -1], center=TRUE, scale=TRUE)\n",
    "    centers <- attr(df, \"scaled:center\")\n",
    "    scales <- attr(df, \"scaled:scale\")\n",
    "    df <- as.matrix(df)\n",
    "    traindat_scaled <- apply(df, MARGIN=2, range01)\n",
    "    colnames(traindat_scaled) <- colnames(traindat)[-1]\n",
    "    rownames(traindat_scaled) <- rownames(traindat)\n",
    "    \n",
    "    # Get mins and maxs for scaling of valdat.\n",
    "    traindat_mins <- as.numeric(apply(df, MARGIN=2, min))\n",
    "    traindat_maxs <- as.numeric(apply(df, MARGIN=2, max))\n",
    "    \n",
    "    #############################\n",
    "    # Apply weights to traindat.\n",
    "    cols <- names(wghts)\n",
    "    df2 <- t(t(traindat_scaled[, cols]) * as.numeric(wghts[cols]))\n",
    "    traindat_wghts <- as.data.frame(df2, row.names=rownames(traindat))\n",
    "    \n",
    "    \n",
    "    #############################################\n",
    "    # Prepare valdat.\n",
    "    #############################################\n",
    "    \n",
    "    svmval_scaled <- scale(valdat[, -1], center=svm_centers, scale=svm_scales)\n",
    "    svmval_scaled <- as.data.frame(svmval_scaled, row.names=rownames(valdat))\n",
    "    \n",
    "    # Compute prob01 and prob02 columns.\n",
    "    preds01_b <- predict(svmod, newdata=svmval_scaled, scale=FALSE, probability=TRUE)\n",
    "    valdat$prob01 <- as.numeric(attr(preds01_b, \"probabilities\")[, 2])\n",
    "    valdat$prob02 <- as.numeric(attr(preds01_b, \"probabilities\")[, 3])\n",
    "\n",
    "    # Scale valdat.\n",
    "    df02 <- scale(valdat[, -1], center=centers, scale=scales)\n",
    "    df02_t <- t(as.matrix(df02))\n",
    "    df02_asList <- split(df02_t, seq(nrow(df02_t)))\n",
    "    names(df02_asList) <- colnames(valdat)[-1]\n",
    "\n",
    "    valdat_scaled <- mapply(range02, df02_asList, traindat_mins, \n",
    "                            traindat_maxs)\n",
    "    # The next step is crucial.\n",
    "    valdat_scaled <- as.data.frame(valdat_scaled, row.names=rownames(valdat))\n",
    "    colnames(valdat_scaled) <- colnames(valdat)[-1]\n",
    "    \n",
    "    # Apply weights to valdat_scaled.\n",
    "    df4 <- t(t(valdat_scaled[, cols]) * as.numeric(wghts[cols]))\n",
    "    valdat_wghts <- as.data.frame(df4, row.names=rownames(valdat))\n",
    "    colnames(valdat_wghts) <- colnames(valdat)[-1]\n",
    "    \n",
    "    \n",
    "    #############################################\n",
    "    # Construct k-means model.\n",
    "\n",
    "    kmod <- kmeans(traindat_wghts, 3, iter.max = 50, nstart=30)\n",
    "    \n",
    "    # See how the clusters are associated with Type level.\n",
    "    dfout <- as.data.frame(cbind(traindat$Type, kmod$cluster), \n",
    "                           row.names=rownames(traindat))\n",
    "    colnames(dfout) <- c(\"Type\", \"cluster\")\n",
    "    mapping <- get_mapping(dfout)\n",
    "    \n",
    "    \n",
    "    #############################\n",
    "    # Apply the k-means model to valdat_wghts.\n",
    "    \n",
    "    # Each element of the following list is a row of valdat_wghts.\n",
    "    valdat_asList <- split(valdat_wghts[, colnames(kmod$centers)],\n",
    "                           seq(nrow(valdat_wghts)))\n",
    "    \n",
    "    ctr_list <- vector(\"list\", length= nrow(valdat))\n",
    "    for(i in 1:nrow(valdat)) {\n",
    "        \n",
    "        ctr_list[[i]] <- kmod$centers\n",
    "    }\n",
    "    names(ctr_list) <- rownames(valdat)\n",
    "    \n",
    "    \n",
    "    # Get the predictions for the validation set.\n",
    "    cluster_assgns <- mcmapply(getCluster, valdat_asList, ctr_list,\n",
    "                               SIMPLIFY=TRUE, USE.NAMES= FALSE, mc.cores=6)\n",
    "    \n",
    "    valdat_wghts$cluster <- as.numeric(cluster_assgns)\n",
    "    \n",
    "    valdat_wghts$pred_Type <- NA\n",
    "    \n",
    "    # Apply mapping to the assigned clusters.  Since valdat is \n",
    "    # quite small (around 35 records if folds = 5), and there \n",
    "    # are 3 clusters, it is possible that one of the LHS expressions\n",
    "    # below is NA.  I will make the changes if the program fails. \n",
    "    valdat_wghts[which(valdat_wghts$cluster==1), c(\"pred_Type\")] <- as.numeric(mapping[\"1\"])\n",
    "    valdat_wghts[which(valdat_wghts$cluster==2), c(\"pred_Type\")] <- as.numeric(mapping[\"2\"])\n",
    "    valdat_wghts[which(valdat_wghts$cluster==3), c(\"pred_Type\")] <- as.numeric(mapping[\"3\"])\n",
    "    \n",
    "    # Generate confusion matrix for the k-means clusters and\n",
    "    # the corresponding f-score.\n",
    "    preds <- as.factor(valdat_wghts$pred_Type)\n",
    "    names(preds) <- rownames(valdat)\n",
    "    ans <- get_confusion(preds, valdat[, \"Type\", drop=FALSE])\n",
    "    return(ans[[2]])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-06-01 12:06:31'"
      ],
      "text/latex": [
       "'Start time: 2021-06-01 12:06:31'"
      ],
      "text/markdown": [
       "'Start time: 2021-06-01 12:06:31'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-06-01 12:06:31\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 7.59 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the correct seed, i.e., the seed we have been\n",
    "# using for this comparative score.\n",
    "\n",
    "set.seed(1931)\n",
    "seed_vector <- sample(1:9999, 2000, replace=FALSE)\n",
    "\n",
    "start <- Sys.time()\n",
    "paste(\"Start time: \", start, sep=\"\")\n",
    "dat_result <- compute_cvScore_km(seed_vector, train) \n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 7.59 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "  0.776   0.821   0.831   0.829   0.837   0.866 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(dat_result$Acc)\n",
    "\n",
    "# The interquartile range is 1.6 percentage points.\n",
    "# For svm02 this range was 1.7 points.\n",
    "# Both distributions have the same maximum value, to\n",
    "# 3 significant digits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.8293"
      ],
      "text/latex": [
       "0.8293"
      ],
      "text/markdown": [
       "0.8293"
      ],
      "text/plain": [
       "[1] 0.8293"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(mean(dat_result$Acc), 4)\n",
    "\n",
    "# Accuracy over 2000 seeds is 0.8293.  Without weights,\n",
    "# this score was 0.8295.  svm02 had an average\n",
    "# cross-val accuracy score of 0.8278.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.8311"
      ],
      "text/latex": [
       "0.8311"
      ],
      "text/markdown": [
       "0.8311"
      ],
      "text/plain": [
       "[1] 0.8311"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.012282"
      ],
      "text/latex": [
       "0.012282"
      ],
      "text/markdown": [
       "0.012282"
      ],
      "text/plain": [
       "[1] 0.012282"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(median(dat_result$Acc), 4)\n",
    "round(sd(dat_result$Acc), 6)\n",
    "# median: 0.8311\n",
    "# sd: 0.012282\n",
    "\n",
    "# The median accuracy score for svm02 was 0.8271.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAMAAAC323mdAAAC/VBMVEUAAAABAQECAgIDAwME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\nmgJcfcdIV78AAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title “Distribution of cross-val accuracy scores for hybrid k-means model with weights”"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width= 10, repr.plot.height= 6)\n",
    "hist(dat_result$Acc, breaks=16, xlab=\"accuracy\",\n",
    "     main=\"Distribution of cross-val accuracy scores for hybrid k-means model with weights\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4 Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While I have not done an exhaustive search for weights, current results are showing that weights are not helping to improve the accuracy score when this score is measured over a very large number of seeds, or folds.  In this case, each of the folds is only 35 or 36 records (20% of the data).  We saw the same result, but with a different set of weights, in Section 3---the result being that using weights did not improve upon the original model.  Different weights give us different average accuracy scores on validation data, but these differences disappear as we increase the number of sets of validation data to a very large number---in this case, 2000 times 5, or 10,000 folds (sets).\n",
    "\n",
    "Although I did not foresee it, this asymptotic-like behavior makes sense.  I was looking for a stable answer regarding best model, overlooking a different kind of consequence of the fact that a model's performance varies no small amount depending on the data that the model is applied to.  If we present each model with enough data, the average performances might not be all that different, especially if---as was the case here--- the type of model is the same in all cases; I was only changing the weights.\n",
    "\n",
    "Nonetheless, the primary reason for this lack of difference, I suspect, is the scaling I am applying to the data: centering each of the variables, scaling so that each variable has unit variance, and then mapping all values into the range, \\[0, 1\\].\n",
    "\n",
    "The alternative method of finding weights, looking for a minimum in tot.withinss (total within group sum of squares), does seem to work, although I am not yet fully convinced.  While the weights I found using this method performed no worse than the weights I found using cross-validation with accuracy scores, we have found that we might be able to say this about any of the sets of weights tested.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: Get scores for k-means models, absent min-max scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Hue           Phenols       Alcalinity  \n",
       " Min.   :0.480   Min.   :0.98   Min.   :10.6  \n",
       " 1st Qu.:0.782   1st Qu.:1.74   1st Qu.:17.2  \n",
       " Median :0.965   Median :2.35   Median :19.5  \n",
       " Mean   :0.957   Mean   :2.30   Mean   :19.5  \n",
       " 3rd Qu.:1.120   3rd Qu.:2.80   3rd Qu.:21.5  \n",
       " Max.   :1.710   Max.   :3.88   Max.   :30.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(train[, -1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Hue           Phenols       Alcalinity  \n",
       " Min.   :0.480   Min.   :0.99   Min.   :1.53  \n",
       " 1st Qu.:0.782   1st Qu.:1.32   1st Qu.:1.67  \n",
       " Median :0.965   Median :1.53   Median :1.71  \n",
       " Mean   :0.957   Mean   :1.50   Mean   :1.70  \n",
       " 3rd Qu.:1.120   3rd Qu.:1.67   3rd Qu.:1.74  \n",
       " Max.   :1.710   Max.   :1.97   Max.   :1.84  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Before scaling, transform the data a bit so \n",
    "# the variable ranges are more alike in terms\n",
    "# of range.\n",
    "\n",
    "df <- train\n",
    "df$Phenols <- (df$Phenols)^0.5\n",
    "df$Alcalinity <- (df$Alcalinity)^0.18\n",
    "summary(df[, -1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Hue            Phenols         Alcalinity     \n",
       " Min.   :-2.089   Min.   :-2.429   Min.   :-3.2418  \n",
       " 1st Qu.:-0.765   1st Qu.:-0.858   1st Qu.:-0.6406  \n",
       " Median : 0.033   Median : 0.163   Median : 0.0717  \n",
       " Mean   : 0.000   Mean   : 0.000   Mean   : 0.0000  \n",
       " 3rd Qu.: 0.711   3rd Qu.: 0.823   3rd Qu.: 0.6370  \n",
       " Max.   : 3.292   Max.   : 2.233   Max.   : 2.6425  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_scaled <- scale(df[, -1], center=TRUE, scale=TRUE)\n",
    "df_scaled <- as.data.frame(cbind(df$Type, df_scaled),\n",
    "                           row.names=rownames(df))\n",
    "colnames(df_scaled) <- colnames(df)\n",
    "summary(df_scaled[, -1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 73 59 46\n"
     ]
    }
   ],
   "source": [
    "# Run k-means with number of clusters set to 3.\n",
    "\n",
    "set.seed(1233)\n",
    "fit_km <- kmeans(df_scaled[, -1], 3, iter.max = 50, nstart = 30)\n",
    "print(fit_km$size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Type</th><th scope=col>cluster</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>113</th><td>2</td><td>3</td></tr>\n",
       "\t<tr><th scope=row>159</th><td>3</td><td>3</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>1</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>131</th><td>3</td><td>2</td></tr>\n",
       "\t<tr><th scope=row>137</th><td>3</td><td>2</td></tr>\n",
       "\t<tr><th scope=row>133</th><td>3</td><td>2</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & Type & cluster\\\\\n",
       "  & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t113 & 2 & 3\\\\\n",
       "\t159 & 3 & 3\\\\\n",
       "\t21 & 1 & 1\\\\\n",
       "\t131 & 3 & 2\\\\\n",
       "\t137 & 3 & 2\\\\\n",
       "\t133 & 3 & 2\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | Type &lt;dbl&gt; | cluster &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 113 | 2 | 3 |\n",
       "| 159 | 3 | 3 |\n",
       "| 21 | 1 | 1 |\n",
       "| 131 | 3 | 2 |\n",
       "| 137 | 3 | 2 |\n",
       "| 133 | 3 | 2 |\n",
       "\n"
      ],
      "text/plain": [
       "    Type cluster\n",
       "113 2    3      \n",
       "159 3    3      \n",
       "21  1    1      \n",
       "131 3    2      \n",
       "137 3    2      \n",
       "133 3    2      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datout <- as.data.frame(cbind(df_scaled$Type, fit_km$cluster))\n",
    "colnames(datout) <- c(\"Type\", \"cluster\")\n",
    "rownames(datout) <- rownames(df_scaled)\n",
    "head(datout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "     1  2  3\n",
       "  1 49  0 10\n",
       "  2 24 14 33\n",
       "  3  0 45  3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We need to map cluster to Type level.\n",
    "\n",
    "table(datout$Type, as.factor(datout$cluster))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 \n",
      "1 3 2 \n"
     ]
    }
   ],
   "source": [
    "ans <- as.matrix(table(datout$Type, as.factor(datout$cluster)))\n",
    "print(apply(ans, MARGIN=2, which.max))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mapping resulting from fit_km above.\n",
    "\n",
    "tmpdat <- datout\n",
    "tmpdat[which(tmpdat$cluster== 1),]$Type <- 1\n",
    "tmpdat[which(tmpdat$cluster== 2),]$Type <- 3\n",
    "tmpdat[which(tmpdat$cluster== 3),]$Type <- 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1  2  3 class.error\n",
      "1 49 10  0      0.1695\n",
      "2 24 33 14      0.5352\n",
      "3  0  3 45      0.0625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "''"
      ],
      "text/latex": [
       "''"
      ],
      "text/markdown": [
       "''"
      ],
      "text/plain": [
       "[1] \"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy score for the base k-means model: 0.7135\"\n"
     ]
    }
   ],
   "source": [
    "# Generate confusion matrix for the k-means clusters.\n",
    "# Output accuracy for this confusion matrix.\n",
    "\n",
    "preds <- as.factor(tmpdat$Type)\n",
    "names(preds) <- rownames(tmpdat)\n",
    "ans <- get_confusion(preds, df_scaled[, \"Type\", drop=FALSE])\n",
    "print(ans$matrix)\n",
    "''\n",
    "print(paste(\"Accuracy score for the base k-means model: \", as.character(ans[[2]]), sep=\"\"))\n",
    "# Section 2 base k-means accuracy score on training set: 0.7135\n",
    "\n",
    "# current accuracy score: 0.7135\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get comparative cross-val score for this new base k-means model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for obtaining average of confusion matrix \n",
    "# accuracy score. This function is called from compute_cvScore_km.\n",
    "\n",
    "get_cvScore_km02 <- function(traindat, valdat) {\n",
    "    \n",
    "    # Scale training set data.  traindat and valdat \n",
    "    # columns have already been transformed in the \n",
    "    # calling function.\n",
    "    df <- scale(traindat[, -1], center=TRUE, scale=TRUE)\n",
    "    centers <- attr(df, \"scaled:center\")\n",
    "    scales <- attr(df, \"scaled:scale\")\n",
    "    # df is a matrix, not a dataframe; this means we \n",
    "    # cannot refer to its columns using $\n",
    "\n",
    "    \n",
    "    ############################\n",
    "    # Transform and scale valdat.\n",
    "    df02 <- scale(valdat[, -1], center=centers, scale=scales)\n",
    "    \n",
    "    # The next step is crucial.\n",
    "    valdat_scaled <- as.data.frame(df02, row.names=rownames(valdat))\n",
    "    colnames(valdat_scaled) <- colnames(valdat)[-1]\n",
    "    \n",
    "    \n",
    "    #########################\n",
    "    # Construct k-means model.\n",
    "\n",
    "    kmod <- kmeans(df, 3, iter.max = 50, nstart=30)\n",
    "    \n",
    "    # See how the clusters are associated with Type level.\n",
    "    dfout <- as.data.frame(cbind(traindat$Type, kmod$cluster))\n",
    "    colnames(dfout) <- c(\"Type\", \"cluster\")\n",
    "    rownames(dfout) <- rownames(traindat)\n",
    "    mapping <- get_mapping(dfout)\n",
    "    \n",
    "    #############################\n",
    "    # Apply the k-means model to valdat_scaled.\n",
    "    \n",
    "    # Each element of the following list is a row of valdat_wghts.\n",
    "    valdat_asList <- split(valdat_scaled[, colnames(kmod$centers)],\n",
    "                           seq(nrow(valdat_scaled)))\n",
    "    \n",
    "    ctr_list <- vector(\"list\", length= nrow(valdat))\n",
    "    for(i in 1:nrow(valdat)) {\n",
    "        \n",
    "        ctr_list[[i]] <- kmod$centers\n",
    "    }\n",
    "    names(ctr_list) <- rownames(valdat)\n",
    "    \n",
    "    \n",
    "    # Get the predictions for the validation set.\n",
    "    cluster_assgns <- mcmapply(getCluster, valdat_asList, ctr_list,\n",
    "                               SIMPLIFY=TRUE, USE.NAMES= FALSE, mc.cores=6)\n",
    "    \n",
    "    valdat_scaled$cluster <- as.numeric(cluster_assgns)\n",
    "    \n",
    "    valdat_scaled$pred_Type <- NA\n",
    "    \n",
    "    # Apply mapping to the assigned clusters.  Since valdat is \n",
    "    # quite small (around 35 records if folds = 5), and there \n",
    "    # are 3 clusters, it is possible that one of the LHS expressions\n",
    "    # below is NA.  I will make the changes if the program fails. \n",
    "    valdat_scaled[which(valdat_scaled$cluster==1), c(\"pred_Type\")] <- as.numeric(mapping[\"1\"])\n",
    "    valdat_scaled[which(valdat_scaled$cluster==2), c(\"pred_Type\")] <- as.numeric(mapping[\"2\"])\n",
    "    valdat_scaled[which(valdat_scaled$cluster==3), c(\"pred_Type\")] <- as.numeric(mapping[\"3\"])\n",
    "    \n",
    "    # Generate confusion matrix for the k-means clusters and\n",
    "    # the corresponding f-score.\n",
    "    preds <- as.factor(valdat_scaled$pred_Type)\n",
    "    names(preds) <- rownames(valdat)\n",
    "    ans <- get_confusion(preds, valdat[, \"Type\", drop=FALSE])\n",
    "    return(ans[[2]])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-06-02 10:15:20'"
      ],
      "text/latex": [
       "'Start time: 2021-06-02 10:15:20'"
      ],
      "text/markdown": [
       "'Start time: 2021-06-02 10:15:20'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-06-02 10:15:20\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 5.26 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Again, use the same initial seed that we have \n",
    "# been using for this score.\n",
    "\n",
    "set.seed(1931)\n",
    "seed_vector <- sample(1:9999, 2000, replace=FALSE)\n",
    "\n",
    "\n",
    "# Use df instead of train since df has the variable \n",
    "# transformations.\n",
    "\n",
    "start <- Sys.time()\n",
    "paste(\"Start time: \", start, sep=\"\")\n",
    "ans <- compute_cvScore_km(seed_vector, df)\n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 5.26 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "  0.642   0.692   0.708   0.706   0.719   0.765 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(ans$Acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.7057"
      ],
      "text/latex": [
       "0.7057"
      ],
      "text/markdown": [
       "0.7057"
      ],
      "text/plain": [
       "[1] 0.7057"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(mean(ans$Acc), 4)\n",
    "# 0.7057\n",
    "\n",
    "# In Section 2 above, using the min-max scaling, our\n",
    "# score was 0.7095\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.7075"
      ],
      "text/latex": [
       "0.7075"
      ],
      "text/markdown": [
       "0.7075"
      ],
      "text/plain": [
       "[1] 0.7075"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.018619"
      ],
      "text/latex": [
       "0.018619"
      ],
      "text/markdown": [
       "0.018619"
      ],
      "text/plain": [
       "[1] 0.018619"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(median(ans$Acc), 4)\n",
    "round(sd(ans$Acc), 6)\n",
    "# median: 0.7075\n",
    "# sd: 0.018619\n",
    "\n",
    "\n",
    "# Section 2 median: 0.7085\n",
    "# Section 2 sd: 0.024145\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAMAAAC323mdAAAC+lBMVEUAAAABAQECAgIDAwME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\n37FLnFJfAAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title “Distribution of cross-val accuracy scores for base k-means model”"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width= 10, repr.plot.height= 6)\n",
    "hist(ans$Acc, breaks=16, xlab=\"accuracy\",\n",
    "     main=\"Distribution of cross-val accuracy scores for base k-means model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMMENTS:\n",
    "\n",
    "# The scores are somewhat better when we use the min-max\n",
    "# scaling on top of the regular scaling.  Here I applied\n",
    "# some transformations to the variables and then applied\n",
    "# regular scaling.  When I did this in Part 2, I then\n",
    "# found weights and those weights made a real difference\n",
    "# in the score.  So it is worth looking into whether \n",
    "# weights make a difference in this case, too.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get comparative cross-val score for the corresponding hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for obtaining average of confusion matrix accuracy\n",
    "# score. This function is called from compute_cvScore_km.\n",
    "\n",
    "get_cvScore_hybrid02 <- function(traindat, valdat) {\n",
    "    \n",
    "    # Scale traindat for purpose of an svm model.\n",
    "    svm_scaled <- scale(traindat[, -1])\n",
    "    svm_centers <- attr(svm_scaled, \"scaled:center\")\n",
    "    svm_scales <- attr(svm_scaled, \"scaled:scale\")\n",
    "    svm_scaled <- as.data.frame(cbind(traindat$Type, svm_scaled),\n",
    "                                row.names=rownames(traindat))\n",
    "    colnames(svm_scaled) <- colnames(traindat)\n",
    "    \n",
    "    # This is our current best svm model for the trainset data\n",
    "    svmod <- svm(I(as.factor(Type)) ~ ., data=svm_scaled, kernel=\"radial\",\n",
    "                 gamma= 0.03, cost= 25, scale=FALSE, probability=TRUE)\n",
    "    \n",
    "    \n",
    "    preds <- predict(svmod, newdata=svm_scaled, scale=FALSE, probability=TRUE)\n",
    "    traindat$prob01 <- as.numeric(attr(preds, \"probabilities\")[, 2])\n",
    "    traindat$prob02 <- as.numeric(attr(preds, \"probabilities\")[, 3])\n",
    "    \n",
    "    # Apply transformations to Phenols and Alcalinity\n",
    "    traindat$Phenols <- (traindat$Phenols)^0.5\n",
    "    traindat$Alcalinity <- (traindat$Alcalinity)^0.18\n",
    "    \n",
    "    #############################\n",
    "    # Scale training set data for the k-means model.\n",
    "    \n",
    "    traindat_scaled <- scale(traindat[, -1], center=TRUE, scale=TRUE)\n",
    "    centers <- attr(traindat_scaled, \"scaled:center\")\n",
    "    scales <- attr(traindat_scaled, \"scaled:scale\")\n",
    "    rownames(traindat_scaled) <- rownames(traindat)\n",
    "    \n",
    "    \n",
    "    ############################\n",
    "    # Prepare valdat for svm modeling.\n",
    "    \n",
    "    svmval_scaled <- scale(valdat[, -1], center=svm_centers, scale=svm_scales)\n",
    "    svmval_scaled <- as.data.frame(svmval_scaled, row.names=rownames(valdat))\n",
    "    \n",
    "    # Compute prob01 and prob02 columns.\n",
    "    preds01_b <- predict(svmod, newdata=svmval_scaled, scale=FALSE, probability=TRUE)\n",
    "    valdat$prob01 <- as.numeric(attr(preds01_b, \"probabilities\")[, 2])\n",
    "    valdat$prob02 <- as.numeric(attr(preds01_b, \"probabilities\")[, 3])\n",
    "    \n",
    "    # Apply transformations to Phenols and Alcalinity\n",
    "    valdat$Phenols <- (valdat$Phenols)^0.5\n",
    "    valdat$Alcalinity <- (valdat$Alcalinity)^0.18\n",
    "\n",
    "    # Scale valdat.\n",
    "    valdat_scaled <- scale(valdat[, -1], center=centers, scale=scales)\n",
    "    \n",
    "    # The next step is crucial.\n",
    "    valdat_scaled <- as.data.frame(valdat_scaled, row.names=rownames(valdat))\n",
    "    \n",
    "    \n",
    "    #############################\n",
    "    # Construct k-means model.\n",
    "\n",
    "    kmod <- kmeans(traindat_scaled, 3, iter.max = 50, nstart=30)\n",
    "    \n",
    "    # See how the clusters are associated with Type level.\n",
    "    dfout <- as.data.frame(cbind(traindat$Type, kmod$cluster))\n",
    "    colnames(dfout) <- c(\"Type\", \"cluster\")\n",
    "    rownames(dfout) <- rownames(traindat)\n",
    "    mapping <- get_mapping(dfout)\n",
    "    \n",
    "    #############################\n",
    "    # Apply the k-means model to valdat_scaled.\n",
    "    \n",
    "    # Each element of the following list is a row of valdat_scaled.\n",
    "    valdat_asList <- split(valdat_scaled[, colnames(kmod$centers)],\n",
    "                           seq(nrow(valdat_scaled)))\n",
    "    \n",
    "    ctr_list <- vector(\"list\", length= nrow(valdat))\n",
    "    for(i in 1:nrow(valdat)) {\n",
    "        \n",
    "        ctr_list[[i]] <- kmod$centers\n",
    "    }\n",
    "    names(ctr_list) <- rownames(valdat)\n",
    "    \n",
    "    \n",
    "    # Get the predictions for the validation set.\n",
    "    cluster_assgns <- mcmapply(getCluster, valdat_asList, ctr_list,\n",
    "                               SIMPLIFY=TRUE, USE.NAMES= FALSE, mc.cores=6)\n",
    "    \n",
    "    valdat_scaled$cluster <- as.numeric(cluster_assgns)\n",
    "    \n",
    "    valdat_scaled$pred_Type <- NA\n",
    "    \n",
    "    # Apply mapping to the assigned clusters.  Since valdat is \n",
    "    # quite small (around 35 records if folds = 5), and there \n",
    "    # are 3 clusters, it is possible that one of the LHS expressions\n",
    "    # below is NA.  I will make the changes if the program fails. \n",
    "    valdat_scaled[which(valdat_scaled$cluster==1), c(\"pred_Type\")] <- as.numeric(mapping[\"1\"])\n",
    "    valdat_scaled[which(valdat_scaled$cluster==2), c(\"pred_Type\")] <- as.numeric(mapping[\"2\"])\n",
    "    valdat_scaled[which(valdat_scaled$cluster==3), c(\"pred_Type\")] <- as.numeric(mapping[\"3\"])\n",
    "    \n",
    "    # Generate confusion matrix for the k-means clusters and\n",
    "    # the corresponding f-score.\n",
    "    preds <- as.factor(valdat_scaled$pred_Type)\n",
    "    names(preds) <- rownames(valdat)\n",
    "    ans <- get_confusion(preds, valdat[, \"Type\", drop=FALSE])\n",
    "    return(ans[[2]])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-06-02 10:43:32'"
      ],
      "text/latex": [
       "'Start time: 2021-06-02 10:43:32'"
      ],
      "text/markdown": [
       "'Start time: 2021-06-02 10:43:32'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-06-02 10:43:32\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 7.13 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the same initial seed as we have been using for\n",
    "# this score.\n",
    "\n",
    "set.seed(1931)\n",
    "seed_vector <- sample(1:9999, 2000, replace=FALSE)\n",
    "\n",
    "# Here we need to use train instead of df because\n",
    "# svm02 is using un-transformed columns.\n",
    "\n",
    "start <- Sys.time()\n",
    "paste(\"Start time: \", start, sep=\"\")\n",
    "ans <- compute_cvScore_km(seed_vector, train)\n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 7.13 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "  0.775   0.815   0.821   0.822   0.831   0.865 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(ans$Acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.8219"
      ],
      "text/latex": [
       "0.8219"
      ],
      "text/markdown": [
       "0.8219"
      ],
      "text/plain": [
       "[1] 0.8219"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(mean(ans$Acc), 4)\n",
    "# 0.8219\n",
    "\n",
    "# Section 2 score: 0.8295\n",
    "\n",
    "# For svm02, this score was 0.8278.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.8209"
      ],
      "text/latex": [
       "0.8209"
      ],
      "text/markdown": [
       "0.8209"
      ],
      "text/plain": [
       "[1] 0.8209"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.011109"
      ],
      "text/latex": [
       "0.011109"
      ],
      "text/markdown": [
       "0.011109"
      ],
      "text/plain": [
       "[1] 0.011109"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(median(ans$Acc), 4)\n",
    "round(sd(ans$Acc), 6)\n",
    "# 0.8209\n",
    "# 0.011109\n",
    "\n",
    "# Section 2 median: 0.8314\n",
    "# Section 2 sd: 0.012021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAMAAAC323mdAAADAFBMVEUAAAABAQECAgIDAwME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\nhRuqxAAAAABJRU5ErkJggg==",
      "text/plain": [
       "Plot with title “Distribution of cross-val accuracy scores for hybrid k-means model”"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width= 10, repr.plot.height= 6)\n",
    "hist(ans$Acc, breaks=14, xlab=\"accuracy\",\n",
    "     main=\"Distribution of cross-val accuracy scores for hybrid k-means model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMMENTS:\n",
    "\n",
    "# Not only is the min-max scaling taking a bit less time, \n",
    "# we are also seeing an important (statistically significant) \n",
    "# difference in the scores.  Because I do not think that applying\n",
    "# weights to this model will get us the boost we need to beat\n",
    "# the 0.8295 score, I am not going to search for weights.  In\n",
    "# Part 2 with the cow data, when weights were applied to the \n",
    "# base k-means model, the gain was only 0.007 (i.e., less than \n",
    "# 1 percentage point).  Here in Part 4 the bar is much higher and,\n",
    "# thus, we are not likely to see a gain even of 0.007 with the \n",
    "# best weights that we find.  (The bar is much higher because we\n",
    "# have less than half the records to work with and the accuracy\n",
    "# score we are trying to beat is 11 percentage points higher.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get comparative cross-val score for a hybrid model employing pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point of employing pca is to reduce the dimensions of train in order to make it easier to find weights.  But in what follows, I see reason to apply min-max scaling in the process, absent any weights.  This means, in turn, that weights are unlikely to improve upon the following average cross-val accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformations.\n",
    "\n",
    "df <- train\n",
    "df$Phenols <- (df$Phenols)^0.5\n",
    "df$Alcalinity <- (df$Alcalinity)^0.18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Importance of first k=2 (out of 3) components:\n",
       "                         PC1   PC2\n",
       "Standard deviation     1.311 0.858\n",
       "Proportion of Variance 0.573 0.245\n",
       "Cumulative Proportion  0.573 0.818"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The R help for prcomp points out that we ought to set\n",
    "# scale.=TRUE.  If I do not scale, PC1 and PC2 together\n",
    "# capture around 99% of the variance.  But it is highly\n",
    "# unlikely we would see such performance on new data.\n",
    "# Scaling should give us a model that performs better on\n",
    "# new data.\n",
    "\n",
    "pca2 <- prcomp(df[, -1], retx=TRUE, rank.=2, center=TRUE,\n",
    "               scale.=TRUE)\n",
    "summary(pca2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      pc1               pc2          \n",
       " Min.   :-0.6176   Min.   :-0.43125  \n",
       " 1st Qu.:-0.1952   1st Qu.:-0.10162  \n",
       " Median :-0.0593   Median : 0.00229  \n",
       " Mean   : 0.0000   Mean   : 0.00000  \n",
       " 3rd Qu.: 0.2143   3rd Qu.: 0.09219  \n",
       " Max.   : 0.6158   Max.   : 0.41777  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kmpca <- as.data.frame(pca2$x)\n",
    "colnames(kmpca) <- paste0(\"pc\", 1:2)\n",
    "rownames(kmpca) <- rownames(df)\n",
    "summary(kmpca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It makes sense to move the data into the range, [0,1],\n",
    "# because that is where the data for prob01 and prob02 lie.\n",
    "\n",
    "kmpca_scaled <- apply(kmpca, MARGIN=2, range01)\n",
    "summary(kmpca_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Importance of first k=2 (out of 3) components:\n",
       "                         PC1   PC2\n",
       "Standard deviation     1.300 0.865\n",
       "Proportion of Variance 0.563 0.249\n",
       "Cumulative Proportion  0.563 0.813"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See if pca works better with no transformations on \n",
    "# the variables.\n",
    "\n",
    "pca2_b <- prcomp(train[, -1], retx=TRUE, rank.=2, center=TRUE,\n",
    "                 scale.=TRUE)\n",
    "summary(pca2_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for obtaining average of confusion matrix accuracy\n",
    "# score. This function is called from compute_cvScore_km.\n",
    "\n",
    "get_cvScore_hybrid_pca <- function(traindat, valdat) {\n",
    "    \n",
    "    # Scale traindat for purpose of an svm model.\n",
    "    svm_scaled <- scale(traindat[, -1])\n",
    "    svm_centers <- attr(svm_scaled, \"scaled:center\")\n",
    "    svm_scales <- attr(svm_scaled, \"scaled:scale\")\n",
    "    svm_scaled <- as.data.frame(cbind(traindat$Type, svm_scaled),\n",
    "                                row.names=rownames(traindat))\n",
    "    colnames(svm_scaled) <- colnames(traindat)\n",
    "    \n",
    "    # This is our current best svm model for the trainset data\n",
    "    svmod <- svm(I(as.factor(Type)) ~ ., data=svm_scaled, kernel=\"radial\",\n",
    "                 gamma= 0.03, cost= 25, scale=FALSE, probability=TRUE)\n",
    "    \n",
    "    preds <- predict(svmod, newdata=svm_scaled, scale=FALSE, probability=TRUE)\n",
    "    \n",
    "    prob01 <- as.numeric(attr(preds, \"probabilities\")[, 2])\n",
    "    prob02 <- as.numeric(attr(preds, \"probabilities\")[, 3])\n",
    "    \n",
    "    # Scale the probability columns.\n",
    "    prob01_scaled <- scale(prob01, center=TRUE, scale=TRUE)\n",
    "    prob01_center <- attr(prob01_scaled, \"scaled:center\")\n",
    "    prob01_scale <- attr(prob01_scaled, \"scaled:scale\")\n",
    "    \n",
    "    prob02_scaled <- scale(prob02, center=TRUE, scale=TRUE)\n",
    "    prob02_center <- attr(prob02_scaled, \"scaled:center\")\n",
    "    prob02_scale <- attr(prob02_scaled, \"scaled:scale\")\n",
    "    \n",
    "    #############################\n",
    "    \n",
    "    # Transform columns of traindat.\n",
    "    traindat$Phenols <- (traindat$Phenols)^0.5\n",
    "    traindat$Alcalinity <- (traindat$Alcalinity)^0.18\n",
    "    \n",
    "    # Apply pca to traindat.\n",
    "    pca <- prcomp(traindat[, -1], retx=TRUE, rank.=2, center=TRUE,\n",
    "                  scale.=TRUE)\n",
    "    dftmp <- as.data.frame(pca$x, row.names=rownames(traindat))\n",
    "    \n",
    "    # Add in the probability columns.\n",
    "    dftmp$prob01 <- prob01_scaled\n",
    "    dftmp$prob02 <- prob02_scaled\n",
    "    \n",
    "    # Apply min-max scaling.\n",
    "    dftmp_scaled <- apply(as.matrix(dftmp), MARGIN=2, range01)\n",
    "    \n",
    "    traindat_scaled <- as.data.frame(dftmp_scaled, row.names=rownames(traindat))\n",
    "    colnames(traindat_scaled) <- c(paste0(\"pc\", 1:2),\"prob01\",\"prob02\")\n",
    "    \n",
    "    # Get mins and maxs for scaling of valdat.\n",
    "    traindat_mins <- as.numeric(apply(as.matrix(dftmp), MARGIN=2, min))\n",
    "    traindat_maxs <- as.numeric(apply(as.matrix(dftmp), MARGIN=2, max))\n",
    "    \n",
    "    \n",
    "    ############################\n",
    "    # Prepare valdat for svm modeling.\n",
    "    \n",
    "    svmval_scaled <- scale(valdat[, -1], center=svm_centers, scale=svm_scales)\n",
    "    svmval_scaled <- as.data.frame(svmval_scaled, row.names=rownames(valdat))\n",
    "    \n",
    "    # Compute prob01 and prob02 columns.\n",
    "    preds01_b <- predict(svmod, newdata=svmval_scaled, scale=FALSE, probability=TRUE)\n",
    "    prob01_b <- as.numeric(attr(preds01_b, \"probabilities\")[, 2])\n",
    "    prob02_b <- as.numeric(attr(preds01_b, \"probabilities\")[, 3])\n",
    "    \n",
    "    # Scale the probability columns.\n",
    "    prob01b_scaled <- scale(prob01_b, center=prob01_center, scale=prob01_scale)\n",
    "    prob02b_scaled <- scale(prob02_b, center=prob02_center, scale=prob02_scale)\n",
    "    \n",
    "    # Transform columns of valdat.\n",
    "    valdat$Phenols <- (valdat$Phenols)^0.5\n",
    "    valdat$Alcalinity <- (valdat$Alcalinity)^0.18\n",
    "    \n",
    "    # Apply pca to valdat.\n",
    "    valpca <- predict(pca, valdat[, -1])\n",
    "    df02tmp <- as.data.frame(valpca, row.names=rownames(valdat))\n",
    "    \n",
    "    # Add in the probability columns.\n",
    "    df02tmp$prob01 <- prob01b_scaled\n",
    "    df02tmp$prob02 <- prob02b_scaled\n",
    "    \n",
    "    # Apply min-max scaling.\n",
    "    df03_t <- t(as.matrix(df02tmp))\n",
    "    df03_asList <- split(df03_t, seq(nrow(df03_t)))\n",
    "    names(df03_asList) <- colnames(traindat_scaled)\n",
    "    valpca_scaled <- mapply(range02, df03_asList, traindat_mins, traindat_maxs)\n",
    "\n",
    "    # The next step is crucial.\n",
    "    valdat_scaled <- as.data.frame(valpca_scaled, row.names=rownames(valdat))\n",
    "    colnames(valdat_scaled) <- colnames(traindat_scaled)\n",
    "    \n",
    "    \n",
    "    #############################\n",
    "    # Construct k-means model.\n",
    "\n",
    "    kmod <- kmeans(traindat_scaled, 3, iter.max = 50, nstart=30)\n",
    "    \n",
    "    # See how the clusters are associated with Type level.\n",
    "    dfout <- as.data.frame(cbind(traindat$Type, kmod$cluster))\n",
    "    colnames(dfout) <- c(\"Type\", \"cluster\")\n",
    "    rownames(dfout) <- rownames(traindat)\n",
    "    mapping <- get_mapping(dfout)\n",
    "    \n",
    "    #############################\n",
    "    # Apply the k-means model to valdat_scaled.\n",
    "    \n",
    "    # Each element of the following list is a row of valdat_scaled.\n",
    "    valdat_asList <- split(valdat_scaled[, colnames(kmod$centers)],\n",
    "                           seq(nrow(valdat_scaled)))\n",
    "    \n",
    "    ctr_list <- vector(\"list\", length= nrow(valdat))\n",
    "    for(i in 1:nrow(valdat)) {\n",
    "        \n",
    "        ctr_list[[i]] <- kmod$centers\n",
    "    }\n",
    "    names(ctr_list) <- rownames(valdat)\n",
    "    \n",
    "    \n",
    "    # Get the predictions for the validation set.\n",
    "    cluster_assgns <- mcmapply(getCluster, valdat_asList, ctr_list,\n",
    "                               SIMPLIFY=TRUE, USE.NAMES= FALSE, mc.cores=6)\n",
    "    \n",
    "    valdat_scaled$cluster <- as.numeric(cluster_assgns)\n",
    "    \n",
    "    valdat_scaled$pred_Type <- NA\n",
    "    \n",
    "    # Apply mapping to the assigned clusters.  Since valdat is \n",
    "    # quite small (around 35 records if folds = 5), and there \n",
    "    # are 3 clusters, it is possible that one of the LHS expressions\n",
    "    # below is NA.  I will make the changes if the program fails. \n",
    "    valdat_scaled[which(valdat_scaled$cluster==1), c(\"pred_Type\")] <- as.numeric(mapping[\"1\"])\n",
    "    valdat_scaled[which(valdat_scaled$cluster==2), c(\"pred_Type\")] <- as.numeric(mapping[\"2\"])\n",
    "    valdat_scaled[which(valdat_scaled$cluster==3), c(\"pred_Type\")] <- as.numeric(mapping[\"3\"])\n",
    "    \n",
    "    # Generate confusion matrix for the k-means clusters and\n",
    "    # the corresponding f-score.\n",
    "    preds <- as.factor(valdat_scaled$pred_Type)\n",
    "    names(preds) <- rownames(valdat)\n",
    "    ans <- get_confusion(preds, valdat[, \"Type\", drop=FALSE])\n",
    "    return(ans[[2]])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-06-02 12:42:29'"
      ],
      "text/latex": [
       "'Start time: 2021-06-02 12:42:29'"
      ],
      "text/markdown": [
       "'Start time: 2021-06-02 12:42:29'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-06-02 12:42:29\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 6.65 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the same initial seed as we have been using for\n",
    "# this score.\n",
    "\n",
    "set.seed(1931)\n",
    "seed_vector <- sample(1:9999, 2000, replace=FALSE)\n",
    "\n",
    "# Here we need to use train instead of df because\n",
    "# svm02 is using un-transformed columns.\n",
    "\n",
    "start <- Sys.time()\n",
    "paste(\"Start time: \", start, sep=\"\")\n",
    "ans <- compute_cvScore_km(seed_vector, train)\n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 6.65 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "  0.785   0.821   0.831   0.830   0.838   0.865 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(ans$Acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.8298"
      ],
      "text/latex": [
       "0.8298"
      ],
      "text/markdown": [
       "0.8298"
      ],
      "text/plain": [
       "[1] 0.8298"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(mean(ans$Acc), 4)\n",
    "# 0.8298\n",
    "\n",
    "# Section 2 score: 0.8295\n",
    "\n",
    "# For svm02, this score was 0.8278.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.8314"
      ],
      "text/latex": [
       "0.8314"
      ],
      "text/markdown": [
       "0.8314"
      ],
      "text/plain": [
       "[1] 0.8314"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.01239"
      ],
      "text/latex": [
       "0.01239"
      ],
      "text/markdown": [
       "0.01239"
      ],
      "text/plain": [
       "[1] 0.01239"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(median(ans$Acc), 4)\n",
    "round(sd(ans$Acc), 6)\n",
    "# 0.8314\n",
    "# 0.01239\n",
    "\n",
    "# Section 2 median: 0.8314\n",
    "# Section 2 sd: 0.012021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAMAAAC323mdAAAC+lBMVEUAAAABAQECAgIDAwME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\nt0iNjFNPDgAAAABJRU5ErkJggg==",
      "text/plain": [
       "Plot with title “Distribution of cross-val accuracy scores for hybrid k-means model”"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width= 10, repr.plot.height= 6)\n",
    "hist(ans$Acc, breaks=14, xlab=\"accuracy\",\n",
    "     main=\"Distribution of cross-val accuracy scores for hybrid k-means model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See what the variability is in the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1469</li><li>4</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1469\n",
       "\\item 4\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1469\n",
       "2. 4\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1469    4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# With 4 columns, no weights = 0.25 for each column.  \n",
    "# Keep 0.25 at the center of each sequence.\n",
    "\n",
    "lst <- vector(\"list\", length= 4)\n",
    "names(lst) <- c(paste0(\"pc\", 1:2), \"prob01\",\"prob02\")\n",
    "\n",
    "lst[[1]] <- lst[[2]] <- lst[[3]] <- lst[[4]] <- seq(0.13, 0.37, by=0.02)\n",
    "\n",
    "start <- Sys.time()\n",
    "dfc01 <- generate_combs(lst)\n",
    "stop <- Sys.time()\n",
    "# round(stop - start, 2)\n",
    "\n",
    "dim(dfc01)\n",
    "#  1,469     4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for computing the tot.withinss for each set of \n",
    "# weights in df_params (a dataframe, each row of which is\n",
    "# a candidate set of weights).  The optimal set of weights\n",
    "# will be the set that yields the smallest average (over\n",
    "# the folds) for tot.withinss.\n",
    "# This function is called from gridSearch07.\n",
    "\n",
    "get_tot.withinss02 <- function(traindat, valdat, wghts) {\n",
    "    \n",
    "    # Scale traindat for purpose of an svm model.\n",
    "    svm_scaled <- scale(traindat[, -1])\n",
    "    svm_centers <- attr(svm_scaled, \"scaled:center\")\n",
    "    svm_scales <- attr(svm_scaled, \"scaled:scale\")\n",
    "    svm_scaled <- as.data.frame(cbind(traindat$Type, svm_scaled),\n",
    "                                row.names=rownames(traindat))\n",
    "    colnames(svm_scaled) <- colnames(traindat)\n",
    "    \n",
    "    # This is our current best svm model for the trainset data\n",
    "    svmod <- svm(I(as.factor(Type)) ~ ., data=svm_scaled, kernel=\"radial\",\n",
    "                 gamma= 0.03, cost= 25, scale=FALSE, probability=TRUE)\n",
    "    \n",
    "    preds <- predict(svmod, newdata=svm_scaled, scale=FALSE, probability=TRUE)\n",
    "    \n",
    "    prob01 <- as.numeric(attr(preds, \"probabilities\")[, 2])\n",
    "    prob02 <- as.numeric(attr(preds, \"probabilities\")[, 3])\n",
    "    \n",
    "    # Scale the probability columns.\n",
    "    prob01_scaled <- scale(prob01, center=TRUE, scale=TRUE)\n",
    "    prob01_center <- attr(prob01_scaled, \"scaled:center\")\n",
    "    prob01_scale <- attr(prob01_scaled, \"scaled:scale\")\n",
    "    \n",
    "    prob02_scaled <- scale(prob02, center=TRUE, scale=TRUE)\n",
    "    prob02_center <- attr(prob02_scaled, \"scaled:center\")\n",
    "    prob02_scale <- attr(prob02_scaled, \"scaled:scale\")\n",
    "    \n",
    "    #############################\n",
    "    \n",
    "    # Transform columns of traindat.\n",
    "    traindat$Phenols <- (traindat$Phenols)^0.5\n",
    "    traindat$Alcalinity <- (traindat$Alcalinity)^0.18\n",
    "    \n",
    "    # Apply pca to traindat.\n",
    "    pca <- prcomp(traindat[, -1], retx=TRUE, rank.=2, center=TRUE,\n",
    "                  scale.=TRUE)\n",
    "    dftmp <- as.data.frame(pca$x, row.names=rownames(traindat))\n",
    "    \n",
    "    # Add in the probability columns.\n",
    "    dftmp$prob01 <- prob01_scaled\n",
    "    dftmp$prob02 <- prob02_scaled\n",
    "    \n",
    "    # Apply min-max scaling.\n",
    "    # dftmp_scaled <- apply(as.matrix(dftmp), MARGIN=2, range01)\n",
    "    \n",
    "    # traindat_scaled <- as.data.frame(dftmp_scaled, row.names=rownames(traindat))\n",
    "    # colnames(traindat_scaled) <- c(paste0(\"pc\", 1:2),\"prob01\",\"prob02\")\n",
    "    \n",
    "    # Get mins and maxs for scaling of valdat.\n",
    "    traindat_mins <- as.numeric(apply(as.matrix(dftmp), MARGIN=2, min))\n",
    "    traindat_maxs <- as.numeric(apply(as.matrix(dftmp), MARGIN=2, max))\n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################\n",
    "    # Prepare valdat for svm modeling.\n",
    "    \n",
    "    svmval_scaled <- scale(valdat[, -1], center=svm_centers, scale=svm_scales)\n",
    "    svmval_scaled <- as.data.frame(svmval_scaled, row.names=rownames(valdat))\n",
    "    \n",
    "    # Compute prob01 and prob02 columns.\n",
    "    preds01_b <- predict(svmod, newdata=svmval_scaled, scale=FALSE, probability=TRUE)\n",
    "    prob01_b <- as.numeric(attr(preds01_b, \"probabilities\")[, 2])\n",
    "    prob02_b <- as.numeric(attr(preds01_b, \"probabilities\")[, 3])\n",
    "    \n",
    "    # Scale the probability columns.\n",
    "    prob01b_scaled <- scale(prob01_b, center=prob01_center, scale=prob01_scale)\n",
    "    prob02b_scaled <- scale(prob02_b, center=prob02_center, scale=prob02_scale)\n",
    "    \n",
    "    # Transform columns of valdat.\n",
    "    valdat$Phenols <- (valdat$Phenols)^0.5\n",
    "    valdat$Alcalinity <- (valdat$Alcalinity)^0.18\n",
    "    \n",
    "    # Apply pca to valdat.\n",
    "    valpca <- predict(pca, valdat[, -1])\n",
    "    df02tmp <- as.data.frame(valpca, row.names=rownames(valdat))\n",
    "    \n",
    "    # Add in the probability columns.\n",
    "    df02tmp$prob01 <- prob01b_scaled\n",
    "    df02tmp$prob02 <- prob02b_scaled\n",
    "    \n",
    "    # Apply min-max scaling.\n",
    "    df03_t <- t(as.matrix(df02tmp))\n",
    "    df03_asList <- split(df03_t, seq(nrow(df03_t)))\n",
    "    names(df03_asList) <- c(paste0(\"pc\", 1:2),\"prob01\",\"prob02\")\n",
    "    valpca_scaled <- mapply(range02, df03_asList, traindat_mins, traindat_maxs)\n",
    "\n",
    "    # The next step is crucial.\n",
    "    valdat_scaled <- as.data.frame(valpca_scaled, row.names=rownames(valdat))\n",
    "    colnames(valdat_scaled) <- c(paste0(\"pc\", 1:2),\"prob01\",\"prob02\")\n",
    "    \n",
    "    \n",
    "    # Apply weights to valdat_scaled.\n",
    "    cols <- names(wghts)\n",
    "    df4 <- t(t(valdat_scaled[, cols]) * as.numeric(wghts[cols]))\n",
    "    # valdat_wghts <- as.data.frame(df4, row.names=rownames(valdat))\n",
    "    # colnames(valdat_wghts) <- cols\n",
    "    \n",
    "    \n",
    "    #############################################\n",
    "    # Construct k-means model on the validation set.\n",
    "\n",
    "    kmod <- kmeans(df4, 3, iter.max = 50, nstart=30)\n",
    "    \n",
    "    return(kmod$tot.withinss)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>pc1</th><th scope=col>pc2</th><th scope=col>prob01</th><th scope=col>prob02</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>11425</th><td>0.33</td><td>0.27</td><td>0.17</td><td>0.23</td></tr>\n",
       "\t<tr><th scope=row>7201</th><td>0.35</td><td>0.27</td><td>0.19</td><td>0.19</td></tr>\n",
       "\t<tr><th scope=row>22165</th><td>0.37</td><td>0.15</td><td>0.15</td><td>0.33</td></tr>\n",
       "\t<tr><th scope=row>20509</th><td>0.27</td><td>0.21</td><td>0.21</td><td>0.31</td></tr>\n",
       "\t<tr><th scope=row>23329</th><td>0.25</td><td>0.13</td><td>0.29</td><td>0.33</td></tr>\n",
       "\t<tr><th scope=row>22057</th><td>0.29</td><td>0.25</td><td>0.13</td><td>0.33</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & pc1 & pc2 & prob01 & prob02\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t11425 & 0.33 & 0.27 & 0.17 & 0.23\\\\\n",
       "\t7201 & 0.35 & 0.27 & 0.19 & 0.19\\\\\n",
       "\t22165 & 0.37 & 0.15 & 0.15 & 0.33\\\\\n",
       "\t20509 & 0.27 & 0.21 & 0.21 & 0.31\\\\\n",
       "\t23329 & 0.25 & 0.13 & 0.29 & 0.33\\\\\n",
       "\t22057 & 0.29 & 0.25 & 0.13 & 0.33\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 4\n",
       "\n",
       "| <!--/--> | pc1 &lt;dbl&gt; | pc2 &lt;dbl&gt; | prob01 &lt;dbl&gt; | prob02 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 11425 | 0.33 | 0.27 | 0.17 | 0.23 |\n",
       "| 7201 | 0.35 | 0.27 | 0.19 | 0.19 |\n",
       "| 22165 | 0.37 | 0.15 | 0.15 | 0.33 |\n",
       "| 20509 | 0.27 | 0.21 | 0.21 | 0.31 |\n",
       "| 23329 | 0.25 | 0.13 | 0.29 | 0.33 |\n",
       "| 22057 | 0.29 | 0.25 | 0.13 | 0.33 |\n",
       "\n"
      ],
      "text/plain": [
       "      pc1  pc2  prob01 prob02\n",
       "11425 0.33 0.27 0.17   0.23  \n",
       "7201  0.35 0.27 0.19   0.19  \n",
       "22165 0.37 0.15 0.15   0.33  \n",
       "20509 0.27 0.21 0.21   0.31  \n",
       "23329 0.25 0.13 0.29   0.33  \n",
       "22057 0.29 0.25 0.13   0.33  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test on a sample of 100.\n",
    "\n",
    "set.seed(42)\n",
    "smp <- sample(rownames(dfc01), 100, replace=FALSE)\n",
    "tst_params <- dfc01[smp,]\n",
    "head(tst_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-06-02 13:53:22'"
      ],
      "text/latex": [
       "'Start time: 2021-06-02 13:53:22'"
      ],
      "text/markdown": [
       "'Start time: 2021-06-02 13:53:22'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-06-02 13:53:22\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 7.06 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the best weights of those in tst_params.\n",
    "# Use 120 seeds.\n",
    "\n",
    "set.seed(1233)\n",
    "seed_vector <- sample(1:9999, 120, replace=FALSE)\n",
    "\n",
    "start <- Sys.time()\n",
    "paste0(\"Start time: \", start)\n",
    "dat_result <- gridSearch07(seed_vector, train, tst_params) \n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 7.06 mins (for 100 rows; 120 seeds each row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params <- dat_result[which(dat_result$tot.withinss == \n",
    "                                min(dat_result$tot.withinss, na.rm=TRUE)),]$row\n",
    "length(best_params)\n",
    "\n",
    "best_tot.withinss <- round(dat_result[which(dat_result$tot.withinss == \n",
    "                                min(dat_result$tot.withinss, na.rm=TRUE)),]$tot.withinss, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 1 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>pc1</th><th scope=col>pc2</th><th scope=col>prob01</th><th scope=col>prob02</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>26377</th><td>0.37</td><td>0.13</td><td>0.13</td><td>0.37</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & pc1 & pc2 & prob01 & prob02\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t26377 & 0.37 & 0.13 & 0.13 & 0.37\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 4\n",
       "\n",
       "| <!--/--> | pc1 &lt;dbl&gt; | pc2 &lt;dbl&gt; | prob01 &lt;dbl&gt; | prob02 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 26377 | 0.37 | 0.13 | 0.13 | 0.37 |\n",
       "\n"
      ],
      "text/plain": [
       "      pc1  pc2  prob01 prob02\n",
       "26377 0.37 0.13 0.13   0.37  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.46"
      ],
      "text/latex": [
       "0.46"
      ],
      "text/markdown": [
       "0.46"
      ],
      "text/plain": [
       "[1] 0.46"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfc01[best_params,]\n",
    "\n",
    "best_tot.withinss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-06-02 14:03:20'"
      ],
      "text/latex": [
       "'Start time: 2021-06-02 14:03:20'"
      ],
      "text/markdown": [
       "'Start time: 2021-06-02 14:03:20'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-06-02 14:03:20\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 1.8 hours"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the best weights of those in dfc01.\n",
    "# Use 120 seeds.  [Approx. time: 1.75 hours]\n",
    "\n",
    "set.seed(1233)\n",
    "seed_vector <- sample(1:9999, 120, replace=FALSE)\n",
    "\n",
    "start <- Sys.time()\n",
    "paste0(\"Start time: \", start)\n",
    "dat_result <- gridSearch07(seed_vector, train, dfc01) \n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "datout_01 <- dat_result\n",
    "# Time difference of 1.8 hours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params <- dat_result[which(dat_result$tot.withinss == \n",
    "                                min(dat_result$tot.withinss, na.rm=TRUE)),]$row\n",
    "length(best_params)\n",
    "\n",
    "best_tot.withinss <- round(dat_result[which(dat_result$tot.withinss == \n",
    "                                min(dat_result$tot.withinss, na.rm=TRUE)),]$tot.withinss, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 1 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>pc1</th><th scope=col>pc2</th><th scope=col>prob01</th><th scope=col>prob02</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>26377</th><td>0.37</td><td>0.13</td><td>0.13</td><td>0.37</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & pc1 & pc2 & prob01 & prob02\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t26377 & 0.37 & 0.13 & 0.13 & 0.37\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 4\n",
       "\n",
       "| <!--/--> | pc1 &lt;dbl&gt; | pc2 &lt;dbl&gt; | prob01 &lt;dbl&gt; | prob02 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 26377 | 0.37 | 0.13 | 0.13 | 0.37 |\n",
       "\n"
      ],
      "text/plain": [
       "      pc1  pc2  prob01 prob02\n",
       "26377 0.37 0.13 0.13   0.37  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.4615"
      ],
      "text/latex": [
       "0.4615"
      ],
      "text/markdown": [
       "0.4615"
      ],
      "text/plain": [
       "[1] 0.4615"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfc01[best_params,]\n",
    "#       \t pc1\t pc2\tprob01  \tprob02\n",
    "\n",
    "# 26377 \t0.37\t0.13\t  0.13  \t  0.37\n",
    "\n",
    "best_tot.withinss\n",
    "# 0.4615\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 15 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>row</th><th scope=col>tot.withinss</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1379</th><td>26377</td><td>0.46152</td></tr>\n",
       "\t<tr><th scope=row>1289</th><td>24349</td><td>0.46377</td></tr>\n",
       "\t<tr><th scope=row>1277</th><td>24193</td><td>0.46483</td></tr>\n",
       "\t<tr><th scope=row>1189</th><td>22321</td><td>0.46559</td></tr>\n",
       "\t<tr><th scope=row>1392</th><td>26545</td><td>0.46580</td></tr>\n",
       "\t<tr><th scope=row>1380</th><td>26389</td><td>0.46712</td></tr>\n",
       "\t<tr><th scope=row>1081</th><td>20293</td><td>0.46731</td></tr>\n",
       "\t<tr><th scope=row>1177</th><td>22165</td><td>0.46735</td></tr>\n",
       "\t<tr><th scope=row>1302</th><td>24517</td><td>0.46798</td></tr>\n",
       "\t<tr><th scope=row>1166</th><td>22009</td><td>0.46799</td></tr>\n",
       "\t<tr><th scope=row>967</th><td>18265</td><td>0.46822</td></tr>\n",
       "\t<tr><th scope=row>1069</th><td>20137</td><td>0.46933</td></tr>\n",
       "\t<tr><th scope=row>1290</th><td>24361</td><td>0.46950</td></tr>\n",
       "\t<tr><th scope=row>1202</th><td>22489</td><td>0.46966</td></tr>\n",
       "\t<tr><th scope=row>849</th><td>16237</td><td>0.46973</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 15 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & row & tot.withinss\\\\\n",
       "  & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1379 & 26377 & 0.46152\\\\\n",
       "\t1289 & 24349 & 0.46377\\\\\n",
       "\t1277 & 24193 & 0.46483\\\\\n",
       "\t1189 & 22321 & 0.46559\\\\\n",
       "\t1392 & 26545 & 0.46580\\\\\n",
       "\t1380 & 26389 & 0.46712\\\\\n",
       "\t1081 & 20293 & 0.46731\\\\\n",
       "\t1177 & 22165 & 0.46735\\\\\n",
       "\t1302 & 24517 & 0.46798\\\\\n",
       "\t1166 & 22009 & 0.46799\\\\\n",
       "\t967 & 18265 & 0.46822\\\\\n",
       "\t1069 & 20137 & 0.46933\\\\\n",
       "\t1290 & 24361 & 0.46950\\\\\n",
       "\t1202 & 22489 & 0.46966\\\\\n",
       "\t849 & 16237 & 0.46973\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 15 × 2\n",
       "\n",
       "| <!--/--> | row &lt;chr&gt; | tot.withinss &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 1379 | 26377 | 0.46152 |\n",
       "| 1289 | 24349 | 0.46377 |\n",
       "| 1277 | 24193 | 0.46483 |\n",
       "| 1189 | 22321 | 0.46559 |\n",
       "| 1392 | 26545 | 0.46580 |\n",
       "| 1380 | 26389 | 0.46712 |\n",
       "| 1081 | 20293 | 0.46731 |\n",
       "| 1177 | 22165 | 0.46735 |\n",
       "| 1302 | 24517 | 0.46798 |\n",
       "| 1166 | 22009 | 0.46799 |\n",
       "| 967 | 18265 | 0.46822 |\n",
       "| 1069 | 20137 | 0.46933 |\n",
       "| 1290 | 24361 | 0.46950 |\n",
       "| 1202 | 22489 | 0.46966 |\n",
       "| 849 | 16237 | 0.46973 |\n",
       "\n"
      ],
      "text/plain": [
       "     row   tot.withinss\n",
       "1379 26377 0.46152     \n",
       "1289 24349 0.46377     \n",
       "1277 24193 0.46483     \n",
       "1189 22321 0.46559     \n",
       "1392 26545 0.46580     \n",
       "1380 26389 0.46712     \n",
       "1081 20293 0.46731     \n",
       "1177 22165 0.46735     \n",
       "1302 24517 0.46798     \n",
       "1166 22009 0.46799     \n",
       "967  18265 0.46822     \n",
       "1069 20137 0.46933     \n",
       "1290 24361 0.46950     \n",
       "1202 22489 0.46966     \n",
       "849  16237 0.46973     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datout_01 <- datout_01[order(datout_01$tot.withinss, decreasing=FALSE),]\n",
    "datout_01[1:15,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>pc1</th><th scope=col>pc2</th><th scope=col>prob01</th><th scope=col>prob02</th><th scope=col>tot.withinss</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>26377</th><td>0.37</td><td>0.13</td><td>0.13</td><td>0.37</td><td>0.46152</td></tr>\n",
       "\t<tr><th scope=row>24349</th><td>0.37</td><td>0.13</td><td>0.15</td><td>0.35</td><td>0.46377</td></tr>\n",
       "\t<tr><th scope=row>24193</th><td>0.37</td><td>0.15</td><td>0.13</td><td>0.35</td><td>0.46483</td></tr>\n",
       "\t<tr><th scope=row>22321</th><td>0.37</td><td>0.13</td><td>0.17</td><td>0.33</td><td>0.46559</td></tr>\n",
       "\t<tr><th scope=row>26545</th><td>0.35</td><td>0.13</td><td>0.15</td><td>0.37</td><td>0.46580</td></tr>\n",
       "\t<tr><th scope=row>26389</th><td>0.35</td><td>0.15</td><td>0.13</td><td>0.37</td><td>0.46712</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & pc1 & pc2 & prob01 & prob02 & tot.withinss\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t26377 & 0.37 & 0.13 & 0.13 & 0.37 & 0.46152\\\\\n",
       "\t24349 & 0.37 & 0.13 & 0.15 & 0.35 & 0.46377\\\\\n",
       "\t24193 & 0.37 & 0.15 & 0.13 & 0.35 & 0.46483\\\\\n",
       "\t22321 & 0.37 & 0.13 & 0.17 & 0.33 & 0.46559\\\\\n",
       "\t26545 & 0.35 & 0.13 & 0.15 & 0.37 & 0.46580\\\\\n",
       "\t26389 & 0.35 & 0.15 & 0.13 & 0.37 & 0.46712\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 5\n",
       "\n",
       "| <!--/--> | pc1 &lt;dbl&gt; | pc2 &lt;dbl&gt; | prob01 &lt;dbl&gt; | prob02 &lt;dbl&gt; | tot.withinss &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 26377 | 0.37 | 0.13 | 0.13 | 0.37 | 0.46152 |\n",
       "| 24349 | 0.37 | 0.13 | 0.15 | 0.35 | 0.46377 |\n",
       "| 24193 | 0.37 | 0.15 | 0.13 | 0.35 | 0.46483 |\n",
       "| 22321 | 0.37 | 0.13 | 0.17 | 0.33 | 0.46559 |\n",
       "| 26545 | 0.35 | 0.13 | 0.15 | 0.37 | 0.46580 |\n",
       "| 26389 | 0.35 | 0.15 | 0.13 | 0.37 | 0.46712 |\n",
       "\n"
      ],
      "text/plain": [
       "      pc1  pc2  prob01 prob02 tot.withinss\n",
       "26377 0.37 0.13 0.13   0.37   0.46152     \n",
       "24349 0.37 0.13 0.15   0.35   0.46377     \n",
       "24193 0.37 0.15 0.13   0.35   0.46483     \n",
       "22321 0.37 0.13 0.17   0.33   0.46559     \n",
       "26545 0.35 0.13 0.15   0.37   0.46580     \n",
       "26389 0.35 0.15 0.13   0.37   0.46712     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bestrows <- (datout_01$row)[1:6]\n",
    "dfc02 <- as.data.frame(cbind(dfc01[bestrows,], datout_01[1:6, c(\"tot.withinss\")]),\n",
    "                       row.names=bestrows)\n",
    "colnames(dfc02) <- c(colnames(dfc01), \"tot.withinss\")\n",
    "dfc02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>44</li><li>4</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 44\n",
       "\\item 4\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 44\n",
       "2. 4\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 44  4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Refine the search, this time using cross-val accuracy scores.\n",
    "\n",
    "lst <- vector(\"list\", length= 4)\n",
    "names(lst) <- c(paste0(\"pc\", 1:2), \"prob01\",\"prob02\")\n",
    "\n",
    "lst[[1]] <- seq(0.36, 0.39, by=0.01)\n",
    "lst[[2]] <- seq(0.11, 0.14, by=0.01)\n",
    "lst[[3]] <- seq(0.11, 0.14, by=0.01)\n",
    "lst[[4]] <- seq(0.36, 0.39, by=0.01)\n",
    "\n",
    "start <- Sys.time()\n",
    "dfc02 <- generate_combs(lst)\n",
    "stop <- Sys.time()\n",
    "# round(stop - start, 2)\n",
    "\n",
    "dim(dfc02)\n",
    "#  44     4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for obtaining average of confusion matrix accuracy\n",
    "# score. This function is called from gridSearch03.\n",
    "\n",
    "get_cvScore_hybrid_pcaWghts <- function(traindat, valdat, wghts) {\n",
    "    \n",
    "    # Scale traindat for purpose of an svm model.\n",
    "    svm_scaled <- scale(traindat[, -1])\n",
    "    svm_centers <- attr(svm_scaled, \"scaled:center\")\n",
    "    svm_scales <- attr(svm_scaled, \"scaled:scale\")\n",
    "    svm_scaled <- as.data.frame(cbind(traindat$Type, svm_scaled),\n",
    "                                row.names=rownames(traindat))\n",
    "    colnames(svm_scaled) <- colnames(traindat)\n",
    "    \n",
    "    # This is our current best svm model for the trainset data\n",
    "    svmod <- svm(I(as.factor(Type)) ~ ., data=svm_scaled, kernel=\"radial\",\n",
    "                 gamma= 0.03, cost= 25, scale=FALSE, probability=TRUE)\n",
    "    \n",
    "    preds <- predict(svmod, newdata=svm_scaled, scale=FALSE, probability=TRUE)\n",
    "    \n",
    "    prob01 <- as.numeric(attr(preds, \"probabilities\")[, 2])\n",
    "    prob02 <- as.numeric(attr(preds, \"probabilities\")[, 3])\n",
    "    \n",
    "    # Scale the probability columns.\n",
    "    prob01_scaled <- scale(prob01, center=TRUE, scale=TRUE)\n",
    "    prob01_center <- attr(prob01_scaled, \"scaled:center\")\n",
    "    prob01_scale <- attr(prob01_scaled, \"scaled:scale\")\n",
    "    \n",
    "    prob02_scaled <- scale(prob02, center=TRUE, scale=TRUE)\n",
    "    prob02_center <- attr(prob02_scaled, \"scaled:center\")\n",
    "    prob02_scale <- attr(prob02_scaled, \"scaled:scale\")\n",
    "    \n",
    "    #############################\n",
    "    \n",
    "    # Transform columns of traindat.\n",
    "    traindat$Phenols <- (traindat$Phenols)^0.5\n",
    "    traindat$Alcalinity <- (traindat$Alcalinity)^0.18\n",
    "    \n",
    "    # Apply pca to traindat.\n",
    "    pca <- prcomp(traindat[, -1], retx=TRUE, rank.=2, center=TRUE,\n",
    "                  scale.=TRUE)\n",
    "    dftmp <- as.data.frame(pca$x, row.names=rownames(traindat))\n",
    "    \n",
    "    # Add in the probability columns.\n",
    "    dftmp$prob01 <- prob01_scaled\n",
    "    dftmp$prob02 <- prob02_scaled\n",
    "    \n",
    "    # Apply min-max scaling.\n",
    "    dftmp_scaled <- apply(as.matrix(dftmp), MARGIN=2, range01)\n",
    "    \n",
    "    traindat_scaled <- as.data.frame(dftmp_scaled, row.names=rownames(traindat))\n",
    "    colnames(traindat_scaled) <- c(paste0(\"pc\", 1:2),\"prob01\",\"prob02\")\n",
    "    \n",
    "    # Get mins and maxs for scaling of valdat.\n",
    "    traindat_mins <- as.numeric(apply(as.matrix(dftmp), MARGIN=2, min))\n",
    "    traindat_maxs <- as.numeric(apply(as.matrix(dftmp), MARGIN=2, max))\n",
    "    \n",
    "    #############################\n",
    "    # Apply weights to traindat.  The sqrt should have\n",
    "    # been taken in the calling function.\n",
    "    cols <- names(wghts)\n",
    "    df2 <- t(t(traindat_scaled[, cols]) * as.numeric(wghts[cols]))\n",
    "    traindat_wghts <- as.data.frame(df2, row.names=rownames(traindat))\n",
    "    \n",
    "    \n",
    "    ############################\n",
    "    # Prepare valdat for svm modeling.\n",
    "    \n",
    "    svmval_scaled <- scale(valdat[, -1], center=svm_centers, scale=svm_scales)\n",
    "    svmval_scaled <- as.data.frame(svmval_scaled, row.names=rownames(valdat))\n",
    "    \n",
    "    # Compute prob01 and prob02 columns.\n",
    "    preds01_b <- predict(svmod, newdata=svmval_scaled, scale=FALSE, probability=TRUE)\n",
    "    prob01_b <- as.numeric(attr(preds01_b, \"probabilities\")[, 2])\n",
    "    prob02_b <- as.numeric(attr(preds01_b, \"probabilities\")[, 3])\n",
    "    \n",
    "    # Scale the probability columns.\n",
    "    prob01b_scaled <- scale(prob01_b, center=prob01_center, scale=prob01_scale)\n",
    "    prob02b_scaled <- scale(prob02_b, center=prob02_center, scale=prob02_scale)\n",
    "    \n",
    "    # Transform columns of valdat.\n",
    "    valdat$Phenols <- (valdat$Phenols)^0.5\n",
    "    valdat$Alcalinity <- (valdat$Alcalinity)^0.18\n",
    "    \n",
    "    # Apply pca to valdat.\n",
    "    valpca <- predict(pca, valdat[, -1])\n",
    "    df02tmp <- as.data.frame(valpca, row.names=rownames(valdat))\n",
    "    \n",
    "    # Add in the probability columns.\n",
    "    df02tmp$prob01 <- prob01b_scaled\n",
    "    df02tmp$prob02 <- prob02b_scaled\n",
    "    \n",
    "    # Apply min-max scaling.\n",
    "    df03_t <- t(as.matrix(df02tmp))\n",
    "    df03_asList <- split(df03_t, seq(nrow(df03_t)))\n",
    "    names(df03_asList) <- colnames(traindat_scaled)\n",
    "    valpca_scaled <- mapply(range02, df03_asList, traindat_mins, traindat_maxs)\n",
    "\n",
    "    # The next step is crucial.\n",
    "    valdat_scaled <- as.data.frame(valpca_scaled, row.names=rownames(valdat))\n",
    "    colnames(valdat_scaled) <- colnames(traindat_scaled)\n",
    "    \n",
    "    # Apply weights to valdat_scaled.\n",
    "    df4 <- t(t(valdat_scaled[, cols]) * as.numeric(wghts[cols]))\n",
    "    valdat_wghts <- as.data.frame(df4, row.names=rownames(valdat))\n",
    "    colnames(valdat_wghts) <- colnames(traindat_scaled)\n",
    "    \n",
    "    \n",
    "    #############################\n",
    "    # Construct k-means model.\n",
    "\n",
    "    kmod <- kmeans(traindat_wghts, 3, iter.max = 50, nstart=30)\n",
    "    \n",
    "    # See how the clusters are associated with Type level.\n",
    "    dfout <- as.data.frame(cbind(traindat$Type, kmod$cluster))\n",
    "    colnames(dfout) <- c(\"Type\", \"cluster\")\n",
    "    rownames(dfout) <- rownames(traindat)\n",
    "    mapping <- get_mapping(dfout)\n",
    "    \n",
    "    #############################\n",
    "    # Apply the k-means model to valdat_scaled.\n",
    "    \n",
    "    # Each element of the following list is a row of valdat_scaled.\n",
    "    valdat_asList <- split(valdat_wghts[, colnames(kmod$centers)],\n",
    "                           seq(nrow(valdat_wghts)))\n",
    "    \n",
    "    ctr_list <- vector(\"list\", length= nrow(valdat))\n",
    "    for(i in 1:nrow(valdat)) {\n",
    "        \n",
    "        ctr_list[[i]] <- kmod$centers\n",
    "    }\n",
    "    names(ctr_list) <- rownames(valdat)\n",
    "    \n",
    "    \n",
    "    # Get the predictions for the validation set.\n",
    "    cluster_assgns <- mcmapply(getCluster, valdat_asList, ctr_list,\n",
    "                               SIMPLIFY=TRUE, USE.NAMES= FALSE, mc.cores=6)\n",
    "    \n",
    "    valdat_scaled$cluster <- as.numeric(cluster_assgns)\n",
    "    \n",
    "    valdat_scaled$pred_Type <- NA\n",
    "    \n",
    "    # Apply mapping to the assigned clusters.  Since valdat is \n",
    "    # quite small (around 35 records if folds = 5), and there \n",
    "    # are 3 clusters, it is possible that one of the LHS expressions\n",
    "    # below is NA.  I will make the changes if the program fails. \n",
    "    valdat_scaled[which(valdat_scaled$cluster==1), c(\"pred_Type\")] <- as.numeric(mapping[\"1\"])\n",
    "    valdat_scaled[which(valdat_scaled$cluster==2), c(\"pred_Type\")] <- as.numeric(mapping[\"2\"])\n",
    "    valdat_scaled[which(valdat_scaled$cluster==3), c(\"pred_Type\")] <- as.numeric(mapping[\"3\"])\n",
    "    \n",
    "    # Generate confusion matrix for the k-means clusters and\n",
    "    # the corresponding f-score.\n",
    "    preds <- as.factor(valdat_scaled$pred_Type)\n",
    "    names(preds) <- rownames(valdat)\n",
    "    ans <- get_confusion(preds, valdat[, \"Type\", drop=FALSE])\n",
    "    return(ans[[2]])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-06-03 09:24:59'"
      ],
      "text/latex": [
       "'Start time: 2021-06-03 09:24:59'"
      ],
      "text/markdown": [
       "'Start time: 2021-06-03 09:24:59'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-06-03 09:24:59\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 16.12 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the best weights of those in dfc02.\n",
    "# Use 120 seeds.\n",
    "\n",
    "set.seed(1233)\n",
    "seed_vector <- sample(1:9999, 120, replace=FALSE)\n",
    "\n",
    "start <- Sys.time()\n",
    "paste0(\"Start time: \", start)\n",
    "dat_result <- gridSearch03(seed_vector, train, dfc02) \n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "datout_02 <- dat_result\n",
    "# Time difference of 16.12 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params <- dat_result[which(dat_result$Acc == \n",
    "                                max(dat_result$Acc, na.rm=TRUE)),]$row\n",
    "length(best_params)\n",
    "\n",
    "best_Acc <- dat_result[which(dat_result$Acc == \n",
    "                                max(dat_result$Acc, na.rm=TRUE)),]$Acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 1 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>pc1</th><th scope=col>pc2</th><th scope=col>prob01</th><th scope=col>prob02</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>58</th><td>0.37</td><td>0.13</td><td>0.14</td><td>0.36</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & pc1 & pc2 & prob01 & prob02\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t58 & 0.37 & 0.13 & 0.14 & 0.36\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 4\n",
       "\n",
       "| <!--/--> | pc1 &lt;dbl&gt; | pc2 &lt;dbl&gt; | prob01 &lt;dbl&gt; | prob02 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 58 | 0.37 | 0.13 | 0.14 | 0.36 |\n",
       "\n"
      ],
      "text/plain": [
       "   pc1  pc2  prob01 prob02\n",
       "58 0.37 0.13 0.14   0.36  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.83172"
      ],
      "text/latex": [
       "0.83172"
      ],
      "text/markdown": [
       "0.83172"
      ],
      "text/plain": [
       "[1] 0.83172"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfc02[best_params,]\n",
    "#       \t pc1    \t pc2 \tprob01  \tprob02\n",
    "\n",
    "# 58    \t0.37    \t0.13 \t  0.14  \t  0.36\n",
    "\n",
    "best_Acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 15 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>row</th><th scope=col>Acc</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>9</th><td>58 </td><td>0.83172</td></tr>\n",
       "\t<tr><th scope=row>32</th><td>169</td><td>0.83161</td></tr>\n",
       "\t<tr><th scope=row>44</th><td>241</td><td>0.83150</td></tr>\n",
       "\t<tr><th scope=row>34</th><td>181</td><td>0.83141</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>52 </td><td>0.83100</td></tr>\n",
       "\t<tr><th scope=row>33</th><td>178</td><td>0.83081</td></tr>\n",
       "\t<tr><th scope=row>40</th><td>214</td><td>0.83077</td></tr>\n",
       "\t<tr><th scope=row>22</th><td>121</td><td>0.83072</td></tr>\n",
       "\t<tr><th scope=row>10</th><td>61 </td><td>0.83071</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>118</td><td>0.83070</td></tr>\n",
       "\t<tr><th scope=row>41</th><td>217</td><td>0.83062</td></tr>\n",
       "\t<tr><th scope=row>8</th><td>55 </td><td>0.83048</td></tr>\n",
       "\t<tr><th scope=row>20</th><td>115</td><td>0.83044</td></tr>\n",
       "\t<tr><th scope=row>18</th><td>106</td><td>0.83034</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>46 </td><td>0.83033</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 15 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & row & Acc\\\\\n",
       "  & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t9 & 58  & 0.83172\\\\\n",
       "\t32 & 169 & 0.83161\\\\\n",
       "\t44 & 241 & 0.83150\\\\\n",
       "\t34 & 181 & 0.83141\\\\\n",
       "\t7 & 52  & 0.83100\\\\\n",
       "\t33 & 178 & 0.83081\\\\\n",
       "\t40 & 214 & 0.83077\\\\\n",
       "\t22 & 121 & 0.83072\\\\\n",
       "\t10 & 61  & 0.83071\\\\\n",
       "\t21 & 118 & 0.83070\\\\\n",
       "\t41 & 217 & 0.83062\\\\\n",
       "\t8 & 55  & 0.83048\\\\\n",
       "\t20 & 115 & 0.83044\\\\\n",
       "\t18 & 106 & 0.83034\\\\\n",
       "\t6 & 46  & 0.83033\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 15 × 2\n",
       "\n",
       "| <!--/--> | row &lt;chr&gt; | Acc &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 9 | 58  | 0.83172 |\n",
       "| 32 | 169 | 0.83161 |\n",
       "| 44 | 241 | 0.83150 |\n",
       "| 34 | 181 | 0.83141 |\n",
       "| 7 | 52  | 0.83100 |\n",
       "| 33 | 178 | 0.83081 |\n",
       "| 40 | 214 | 0.83077 |\n",
       "| 22 | 121 | 0.83072 |\n",
       "| 10 | 61  | 0.83071 |\n",
       "| 21 | 118 | 0.83070 |\n",
       "| 41 | 217 | 0.83062 |\n",
       "| 8 | 55  | 0.83048 |\n",
       "| 20 | 115 | 0.83044 |\n",
       "| 18 | 106 | 0.83034 |\n",
       "| 6 | 46  | 0.83033 |\n",
       "\n"
      ],
      "text/plain": [
       "   row Acc    \n",
       "9  58  0.83172\n",
       "32 169 0.83161\n",
       "44 241 0.83150\n",
       "34 181 0.83141\n",
       "7  52  0.83100\n",
       "33 178 0.83081\n",
       "40 214 0.83077\n",
       "22 121 0.83072\n",
       "10 61  0.83071\n",
       "21 118 0.83070\n",
       "41 217 0.83062\n",
       "8  55  0.83048\n",
       "20 115 0.83044\n",
       "18 106 0.83034\n",
       "6  46  0.83033"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datout_02 <- datout_02[order(datout_02$Acc, decreasing=TRUE),]\n",
    "datout_02[1:15,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 5 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>pc1</th><th scope=col>pc2</th><th scope=col>prob01</th><th scope=col>prob02</th><th scope=col>Acc</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>58</th><td>0.37</td><td>0.13</td><td>0.14</td><td>0.36</td><td>0.83172</td></tr>\n",
       "\t<tr><th scope=row>169</th><td>0.36</td><td>0.13</td><td>0.13</td><td>0.38</td><td>0.83161</td></tr>\n",
       "\t<tr><th scope=row>241</th><td>0.36</td><td>0.11</td><td>0.14</td><td>0.39</td><td>0.83150</td></tr>\n",
       "\t<tr><th scope=row>181</th><td>0.36</td><td>0.12</td><td>0.14</td><td>0.38</td><td>0.83141</td></tr>\n",
       "\t<tr><th scope=row>52</th><td>0.39</td><td>0.11</td><td>0.14</td><td>0.36</td><td>0.83100</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 5 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & pc1 & pc2 & prob01 & prob02 & Acc\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t58 & 0.37 & 0.13 & 0.14 & 0.36 & 0.83172\\\\\n",
       "\t169 & 0.36 & 0.13 & 0.13 & 0.38 & 0.83161\\\\\n",
       "\t241 & 0.36 & 0.11 & 0.14 & 0.39 & 0.83150\\\\\n",
       "\t181 & 0.36 & 0.12 & 0.14 & 0.38 & 0.83141\\\\\n",
       "\t52 & 0.39 & 0.11 & 0.14 & 0.36 & 0.83100\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 5 × 5\n",
       "\n",
       "| <!--/--> | pc1 &lt;dbl&gt; | pc2 &lt;dbl&gt; | prob01 &lt;dbl&gt; | prob02 &lt;dbl&gt; | Acc &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 58 | 0.37 | 0.13 | 0.14 | 0.36 | 0.83172 |\n",
       "| 169 | 0.36 | 0.13 | 0.13 | 0.38 | 0.83161 |\n",
       "| 241 | 0.36 | 0.11 | 0.14 | 0.39 | 0.83150 |\n",
       "| 181 | 0.36 | 0.12 | 0.14 | 0.38 | 0.83141 |\n",
       "| 52 | 0.39 | 0.11 | 0.14 | 0.36 | 0.83100 |\n",
       "\n"
      ],
      "text/plain": [
       "    pc1  pc2  prob01 prob02 Acc    \n",
       "58  0.37 0.13 0.14   0.36   0.83172\n",
       "169 0.36 0.13 0.13   0.38   0.83161\n",
       "241 0.36 0.11 0.14   0.39   0.83150\n",
       "181 0.36 0.12 0.14   0.38   0.83141\n",
       "52  0.39 0.11 0.14   0.36   0.83100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bestrows <- (datout_02$row)[1:5]\n",
    "dfc03 <- as.data.frame(cbind(dfc02[bestrows,], datout_02[1:5, c(\"Acc\")]),\n",
    "                       row.names=bestrows)\n",
    "colnames(dfc03) <- c(colnames(dfc02), \"Acc\")\n",
    "dfc03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMMENT:\n",
    "\n",
    "# I could continue to search for even better\n",
    "# weights.  But instead, let's see if we can\n",
    "# get a cross-val accuracy score that equals\n",
    "# or exceeds 0.8310 with the row 58 weights above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get comparative cross-val score for pca hybrid model with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for obtaining average of confusion matrix accuracy\n",
    "# score. This function is called from get_cvScore_km.\n",
    "\n",
    "wghts <- c(0.37, 0.13, 0.14, 0.36)^0.5\n",
    "names(wghts) <- c(paste0(\"pc\", 1:2), \"prob01\",\"prob02\")\n",
    "\n",
    "get_cvScore_pcaHybrid_wghts <- function(traindat, valdat) {\n",
    "    \n",
    "    # Scale traindat for purpose of an svm model.\n",
    "    svm_scaled <- scale(traindat[, -1])\n",
    "    svm_centers <- attr(svm_scaled, \"scaled:center\")\n",
    "    svm_scales <- attr(svm_scaled, \"scaled:scale\")\n",
    "    svm_scaled <- as.data.frame(cbind(traindat$Type, svm_scaled),\n",
    "                                row.names=rownames(traindat))\n",
    "    colnames(svm_scaled) <- colnames(traindat)\n",
    "    \n",
    "    # This is our current best svm model for the trainset data\n",
    "    svmod <- svm(I(as.factor(Type)) ~ ., data=svm_scaled, kernel=\"radial\",\n",
    "                 gamma= 0.03, cost= 25, scale=FALSE, probability=TRUE)\n",
    "    \n",
    "    preds <- predict(svmod, newdata=svm_scaled, scale=FALSE, probability=TRUE)\n",
    "    \n",
    "    prob01 <- as.numeric(attr(preds, \"probabilities\")[, 2])\n",
    "    prob02 <- as.numeric(attr(preds, \"probabilities\")[, 3])\n",
    "    \n",
    "    # Scale the probability columns.\n",
    "    prob01_scaled <- scale(prob01, center=TRUE, scale=TRUE)\n",
    "    prob01_center <- attr(prob01_scaled, \"scaled:center\")\n",
    "    prob01_scale <- attr(prob01_scaled, \"scaled:scale\")\n",
    "    \n",
    "    prob02_scaled <- scale(prob02, center=TRUE, scale=TRUE)\n",
    "    prob02_center <- attr(prob02_scaled, \"scaled:center\")\n",
    "    prob02_scale <- attr(prob02_scaled, \"scaled:scale\")\n",
    "    \n",
    "    #############################\n",
    "    \n",
    "    # Transform columns of traindat.\n",
    "    traindat$Phenols <- (traindat$Phenols)^0.5\n",
    "    traindat$Alcalinity <- (traindat$Alcalinity)^0.18\n",
    "    \n",
    "    # Apply pca to traindat.\n",
    "    pca <- prcomp(traindat[, -1], retx=TRUE, rank.=2, center=TRUE,\n",
    "                  scale.=TRUE)\n",
    "    dftmp <- as.data.frame(pca$x, row.names=rownames(traindat))\n",
    "    \n",
    "    # Add in the probability columns.\n",
    "    dftmp$prob01 <- prob01_scaled\n",
    "    dftmp$prob02 <- prob02_scaled\n",
    "    \n",
    "    # Apply min-max scaling.\n",
    "    dftmp_scaled <- apply(as.matrix(dftmp), MARGIN=2, range01)\n",
    "    \n",
    "    traindat_scaled <- as.data.frame(dftmp_scaled, row.names=rownames(traindat))\n",
    "    colnames(traindat_scaled) <- c(paste0(\"pc\", 1:2),\"prob01\",\"prob02\")\n",
    "    \n",
    "    # Get mins and maxs for scaling of valdat.\n",
    "    traindat_mins <- as.numeric(apply(as.matrix(dftmp), MARGIN=2, min))\n",
    "    traindat_maxs <- as.numeric(apply(as.matrix(dftmp), MARGIN=2, max))\n",
    "    \n",
    "    #############################\n",
    "    # Apply weights to traindat.  The sqrt should have\n",
    "    # been taken in the calling function.\n",
    "    cols <- names(wghts)\n",
    "    df2 <- t(t(traindat_scaled[, cols]) * as.numeric(wghts[cols]))\n",
    "    traindat_wghts <- as.data.frame(df2, row.names=rownames(traindat))\n",
    "    \n",
    "    \n",
    "    ############################\n",
    "    # Prepare valdat for svm modeling.\n",
    "    \n",
    "    svmval_scaled <- scale(valdat[, -1], center=svm_centers, scale=svm_scales)\n",
    "    svmval_scaled <- as.data.frame(svmval_scaled, row.names=rownames(valdat))\n",
    "    \n",
    "    # Compute prob01 and prob02 columns.\n",
    "    preds01_b <- predict(svmod, newdata=svmval_scaled, scale=FALSE, probability=TRUE)\n",
    "    prob01_b <- as.numeric(attr(preds01_b, \"probabilities\")[, 2])\n",
    "    prob02_b <- as.numeric(attr(preds01_b, \"probabilities\")[, 3])\n",
    "    \n",
    "    # Scale the probability columns.\n",
    "    prob01b_scaled <- scale(prob01_b, center=prob01_center, scale=prob01_scale)\n",
    "    prob02b_scaled <- scale(prob02_b, center=prob02_center, scale=prob02_scale)\n",
    "    \n",
    "    # Transform columns of valdat.\n",
    "    valdat$Phenols <- (valdat$Phenols)^0.5\n",
    "    valdat$Alcalinity <- (valdat$Alcalinity)^0.18\n",
    "    \n",
    "    # Apply pca to valdat.\n",
    "    valpca <- predict(pca, valdat[, -1])\n",
    "    df02tmp <- as.data.frame(valpca, row.names=rownames(valdat))\n",
    "    \n",
    "    # Add in the probability columns.\n",
    "    df02tmp$prob01 <- prob01b_scaled\n",
    "    df02tmp$prob02 <- prob02b_scaled\n",
    "    \n",
    "    # Apply min-max scaling.\n",
    "    df03_t <- t(as.matrix(df02tmp))\n",
    "    df03_asList <- split(df03_t, seq(nrow(df03_t)))\n",
    "    names(df03_asList) <- colnames(traindat_scaled)\n",
    "    valpca_scaled <- mapply(range02, df03_asList, traindat_mins, traindat_maxs)\n",
    "\n",
    "    # The next step is crucial.\n",
    "    valdat_scaled <- as.data.frame(valpca_scaled, row.names=rownames(valdat))\n",
    "    colnames(valdat_scaled) <- colnames(traindat_scaled)\n",
    "    \n",
    "    # Apply weights to valdat_scaled.\n",
    "    df4 <- t(t(valdat_scaled[, cols]) * as.numeric(wghts[cols]))\n",
    "    valdat_wghts <- as.data.frame(df4, row.names=rownames(valdat))\n",
    "    colnames(valdat_wghts) <- colnames(traindat_scaled)\n",
    "    \n",
    "    \n",
    "    #############################\n",
    "    # Construct k-means model.\n",
    "\n",
    "    kmod <- kmeans(traindat_wghts, 3, iter.max = 50, nstart=30)\n",
    "    \n",
    "    # See how the clusters are associated with Type level.\n",
    "    dfout <- as.data.frame(cbind(traindat$Type, kmod$cluster))\n",
    "    colnames(dfout) <- c(\"Type\", \"cluster\")\n",
    "    rownames(dfout) <- rownames(traindat)\n",
    "    mapping <- get_mapping(dfout)\n",
    "    \n",
    "    #############################\n",
    "    # Apply the k-means model to valdat_scaled.\n",
    "    \n",
    "    # Each element of the following list is a row of valdat_scaled.\n",
    "    valdat_asList <- split(valdat_wghts[, colnames(kmod$centers)],\n",
    "                           seq(nrow(valdat_wghts)))\n",
    "    \n",
    "    ctr_list <- vector(\"list\", length= nrow(valdat))\n",
    "    for(i in 1:nrow(valdat)) {\n",
    "        \n",
    "        ctr_list[[i]] <- kmod$centers\n",
    "    }\n",
    "    names(ctr_list) <- rownames(valdat)\n",
    "    \n",
    "    \n",
    "    # Get the predictions for the validation set.\n",
    "    cluster_assgns <- mcmapply(getCluster, valdat_asList, ctr_list,\n",
    "                               SIMPLIFY=TRUE, USE.NAMES= FALSE, mc.cores=6)\n",
    "    \n",
    "    valdat_scaled$cluster <- as.numeric(cluster_assgns)\n",
    "    \n",
    "    valdat_scaled$pred_Type <- NA\n",
    "    \n",
    "    # Apply mapping to the assigned clusters.  Since valdat is \n",
    "    # quite small (around 35 records if folds = 5), and there \n",
    "    # are 3 clusters, it is possible that one of the LHS expressions\n",
    "    # below is NA.  I will make the changes if the program fails. \n",
    "    valdat_scaled[which(valdat_scaled$cluster==1), c(\"pred_Type\")] <- as.numeric(mapping[\"1\"])\n",
    "    valdat_scaled[which(valdat_scaled$cluster==2), c(\"pred_Type\")] <- as.numeric(mapping[\"2\"])\n",
    "    valdat_scaled[which(valdat_scaled$cluster==3), c(\"pred_Type\")] <- as.numeric(mapping[\"3\"])\n",
    "    \n",
    "    # Generate confusion matrix for the k-means clusters and\n",
    "    # the corresponding f-score.\n",
    "    preds <- as.factor(valdat_scaled$pred_Type)\n",
    "    names(preds) <- rownames(valdat)\n",
    "    ans <- get_confusion(preds, valdat[, \"Type\", drop=FALSE])\n",
    "    return(ans[[2]])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Start time: 2021-06-03 10:01:28'"
      ],
      "text/latex": [
       "'Start time: 2021-06-03 10:01:28'"
      ],
      "text/markdown": [
       "'Start time: 2021-06-03 10:01:28'"
      ],
      "text/plain": [
       "[1] \"Start time: 2021-06-03 10:01:28\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 6.43 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Again, use the same initial seed that we have \n",
    "# been using for this score.\n",
    "\n",
    "set.seed(1931)\n",
    "seed_vector <- sample(1:9999, 2000, replace=FALSE)\n",
    "\n",
    "start <- Sys.time()\n",
    "paste(\"Start time: \", start, sep=\"\")\n",
    "ans <- compute_cvScore_km(seed_vector, train)\n",
    "stop <- Sys.time()\n",
    "round(stop - start, 2)\n",
    "# Time difference of 5.48 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "  0.775   0.821   0.831   0.830   0.838   0.865 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(ans$Acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.8304"
      ],
      "text/latex": [
       "0.8304"
      ],
      "text/markdown": [
       "0.8304"
      ],
      "text/plain": [
       "[1] 0.8304"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(mean(ans$Acc), 4)\n",
    "# 0.8304\n",
    "\n",
    "# svm02's mean accuracy score was 0.8278.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.8314"
      ],
      "text/latex": [
       "0.8314"
      ],
      "text/markdown": [
       "0.8314"
      ],
      "text/plain": [
       "[1] 0.8314"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.012394"
      ],
      "text/latex": [
       "0.012394"
      ],
      "text/markdown": [
       "0.012394"
      ],
      "text/plain": [
       "[1] 0.012394"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(median(ans$Acc), 4)\n",
    "round(sd(ans$Acc), 6)\n",
    "# median: 0.8314\n",
    "# sd: 0.012394\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAMAAAC323mdAAADAFBMVEUAAAABAQECAgIDAwME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\nGINgATAGwQJgDIIFwBj/H4MaBekU7ReUAAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title “Distribution of cross-val accuracy scores for hybrid model with weights”"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width= 10, repr.plot.height= 6)\n",
    "hist(ans$Acc, breaks=16, xlab=\"accuracy\",\n",
    "     main=\"Distribution of cross-val accuracy scores for hybrid model with weights\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Comments for Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding the k-means models, the best model we found for the wine dataset was svm02.  svm02 has a mean cross-val accuracy score of 0.8278 and a median cross-val accuracy score of 0.8271.  We found a hybrid k-means model (without weights) that was able to slightly improve upon this score.  This hybrid model has a mean cross-val accuracy score of 0.8295 and a median cross-val accuracy score of 0.8314.  (All scores are over 2000 samples.)\n",
    "\n",
    "Although this hybrid model's improvement upon svm02 is slight, it is statistically significant.  If we chose a weaker set of 3 predictors from the wine dataset, the best model accuracy score will decrease.  This lowers the bar for the k-means hybrid model; i.e., it may increase the likelihood that the k-means hybrid model will outperform the competing models.  In the Part 1 and Part 2 notebooks which worked with the cow data, the bar was lower---around 0.70 for the best non-k-means model.  There the hybrid k-means model (with weights) had an average accuracy score of 0.73.\n",
    "\n",
    "Above, in one of the Comments, I note that in previous work on the wine dataset I chose a different set of 3 predictors for Type.  In that work the best non-k-means model had a mean cross-val accuracy score of 0.9056.  The best hybrid k-means model I was able to find had a score of 0.9013.  In this notebook, the 3 predictors chosen lowered the accuracy score bar to just under 0.83.  This was enough that a hybrid k-means model could improve upon the score.  In the last section above, I create a different hybrid model that yields a further incremental improvement: over 2000 samples we were able to boost the average score to 0.8304.  The median score, however, remained at 0.8314.\n",
    "\n",
    "The next step would be to choose a third set of 3 predictors, ones that lower the accuracy score of the best models even further, and then see if k-means is able to improve upon the best models, and by how much.  Like other models, how well k-means does depends on the predictors chosen, so improvement isn't guaranteed simply because the highest accuracy score of the competing models is lower.  But a lower accuracy score does mean more opportunity exists for a model like k-means to give a boost to the best of those lower scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
